{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace: Summary of the Task:: MLM [link](https://huggingface.co/transformers/task_summary.html?highlight=fill%20mask#masked-language-modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast , AutoTokenizer,RobertaTokenizerFast, RobertaTokenizer\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RobertaTokenizer'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"./all-data-bytebpe-20000\", max_len=510) # since there are 2 special tokens?\n",
    "tokenizer.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"./Roberta_DonutTest/checkpoint-200000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(20000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=20000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102012704"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '<s>HuggingFace is creating a lot that the community uses to solve NLP tasks.</s>',\n",
       "  'score': 0.27496138215065,\n",
       "  'token': 15888,\n",
       "  'token_str': 'Ġlot'},\n",
       " {'sequence': '<s>HuggingFace is creating age that the community uses to solve NLP tasks.</s>',\n",
       "  'score': 0.14158375561237335,\n",
       "  'token': 3789,\n",
       "  'token_str': 'ge'},\n",
       " {'sequence': '<s>HuggingFace is creating away that the community uses to solve NLP tasks.</s>',\n",
       "  'score': 0.042050398886203766,\n",
       "  'token': 6149,\n",
       "  'token_str': 'way'},\n",
       " {'sequence': '<s>HuggingFace is creating a way that the community uses to solve NLP tasks.</s>',\n",
       "  'score': 0.023051628842949867,\n",
       "  'token': 13919,\n",
       "  'token_str': 'Ġway'},\n",
       " {'sequence': '<s>HuggingFace is creating a relative that the community uses to solve NLP tasks.</s>',\n",
       "  'score': 0.02065601758658886,\n",
       "  'token': 17586,\n",
       "  'token_str': 'Ġrelative'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(f\"HuggingFace is creating a {nlp.tokenizer.mask_token} that the community uses to solve NLP tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '<s>วันนี้เป็นวันที่ 2</s>',\n",
       "  'score': 0.13160008192062378,\n",
       "  'token': 403,\n",
       "  'token_str': 'Ġ2'},\n",
       " {'sequence': '<s>วันนี้เป็นวันที่ 1</s>',\n",
       "  'score': 0.0837036520242691,\n",
       "  'token': 395,\n",
       "  'token_str': 'Ġ1'},\n",
       " {'sequence': '<s>วันนี้เป็นวันที่ 3</s>',\n",
       "  'score': 0.0767679437994957,\n",
       "  'token': 485,\n",
       "  'token_str': 'Ġ3'},\n",
       " {'sequence': '<s>วันนี้เป็นวันที่ท</s>',\n",
       "  'score': 0.05507468059659004,\n",
       "  'token': 288,\n",
       "  'token_str': 'à¸Ĺ'},\n",
       " {'sequence': '<s>วันนี้เป็นวันที่ส</s>',\n",
       "  'score': 0.04600020870566368,\n",
       "  'token': 294,\n",
       "  'token_str': 'à¸ª'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(f\"วันนี้เป็นวันที่{nlp.tokenizer.mask_token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace Trainer [link](https://github.com/huggingface/transformers/blob/master/src/transformers/trainer.py#L375)\n",
    "\n",
    "## DataCollator [link](https://github.com/huggingface/transformers/blob/master/src/transformers/data/data_collator.py#L69)\n",
    "\n",
    "1. A torch.utils.data.dataloader.Dataloader is created from a Dataset (where the examples are tokenized with `tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))` and appended special tokens `<s>` and `</s>` through `tokenizer.build_inputs_with_special_tokens(tokenized_text[i : i + self.block_size])` [this is created where `block_size` is `self.block_size = block_size - tokenizer.num_special_tokens_to_add(pair=False)`] ) referenced [here](https://github.com/huggingface/transformers/blob/9022ef021a56db975d25c7108cbd19d0dd399174/src/transformers/trainer.py#L224).  \n",
    "This will return a \"List\" of ids. \n",
    "2. [_tensorize_batch()](https://github.com/huggingface/transformers/blob/master/src/transformers/data/data_collator.py#L90) will attempt to convert from ```examples: List[torch.Tensor]) -> torch.Tensor:``` and also apply [self.tokenizer._pad_token()](https://github.com/huggingface/transformers/blob/master/src/transformers/data/data_collator.py#L101) along the way for examples with irregular length\n",
    "3. ```if self.mlm: ``` , mask the tokens with [mask_tokens()](https://github.com/huggingface/transformers/blob/master/src/transformers/data/data_collator.py#L103) to Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = f\"Distilled models are smaller than the models they mimic. Using them instead of the large versions would help {tokenizer.mask_token} our carbon footprint.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'D', 'ist', 'il', 'led', ' model', 's', ' are', ' sm', 'all', 'er', ' than', ' the', ' model', 's', ' they', ' m', 'im', 'ic', '.', ' ', 'U', 'sing', ' the', 'm', ' inst', 'e', 'ad', ' of', ' the', ' l', 'ar', 'ge', ' vers', 'ions', ' w', 'ould', ' hel', 'p', '<mask>', ' our', ' car', 'b', 'on', ' f', 'oot', 'pr', 'int', '.', '</s>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    0,    40,  2744,   789,  9774, 17624,    87,  6344,  2352,  1848,\n",
       "           522, 13701,  1207, 17624,    87, 19898,   584,  1164,   721,    18,\n",
       "           225,    57, 19100,  1207,    81, 12140,    73,   977,  1572,  1207,\n",
       "           676,   633,  3789, 12847, 10865,   731, 11955, 15051,    84,     4,\n",
       "         14855,  5963,    70,   524,   655,  8489,  3220,  3449,    18,     2]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "print(list(map(lambda x: tokenizer.decode([x]) , _input[0])))\n",
    "_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
       "         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
       "         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
       "         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
       "         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
       "         0.1500, 0.1500, 0.1500, 0.1500, 0.1500]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = _input.clone()\n",
    "# We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
    "probability_matrix = torch.full(labels.shape, 0.15)\n",
    "probability_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
       "         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
       "         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
       "         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
       "         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,\n",
       "         0.1500, 0.1500, 0.1500, 0.1500, 0.0000]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If there is special tokens, fill it with 0.0\n",
    "special_tokens_mask = [\n",
    "    tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "]\n",
    "print(special_tokens_mask)\n",
    "probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "probability_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IF there is padding mask, fill it with 0 too\n",
    "padding_mask = labels.eq(tokenizer.pad_token_id)\n",
    "probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
    "padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  True,  True, False, False, False,  True,  True,\n",
      "         False, False, False, False,  True, False, False, False,  True, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True, False, False, False,  True, False,\n",
      "         False,  True, False, False, False, False, False, False,  True, False]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -100,  -100,  -100,   789,  9774,  -100,  -100,  -100,  2352,  1848,\n",
       "          -100,  -100,  -100,  -100,    87,  -100,  -100,  -100,   721,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100, 10865,  -100,  -100,  -100,    84,  -100,\n",
       "          -100,  5963,  -100,  -100,  -100,  -100,  -100,  -100,    18,  -100]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select which one to mask based on the probabilities given ealier, and if the mask isn't chosen, fill in -100 for the value\n",
    "masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "print(masked_indices)\n",
    "labels[~masked_indices] = -100  # We only compute loss on masked \n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,    40,  2744,     4,     4, 17624,    87,  6344,     4,     4,\n",
      "           522, 13701,  1207, 17624,     4, 19898,   584,  1164,     4,    18,\n",
      "           225,    57, 19100,  1207,    81, 12140,    73,   977,  1572,  1207,\n",
      "           676,   633,  3789, 12847,     4,   731, 11955, 15051,    84,     4,\n",
      "         14855,     4,    70,   524,   655,  8489,  3220,  3449,    18,     2]]) tensor([[ -100,  -100,  -100,   789,  9774,  -100,  -100,  -100,  2352,  1848,\n",
      "          -100,  -100,  -100,  -100,    87,  -100,  -100,  -100,   721,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100, 10865,  -100,  -100,  -100,    84,  -100,\n",
      "          -100,  5963,  -100,  -100,  -100,  -100,  -100,  -100,    18,  -100]])\n"
     ]
    }
   ],
   "source": [
    "# 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "_input[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "\n",
    "# 10% of the time, we replace masked input tokens with random word\n",
    "indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
    "_input[indices_random] = random_words[indices_random]\n",
    "\n",
    "# The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
    "print(_input, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'D', 'ist', '<mask>', '<mask>', ' model', 's', ' are', '<mask>', '<mask>', 'er', ' than', ' the', ' model', '<mask>', ' they', ' m', 'im', '<mask>', '.', ' ', 'U', 'sing', ' the', 'm', ' inst', 'e', 'ad', ' of', ' the', ' l', 'ar', 'ge', ' vers', '<mask>', ' w', 'ould', ' hel', 'p', '<mask>', ' our', '<mask>', 'b', 'on', ' f', 'oot', 'pr', 'int', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: tokenizer.decode([x]) , _input[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now I'm going to define `_mask_input()` \n",
    " 0.15 Probability: With 100% replace with mask, and 0% unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mask_input(sequence, tokenizer, mlm_probability=0.15, truncation=True):\n",
    "    # Tokenize the sequence with special tokens inserted\n",
    "    _input = tokenizer.encode(sequence, return_tensors=\"pt\", truncation=truncation)\n",
    "    \n",
    "    labels = _input.clone()\n",
    "    # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
    "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
    "    \n",
    "    # If there is special tokens, fill it with 0.0\n",
    "    special_tokens_mask = [\n",
    "        tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "    ]\n",
    "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "    \n",
    "    # IF there is padding mask, fill it with 0 too\n",
    "    padding_mask = labels.eq(tokenizer.pad_token_id)\n",
    "    probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
    "    \n",
    "    # Randomly select which one to mask based on the probabilities given ealier, and if the mask isn't chosen, fill in -100 for the value\n",
    "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "    labels[~masked_indices] = -100  # We only compute loss on masked \n",
    "    \n",
    "    # 100% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "    indices_replaced = masked_indices\n",
    "    _input[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "    \n",
    "    return _input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,    40,  2744,   789,  9774, 17624,    87,     4,  2352,     4,\n",
      "             4, 13701,  1207, 17624,    87, 19898,   584,  1164,   721,    18,\n",
      "           225,     4, 19100,  1207,    81, 12140,    73,   977,  1572,  1207,\n",
      "           676,   633,  3789, 12847, 10865,   731, 11955,     4,    84, 14855,\n",
      "          5963,    70,   524,     4,  8489,  3220,  3449,     4,     2]])\n",
      "['<s>', 'D', 'ist', 'il', 'led', ' model', 's', '<mask>', ' sm', '<mask>', '<mask>', ' than', ' the', ' model', 's', ' they', ' m', 'im', 'ic', '.', ' ', '<mask>', 'sing', ' the', 'm', ' inst', 'e', 'ad', ' of', ' the', ' l', 'ar', 'ge', ' vers', 'ions', ' w', 'ould', '<mask>', 'p', ' our', ' car', 'b', 'on', '<mask>', 'oot', 'pr', 'int', '<mask>', '</s>']\n",
      "tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  6344,  -100,  1848,\n",
      "           522,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,    57,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100, 15051,  -100,  -100,\n",
      "          -100,  -100,  -100,   655,  -100,  -100,  -100,    18,  -100]])\n",
      "['-', '-', '-', '-', '-', '-', '-', ' are', '-', 'all', 'er', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'U', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', ' hel', '-', '-', '-', '-', '-', ' f', '-', '-', '-', '.', '-']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input, labels = _mask_input(f\"Distilled models are smaller than the models they mimic. Using them instead of the large versions would help our carbon footprint.\", tokenizer)\n",
    "print(tokenized_input)\n",
    "print(list(map(lambda x: tokenizer.decode([x]) , tokenized_input[0])))\n",
    "print(labels)\n",
    "print(list(map(lambda x: tokenizer.decode([x]) if x != -100 else '-', labels[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now I'm going to define `_predict_masks()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_masks(_input, labels, tokenizer, k=5, verbose=True, verbose_length=6):\n",
    "    mask_token_index = torch.where(_input == tokenizer.mask_token_id)[1]\n",
    "#     print(mask_token_index)\n",
    "    token_logits = model(_input)[0]\n",
    "#     print(token_logits)\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "#     print(mask_token_logits)\n",
    "    top_k_tokens = torch.topk(mask_token_logits, k, dim=1).indices.numpy()\n",
    "    _labels = labels[0, mask_token_index].numpy()\n",
    "    _labels = np.vstack(_labels) #vertical stack to be able to compare to top_5_tokens\n",
    "#     print(top_5_tokens)\n",
    "#     print(_labels)\n",
    "    \n",
    "    for index, mask_index in enumerate(mask_token_index):\n",
    "        input_verbose_sequence = _input[0, mask_index-verbose_length:mask_index+verbose_length].clone()\n",
    "        labeled_verbose_sequence = input_verbose_sequence.clone()\n",
    "        labeled_verbose_sequence[verbose_length] = labels[0, mask_index]\n",
    "        print(\"Masked Input: \")\n",
    "#         print(f\"\\t{list(map(lambda x: tokenizer.decode([x]) , input_verbose_sequence))}\")\n",
    "        print(f\"\\t{tokenizer.decode(input_verbose_sequence)}\")\n",
    "        print(\"Labeled Input: \")\n",
    "#         print(f\"\\t{list(map(lambda x: tokenizer.decode([x]) , labeled_verbose_sequence))}\")\n",
    "        print(f\"\\t{tokenizer.decode(labeled_verbose_sequence)}\")\n",
    "        print(\"Predictions: \")\n",
    "        for prediction in top_k_tokens[index]:\n",
    "            prediction_verbose_sequence = input_verbose_sequence.clone()\n",
    "            prediction_verbose_sequence[verbose_length] = prediction\n",
    "#             print(f\"\\t{list(map(lambda x: tokenizer.decode([x]) , prediction_verbose_sequence))}\")\n",
    "            print(f\"\\t{tokenizer.decode(prediction_verbose_sequence)}\")\n",
    "        print(\"\")\n",
    "    \n",
    "    correct_labels = np.any(top_k_tokens == _labels, axis=1)\n",
    "    percent_correct = np.sum(correct_labels)/correct_labels.size\n",
    "    print(f\"Total Input Tokens: {_input.squeeze().shape}\")\n",
    "    print(f\"Total Correct for Top {k}: {np.sum(correct_labels)}\")\n",
    "    print(f\"Total Mask: {correct_labels.size}\")\n",
    "    print(f\"Percent Correct: {percent_correct*100:.2f}%\")\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Input: \n",
      "\t['D', 'ist', 'il', 'led', ' model', 's', '<mask>', ' sm', '<mask>', '<mask>', ' than', ' the']\n",
      "Labeled Input: \n",
      "\t['D', 'ist', 'il', 'led', ' model', 's', ' are', ' sm', '<mask>', '<mask>', ' than', ' the']\n",
      "Predictions: \n",
      "\t['D', 'ist', 'il', 'led', ' model', 's', ' they', ' sm', '<mask>', '<mask>', ' than', ' the']\n",
      "\t['D', 'ist', 'il', 'led', ' model', 's', ' we', ' sm', '<mask>', '<mask>', ' than', ' the']\n",
      "\t['D', 'ist', 'il', 'led', ' model', 's', ' and', ' sm', '<mask>', '<mask>', ' than', ' the']\n",
      "\t['D', 'ist', 'il', 'led', ' model', 's', ' that', ' sm', '<mask>', '<mask>', ' than', ' the']\n",
      "\t['D', 'ist', 'il', 'led', ' model', 's', ' you', ' sm', '<mask>', '<mask>', ' than', ' the']\n",
      "\n",
      "Masked Input: \n",
      "\t['il', 'led', ' model', 's', '<mask>', ' sm', '<mask>', '<mask>', ' than', ' the', ' model', 's']\n",
      "Labeled Input: \n",
      "\t['il', 'led', ' model', 's', '<mask>', ' sm', 'all', '<mask>', ' than', ' the', ' model', 's']\n",
      "Predictions: \n",
      "\t['il', 'led', ' model', 's', '<mask>', ' sm', 'ooth', '<mask>', ' than', ' the', ' model', 's']\n",
      "\t['il', 'led', ' model', 's', '<mask>', ' sm', 'all', '<mask>', ' than', ' the', ' model', 's']\n",
      "\t['il', 'led', ' model', 's', '<mask>', ' sm', 'ile', '<mask>', ' than', ' the', ' model', 's']\n",
      "\t['il', 'led', ' model', 's', '<mask>', ' sm', 'ith', '<mask>', ' than', ' the', ' model', 's']\n",
      "\t['il', 'led', ' model', 's', '<mask>', ' sm', 'art', '<mask>', ' than', ' the', ' model', 's']\n",
      "\n",
      "Masked Input: \n",
      "\t['led', ' model', 's', '<mask>', ' sm', '<mask>', '<mask>', ' than', ' the', ' model', 's', ' they']\n",
      "Labeled Input: \n",
      "\t['led', ' model', 's', '<mask>', ' sm', '<mask>', 'er', ' than', ' the', ' model', 's', ' they']\n",
      "Predictions: \n",
      "\t['led', ' model', 's', '<mask>', ' sm', '<mask>', ' more', ' than', ' the', ' model', 's', ' they']\n",
      "\t['led', ' model', 's', '<mask>', ' sm', '<mask>', 'es', ' than', ' the', ' model', 's', ' they']\n",
      "\t['led', ' model', 's', '<mask>', ' sm', '<mask>', 'les', ' than', ' the', ' model', 's', ' they']\n",
      "\t['led', ' model', 's', '<mask>', ' sm', '<mask>', 'ers', ' than', ' the', ' model', 's', ' they']\n",
      "\t['led', ' model', 's', '<mask>', ' sm', '<mask>', 'ing', ' than', ' the', ' model', 's', ' they']\n",
      "\n",
      "Masked Input: \n",
      "\t[' they', ' m', 'im', 'ic', '.', ' ', '<mask>', 'sing', ' the', 'm', ' inst', 'e']\n",
      "Labeled Input: \n",
      "\t[' they', ' m', 'im', 'ic', '.', ' ', 'U', 'sing', ' the', 'm', ' inst', 'e']\n",
      "Predictions: \n",
      "\t[' they', ' m', 'im', 'ic', '.', ' ', '\\n', 'sing', ' the', 'm', ' inst', 'e']\n",
      "\t[' they', ' m', 'im', 'ic', '.', ' ', 'oo', 'sing', ' the', 'm', ' inst', 'e']\n",
      "\t[' they', ' m', 'im', 'ic', '.', ' ', ' to', 'sing', ' the', 'm', ' inst', 'e']\n",
      "\t[' they', ' m', 'im', 'ic', '.', ' ', ' the', 'sing', ' the', 'm', ' inst', 'e']\n",
      "\t[' they', ' m', 'im', 'ic', '.', ' ', 'all', 'sing', ' the', 'm', ' inst', 'e']\n",
      "\n",
      "Masked Input: \n",
      "\t['ar', 'ge', ' vers', 'ions', ' w', 'ould', '<mask>', 'p', ' our', ' car', 'b', 'on']\n",
      "Labeled Input: \n",
      "\t['ar', 'ge', ' vers', 'ions', ' w', 'ould', ' hel', 'p', ' our', ' car', 'b', 'on']\n",
      "Predictions: \n",
      "\t['ar', 'ge', ' vers', 'ions', ' w', 'ould', ' hel', 'p', ' our', ' car', 'b', 'on']\n",
      "\t['ar', 'ge', ' vers', 'ions', ' w', 'ould', ' op', 'p', ' our', ' car', 'b', 'on']\n",
      "\t['ar', 'ge', ' vers', 'ions', ' w', 'ould', 'hel', 'p', ' our', ' car', 'b', 'on']\n",
      "\t['ar', 'ge', ' vers', 'ions', ' w', 'ould', ' de', 'p', ' our', ' car', 'b', 'on']\n",
      "\t['ar', 'ge', ' vers', 'ions', ' w', 'ould', 'com', 'p', ' our', ' car', 'b', 'on']\n",
      "\n",
      "Masked Input: \n",
      "\t['<mask>', 'p', ' our', ' car', 'b', 'on', '<mask>', 'oot', 'pr', 'int', '<mask>', '</s>']\n",
      "Labeled Input: \n",
      "\t['<mask>', 'p', ' our', ' car', 'b', 'on', ' f', 'oot', 'pr', 'int', '<mask>', '</s>']\n",
      "Predictions: \n",
      "\t['<mask>', 'p', ' our', ' car', 'b', 'on', ' b', 'oot', 'pr', 'int', '<mask>', '</s>']\n",
      "\t['<mask>', 'p', ' our', ' car', 'b', 'on', ' r', 'oot', 'pr', 'int', '<mask>', '</s>']\n",
      "\t['<mask>', 'p', ' our', ' car', 'b', 'on', ' f', 'oot', 'pr', 'int', '<mask>', '</s>']\n",
      "\t['<mask>', 'p', ' our', ' car', 'b', 'on', ' sh', 'oot', 'pr', 'int', '<mask>', '</s>']\n",
      "\t['<mask>', 'p', ' our', ' car', 'b', 'on', ' s', 'oot', 'pr', 'int', '<mask>', '</s>']\n",
      "\n",
      "Masked Input: \n",
      "\t['b', 'on', '<mask>', 'oot', 'pr', 'int', '<mask>', '</s>']\n",
      "Labeled Input: \n",
      "\t['b', 'on', '<mask>', 'oot', 'pr', 'int', '.', '</s>']\n",
      "Predictions: \n",
      "\t['b', 'on', '<mask>', 'oot', 'pr', 'int', ' to', '</s>']\n",
      "\t['b', 'on', '<mask>', 'oot', 'pr', 'int', ' the', '</s>']\n",
      "\t['b', 'on', '<mask>', 'oot', 'pr', 'int', '.', '</s>']\n",
      "\t['b', 'on', '<mask>', 'oot', 'pr', 'int', ' than', '</s>']\n",
      "\t['b', 'on', '<mask>', 'oot', 'pr', 'int', ' for', '</s>']\n",
      "\n",
      "Total Input Tokens: torch.Size([49])\n",
      "Total Correct: 4\n",
      "Total Mask: 7\n",
      "Percent Correct: 57.14%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_predict_masks(tokenized_input, labels, tokenizer , k=5, verbose=True, verbose_length=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Mask Filling on New Unseen Pantip Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Tokenize on Pantip Sample ใครเคยมีแฟนที่กินอาหารไม่ถูกปากกันแล้วรู้สึกเสียความสุขไปอย่างนึงบ้างมั้ยครับ\n",
    "https://pantip.com/topic/40006922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Input: \n",
      "\tนอาหารไม่ถูกป<mask><mask>นแล้วรู้\n",
      "Labeled Input: \n",
      "\tนอาหารไม่ถูกปากก<mask>นแล้วรู้\n",
      "Predictions: \n",
      "\tนอาหารไม่ถูกปนก<mask>นแล้วรู้\n",
      "\tนอาหารไม่ถูกปนๆก<mask>นแล้วรู้\n",
      "\tนอาหารไม่ถูกปองก<mask>นแล้วรู้\n",
      "\tนอาหารไม่ถูกปากก<mask>นแล้วรู้\n",
      "\tนอาหารไม่ถูกปอดก<mask>นแล้วรู้\n",
      "\n",
      "Masked Input: \n",
      "\tไม่ถูกป<mask><mask>นแล้วรู้ส\n",
      "Labeled Input: \n",
      "\tไม่ถูกป<mask>ันแล้วรู้ส\n",
      "Predictions: \n",
      "\tไม่ถูกป<mask>ันแล้วรู้ส\n",
      "\tไม่ถูกป<mask>็นแล้วรู้ส\n",
      "\tไม่ถูกป<mask>ั้นแล้วรู้ส\n",
      "\tไม่ถูกป<mask>ินแล้วรู้ส\n",
      "\tไม่ถูกป<mask>นจนแล้วรู้ส\n",
      "\n",
      "Masked Input: \n",
      "\tึงบ้างมั้ยคร<mask>บ  ก่อนอ\n",
      "Labeled Input: \n",
      "\tึงบ้างมั้ยครับ  ก่อนอ\n",
      "Predictions: \n",
      "\tึงบ้างมั้ยครับ  ก่อนอ\n",
      "\tึงบ้างมั้ยคร้บ  ก่อนอ\n",
      "\tึงบ้างมั้ยครั้บ  ก่อนอ\n",
      "\tึงบ้างมั้ยครีบ  ก่อนอ\n",
      "\tึงบ้างมั้ยครั๊บ  ก่อนอ\n",
      "\n",
      "Masked Input: \n",
      "\t<mask>บ  ก่อนอ<mask>นผมต้องบอกก่\n",
      "Labeled Input: \n",
      "\t<mask>บ  ก่อนอื่นผมต้องบอกก่\n",
      "Predictions: \n",
      "\t<mask>บ  ก่อนอื่นผมต้องบอกก่\n",
      "\t<mask>บ  ก่อนอืนผมต้องบอกก่\n",
      "\t<mask>บ  ก่อนอั้นผมต้องบอกก่\n",
      "\t<mask>บ  ก่อนอิ่นผมต้องบอกก่\n",
      "\t<mask>บ  ก่อนอื้นผมต้องบอกก่\n",
      "\n",
      "Masked Input: \n",
      "\t่อนเลยว่าคนเราจะเล<mask>อกกินอาหารแบบไหนชอบ\n",
      "Labeled Input: \n",
      "\t่อนเลยว่าคนเราจะเลือกกินอาหารแบบไหนชอบ\n",
      "Predictions: \n",
      "\t่อนเลยว่าคนเราจะเลือกกินอาหารแบบไหนชอบ\n",
      "\t่อนเลยว่าคนเราจะเลิอกกินอาหารแบบไหนชอบ\n",
      "\t่อนเลยว่าคนเราจะเลื้อกกินอาหารแบบไหนชอบ\n",
      "\t่อนเลยว่าคนเราจะเลื่อกกินอาหารแบบไหนชอบ\n",
      "\t่อนเลยว่าคนเราจะเลื๊อกกินอาหารแบบไหนชอบ\n",
      "\n",
      "Masked Input: \n",
      "\tื่องของความชอบส่วนต<mask>วนะครับทุกคนม\n",
      "Labeled Input: \n",
      "\tื่องของความชอบส่วนตัวนะครับทุกคนม\n",
      "Predictions: \n",
      "\tื่องของความชอบส่วนตัวนะครับทุกคนม\n",
      "\tื่องของความชอบส่วนต้วนะครับทุกคนม\n",
      "\tื่องของความชอบส่วนตั้วนะครับทุกคนม\n",
      "\tื่องของความชอบส่วนต่วนะครับทุกคนม\n",
      "\tื่องของความชอบส่วนติวนะครับทุกคนม\n",
      "\n",
      "Masked Input: \n",
      "\tในการเลือกของที่ชอบ<mask><mask>ชอบอยู่<mask>้\n",
      "Labeled Input: \n",
      "\tในการเลือกของที่ชอบและไม<mask>ชอบอยู่<mask>้\n",
      "Predictions: \n",
      "\tในการเลือกของที่ชอบของคนท<mask>ชอบอยู่<mask>้\n",
      "\tในการเลือกของที่ชอบและไม<mask>ชอบอยู่<mask>้\n",
      "\tในการเลือกของที่ชอบของท<mask>ชอบอยู่<mask>้\n",
      "\tในการเลือกของที่ชอบแบบท<mask>ชอบอยู่<mask>้\n",
      "\tในการเลือกของที่ชอบผมก<mask>ชอบอยู่<mask>้\n",
      "\n",
      "Masked Input: \n",
      "\tือกของที่ชอบ<mask><mask>ชอบอยู่<mask>้ว\n",
      "Labeled Input: \n",
      "\tือกของที่ชอบ<mask>่ชอบอยู่<mask>้ว\n",
      "Predictions: \n",
      "\tือกของที่ชอบ<mask>ี่ชอบอยู่<mask>้ว\n",
      "\tือกของที่ชอบ<mask>่ชอบอยู่<mask>้ว\n",
      "\tือกของที่ชอบ<mask>็ชอบอยู่<mask>้ว\n",
      "\tือกของที่ชอบ<mask>ผมชอบอยู่<mask>้ว\n",
      "\tือกของที่ชอบ<mask>และชอบอยู่<mask>้ว\n",
      "\n",
      "Masked Input: \n",
      "\tี่ชอบ<mask><mask>ชอบอยู่<mask>้ว แต่<mask>\n",
      "Labeled Input: \n",
      "\tี่ชอบ<mask><mask>ชอบอยู่แล้ว แต่<mask>\n",
      "Predictions: \n",
      "\tี่ชอบ<mask><mask>ชอบอยู่แล้ว แต่<mask>\n",
      "\tี่ชอบ<mask><mask>ชอบอยู่มานานแล้ว แต่<mask>\n",
      "\tี่ชอบ<mask><mask>ชอบอยู่เเล้ว แต่<mask>\n",
      "\tี่ชอบ<mask><mask>ชอบอยู่มากแล้ว แต่<mask>\n",
      "\tี่ชอบ<mask><mask>ชอบอยู่นานแล้ว แต่<mask>\n",
      "\n",
      "Masked Input: \n",
      "\tู่<mask>้ว แต่<mask>ู้สึกว่\n",
      "Labeled Input: \n",
      "\tู่<mask>้ว แต่ผมรู้สึกว่\n",
      "Predictions: \n",
      "\tู่<mask>้ว แต่ผมรู้สึกว่\n",
      "\tู่<mask>้ว แต่รู้สึกว่\n",
      "\tู่<mask>้ว แต่เรารู้สึกว่\n",
      "\tู่<mask>้ว แต่ความรู้สึกว่\n",
      "\tู่<mask>้ว แต่พอรู้สึกว่\n",
      "\n",
      "Masked Input: \n",
      "\tังประสบปัญหาที่<mask>ูเหมือนจะเล\n",
      "Labeled Input: \n",
      "\tังประสบปัญหาที่ดูเหมือนจะเล\n",
      "Predictions: \n",
      "\tังประสบปัญหาที่ดูเหมือนจะเล\n",
      "\tังประสบปัญหาที่ผมดูเหมือนจะเล\n",
      "\tังประสบปัญหาที่แลดูเหมือนจะเล\n",
      "\tังประสบปัญหาที่หูเหมือนจะเล\n",
      "\tังประสบปัญหาที่อาจจะดูเหมือนจะเล\n",
      "\n",
      "Masked Input: \n",
      "\tับแฟนมา6ปีแล<mask>วครับ ผมเป็\n",
      "Labeled Input: \n",
      "\tับแฟนมา6ปีแล้วครับ ผมเป็\n",
      "Predictions: \n",
      "\tับแฟนมา6ปีแล้วครับ ผมเป็\n",
      "\tับแฟนมา6ปีแลัวครับ ผมเป็\n",
      "\tับแฟนมา6ปีแล่วครับ ผมเป็\n",
      "\tับแฟนมา6ปีแล้.วครับ ผมเป็\n",
      "\tับแฟนมา6ปีแล๋วครับ ผมเป็\n",
      "\n",
      "Masked Input: \n",
      "\tปลาดิบแต่แฟน<mask><mask>ก<mask>นปลาด\n",
      "Labeled Input: \n",
      "\tปลาดิบแต่แฟนผมไม<mask>ก<mask>นปลาด\n",
      "Predictions: \n",
      "\tปลาดิบแต่แฟนผมไม<mask>ก<mask>นปลาด\n",
      "\tปลาดิบแต่แฟนผมก<mask>ก<mask>นปลาด\n",
      "\tปลาดิบแต่แฟนเราไม<mask>ก<mask>นปลาด\n",
      "\tปลาดิบแต่แฟนผม<mask>ก<mask>นปลาด\n",
      "\tปลาดิบแต่แฟนไม<mask>ก<mask>นปลาด\n",
      "\n",
      "Masked Input: \n",
      "\tาดิบแต่แฟน<mask><mask>ก<mask>นปลาด<mask>\n",
      "Labeled Input: \n",
      "\tาดิบแต่แฟน<mask>่ก<mask>นปลาด<mask>\n",
      "Predictions: \n",
      "\tาดิบแต่แฟน<mask>่ก<mask>นปลาด<mask>\n",
      "\tาดิบแต่แฟน<mask>้ก<mask>นปลาด<mask>\n",
      "\tาดิบแต่แฟน<mask>็ก<mask>นปลาด<mask>\n",
      "\tาดิบแต่แฟน<mask>าอยากก<mask>นปลาด<mask>\n",
      "\tาดิบแต่แฟน<mask>าชอบก<mask>นปลาด<mask>\n",
      "\n",
      "Masked Input: \n",
      "\tบแต่แฟน<mask><mask>ก<mask>นปลาด<mask>บเลย ผมอยาก\n",
      "Labeled Input: \n",
      "\tบแต่แฟน<mask><mask>กินปลาด<mask>บเลย ผมอยาก\n",
      "Predictions: \n",
      "\tบแต่แฟน<mask><mask>กินปลาด<mask>บเลย ผมอยาก\n",
      "\tบแต่แฟน<mask><mask>กันปลาด<mask>บเลย ผมอยาก\n",
      "\tบแต่แฟน<mask><mask>ก็นปลาด<mask>บเลย ผมอยาก\n",
      "\tบแต่แฟน<mask><mask>ก้นปลาด<mask>บเลย ผมอยาก\n",
      "\tบแต่แฟน<mask><mask>กั้นปลาด<mask>บเลย ผมอยาก\n",
      "\n",
      "Masked Input: \n",
      "\t<mask><mask>ก<mask>นปลาด<mask>บเลย ผมอยากกินบ\n",
      "Labeled Input: \n",
      "\t<mask><mask>ก<mask>นปลาดิบเลย ผมอยากกินบ\n",
      "Predictions: \n",
      "\t<mask><mask>ก<mask>นปลาดิบเลย ผมอยากกินบ\n",
      "\t<mask><mask>ก<mask>นปลาดับเลย ผมอยากกินบ\n",
      "\t<mask><mask>ก<mask>นปลาดุบเลย ผมอยากกินบ\n",
      "\t<mask><mask>ก<mask>นปลาดืบเลย ผมอยากกินบ\n",
      "\t<mask><mask>ก<mask>นปลาดิ๊บเลย ผมอยากกินบ\n",
      "\n",
      "Masked Input: \n",
      "\tผมก็ไม่กิ<mask>ื้อ เราเลยไม<mask><mask>\n",
      "Labeled Input: \n",
      "\tผมก็ไม่กินเนื้อ เราเลยไม<mask><mask>\n",
      "Predictions: \n",
      "\tผมก็ไม่กินเนื้อ เราเลยไม<mask><mask>\n",
      "\tผมก็ไม่กินมื้อ เราเลยไม<mask><mask>\n",
      "\tผมก็ไม่กิดเนื้อ เราเลยไม<mask><mask>\n",
      "\tผมก็ไม่กิบเนื้อ เราเลยไม<mask><mask>\n",
      "\tผมก็ไม่กิมเนื้อ เราเลยไม<mask><mask>\n",
      "\n",
      "Masked Input: \n",
      "\tกิ<mask>ื้อ เราเลยไม<mask><mask>้เข้าท\n",
      "Labeled Input: \n",
      "\tกิ<mask>ื้อ เราเลยไม่<mask>้เข้าท\n",
      "Predictions: \n",
      "\tกิ<mask>ื้อ เราเลยไม่<mask>้เข้าท\n",
      "\tกิ<mask>ื้อ เราเลยไม้<mask>้เข้าท\n",
      "\tกิ<mask>ื้อ เราเลยไมี<mask>้เข้าท\n",
      "\tกิ<mask>ื้อ เราเลยไม็<mask>้เข้าท\n",
      "\tกิ<mask>ื้อ เราเลยไมั<mask>้เข้าท\n",
      "\n",
      "Masked Input: \n",
      "\tิ<mask>ื้อ เราเลยไม<mask><mask>้เข้าทานร\n",
      "Labeled Input: \n",
      "\tิ<mask>ื้อ เราเลยไม<mask>ได้เข้าทานร\n",
      "Predictions: \n",
      "\tิ<mask>ื้อ เราเลยไม<mask>ได้เข้าทานร\n",
      "\tิ<mask>ื้อ เราเลยไม<mask>ให้เข้าทานร\n",
      "\tิ<mask>ื้อ เราเลยไม<mask>อยากให้เข้าทานร\n",
      "\tิ<mask>ื้อ เราเลยไม<mask>ชอบให้เข้าทานร\n",
      "\tิ<mask>ื้อ เราเลยไม<mask>เคยได้เข้าทานร\n",
      "\n",
      "Masked Input: \n",
      "\tาทานร้านบุฟเฟ<mask>เนื้อและบุ\n",
      "Labeled Input: \n",
      "\tาทานร้านบุฟเฟ่เนื้อและบุ\n",
      "Predictions: \n",
      "\tาทานร้านบุฟเฟ่เนื้อและบุ\n",
      "\tาทานร้านบุฟเฟ่-เนื้อและบุ\n",
      "\tาทานร้านบุฟเฟ่(เนื้อและบุ\n",
      "\tาทานร้านบุฟเฟ่,เนื้อและบุ\n",
      "\tาทานร้านบุฟเฟ่...เนื้อและบุ\n",
      "\n",
      "Masked Input: \n",
      "\t<mask>เนื้อและบุ<mask><mask>อาหารญี่ป\n",
      "Labeled Input: \n",
      "\t<mask>เนื้อและบุฟเฟ<mask>อาหารญี่ป\n",
      "Predictions: \n",
      "\t<mask>เนื้อและบุฟเฟ<mask>อาหารญี่ป\n",
      "\t<mask>เนื้อและบุฟเฟต<mask>อาหารญี่ป\n",
      "\t<mask>เนื้อและบุร<mask>อาหารญี่ป\n",
      "\t<mask>เนื้อและบุหร<mask>อาหารญี่ป\n",
      "\t<mask>เนื้อและบุก<mask>อาหารญี่ป\n",
      "\n",
      "Masked Input: \n",
      "\tเนื้อและบุ<mask><mask>อาหารญี่ปุ่\n",
      "Labeled Input: \n",
      "\tเนื้อและบุ<mask>่อาหารญี่ปุ่\n",
      "Predictions: \n",
      "\tเนื้อและบุ<mask>่อาหารญี่ปุ่\n",
      "\tเนื้อและบุ<mask>์อาหารญี่ปุ่\n",
      "\tเนื้อและบุ<mask>ของอาหารญี่ปุ่\n",
      "\tเนื้อและบุ<mask>ีอาหารญี่ปุ่\n",
      "\tเนื้อและบุ<mask>ี่อาหารญี่ปุ่\n",
      "\n",
      "Masked Input: \n",
      "\tญี่ปุ่นกั<mask>รู้สึกล\n",
      "Labeled Input: \n",
      "\tญี่ปุ่นกันเพราะรู้สึกล\n",
      "Predictions: \n",
      "\tญี่ปุ่นกับผมรู้สึกล\n",
      "\tญี่ปุ่นกันผมรู้สึกล\n",
      "\tญี่ปุ่นกันเลยรู้สึกล\n",
      "\tญี่ปุ่นกับแฟนรู้สึกล\n",
      "\tญี่ปุ่นกันแบบรู้สึกล\n",
      "\n",
      "Masked Input: \n",
      "\tึกลัวแฟนผมทาน<mask>่คุ้ม และเร\n",
      "Labeled Input: \n",
      "\tึกลัวแฟนผมทานไม่คุ้ม และเร\n",
      "Predictions: \n",
      "\tึกลัวแฟนผมทานไม่คุ้ม และเร\n",
      "\tึกลัวแฟนผมทานแบบไม่คุ้ม และเร\n",
      "\tึกลัวแฟนผมทานอะไรไม่คุ้ม และเร\n",
      "\tึกลัวแฟนผมทานจะไม่คุ้ม และเร\n",
      "\tึกลัวแฟนผมทานมาไม่คุ้ม และเร\n",
      "\n",
      "Masked Input: \n",
      "\tคุ้ม และเรื่องใหญ<mask>เลยคือผมเป็นคนชอบ\n",
      "Labeled Input: \n",
      "\tคุ้ม และเรื่องใหญ่เลยคือผมเป็นคนชอบ\n",
      "Predictions: \n",
      "\tคุ้ม และเรื่องใหญ่เลยคือผมเป็นคนชอบ\n",
      "\tคุ้ม และเรื่องใหญ๋เลยคือผมเป็นคนชอบ\n",
      "\tคุ้ม และเรื่องใหญ่)เลยคือผมเป็นคนชอบ\n",
      "\tคุ้ม และเรื่องใหญ่..เลยคือผมเป็นคนชอบ\n",
      "\tคุ้ม และเรื่องใหญ้เลยคือผมเป็นคนชอบ\n",
      "\n",
      "Masked Input: \n",
      "\tือผมเป็นคนชอบทานอาหารรส<mask>ัดและรสเผ็\n",
      "Labeled Input: \n",
      "\tือผมเป็นคนชอบทานอาหารรสจัดและรสเผ็\n",
      "Predictions: \n",
      "\tือผมเป็นคนชอบทานอาหารรสจัดและรสเผ็\n",
      "\tือผมเป็นคนชอบทานอาหารรสสลัดและรสเผ็\n",
      "\tือผมเป็นคนชอบทานอาหารรสเผัดและรสเผ็\n",
      "\tือผมเป็นคนชอบทานอาหารรสผัดและรสเผ็\n",
      "\tือผมเป็นคนชอบทานอาหารรสสจัดและรสเผ็\n",
      "\n",
      "Masked Input: \n",
      "\tดและรสเผ็ดมาก แต<mask>แฟนผมทานเผ็ดไม\n",
      "Labeled Input: \n",
      "\tดและรสเผ็ดมาก แต่แฟนผมทานเผ็ดไม\n",
      "Predictions: \n",
      "\tดและรสเผ็ดมาก แต่แฟนผมทานเผ็ดไม\n",
      "\tดและรสเผ็ดมาก แต่...แฟนผมทานเผ็ดไม\n",
      "\tดและรสเผ็ดมาก แต่..แฟนผมทานเผ็ดไม\n",
      "\tดและรสเผ็ดมาก แต่)แฟนผมทานเผ็ดไม\n",
      "\tดและรสเผ็ดมาก แต่!แฟนผมทานเผ็ดไม\n",
      "\n",
      "Masked Input: \n",
      "\tเลยเวลาเราไปกินส<mask>มต<mask>�กั\n",
      "Labeled Input: \n",
      "\tเลยเวลาเราไปกินส้มต<mask>�กั\n",
      "Predictions: \n",
      "\tเลยเวลาเราไปกินส้มต<mask>�กั\n",
      "\tเลยเวลาเราไปกินสัมต<mask>�กั\n",
      "\tเลยเวลาเราไปกินสระมต<mask>�กั\n",
      "\tเลยเวลาเราไปกินสุมต<mask>�กั\n",
      "\tเลยเวลาเราไปกินสลมต<mask>�กั\n",
      "\n",
      "Masked Input: \n",
      "\tเราไปกินส<mask>มต<mask>�กันก็\n",
      "Labeled Input: \n",
      "\tเราไปกินส<mask>มตำกันก็\n",
      "Predictions: \n",
      "\tเราไปกินส<mask>มตำกันก็\n",
      "\tเราไปกินส<mask>มต��กันก็\n",
      "\tเราไปกินส<mask>มตเำกันก็\n",
      "\tเราไปกินส<mask>มตราำกันก็\n",
      "\tเราไปกินส<mask>มต��กันก็\n",
      "\n",
      "Masked Input: \n",
      "\tใส่พริก ล<mask>ไม่ใส่พร\n",
      "Labeled Input: \n",
      "\tใส่พริก ลาบไม่ใส่พร\n",
      "Predictions: \n",
      "\tใส่พริก ลวกไม่ใส่พร\n",
      "\tใส่พริก ลาบไม่ใส่พร\n",
      "\tใส่พริก ลามกไม่ใส่พร\n",
      "\tใส่พริก ลายๆไม่ใส่พร\n",
      "\tใส่พริก ลวดไม่ใส่พร\n",
      "\n",
      "Masked Input: \n",
      "\tพริก ร้านก<mask>บข้าวอื่นๆก\n",
      "Labeled Input: \n",
      "\tพริก ร้านกับข้าวอื่นๆก\n",
      "Predictions: \n",
      "\tพริก ร้านกับข้าวอื่นๆก\n",
      "\tพริก ร้านกิบข้าวอื่นๆก\n",
      "\tพริก ร้านกีบข้าวอื่นๆก\n",
      "\tพริก ร้านก้บข้าวอื่นๆก\n",
      "\tพริก ร้านกุ้บข้าวอื่นๆก\n",
      "\n",
      "Masked Input: \n",
      "\tื่นๆก็เช่นก<mask>นแฟนผมจะไม่ชอบก\n",
      "Labeled Input: \n",
      "\tื่นๆก็เช่นกันแฟนผมจะไม่ชอบก\n",
      "Predictions: \n",
      "\tื่นๆก็เช่นกันแฟนผมจะไม่ชอบก\n",
      "\tื่นๆก็เช่นก้นแฟนผมจะไม่ชอบก\n",
      "\tื่นๆก็เช่นกั้นแฟนผมจะไม่ชอบก\n",
      "\tื่นๆก็เช่นก็นแฟนผมจะไม่ชอบก\n",
      "\tื่นๆก็เช่นกินแฟนผมจะไม่ชอบก\n",
      "\n",
      "Masked Input: \n",
      "\tผมจะไม่ชอบกินผ<mask><mask>่ค่อยส\n",
      "Labeled Input: \n",
      "\tผมจะไม่ชอบกินผั<mask>่ค่อยส\n",
      "Predictions: \n",
      "\tผมจะไม่ชอบกินผั<mask>่ค่อยส\n",
      "\tผมจะไม่ชอบกินผ้<mask>่ค่อยส\n",
      "\tผมจะไม่ชอบกินผู้<mask>่ค่อยส\n",
      "\tผมจะไม่ชอบกินผื<mask>่ค่อยส\n",
      "\tผมจะไม่ชอบกินผง<mask>่ค่อยส\n",
      "\n",
      "Masked Input: \n",
      "\tจะไม่ชอบกินผ<mask><mask>่ค่อยสั่\n",
      "Labeled Input: \n",
      "\tจะไม่ชอบกินผ<mask>กไม่ค่อยสั่\n",
      "Predictions: \n",
      "\tจะไม่ชอบกินผ<mask>กไม่ค่อยสั่\n",
      "\tจะไม่ชอบกินผ<mask>ดไม่ค่อยสั่\n",
      "\tจะไม่ชอบกินผ<mask>ไม่ค่อยสั่\n",
      "\tจะไม่ชอบกินผ<mask>กจะไม่ค่อยสั่\n",
      "\tจะไม่ชอบกินผ<mask>ชายไม่ค่อยสั่\n",
      "\n",
      "Masked Input: \n",
      "\t่ค่อยสั่งก<mask>บข้าวที่เป\n",
      "Labeled Input: \n",
      "\t่ค่อยสั่งกับข้าวที่เป\n",
      "Predictions: \n",
      "\t่ค่อยสั่งกับข้าวที่เป\n",
      "\t่ค่อยสั่งกิบข้าวที่เป\n",
      "\t่ค่อยสั่งกีบข้าวที่เป\n",
      "\t่ค่อยสั่งก้บข้าวที่เป\n",
      "\t่ค่อยสั่งกุ้บข้าวที่เป\n",
      "\n",
      "Masked Input: \n",
      "\tาวที่เป็นผั<mask>้วผมชอบผ<mask>กบ\n",
      "Labeled Input: \n",
      "\tาวที่เป็นผักแล้วผมชอบผ<mask>กบ\n",
      "Predictions: \n",
      "\tาวที่เป็นผักแล้วผมชอบผ<mask>กบ\n",
      "\tาวที่เป็นผัดแล้วผมชอบผ<mask>กบ\n",
      "\tาวที่เป็นผับแล้วผมชอบผ<mask>กบ\n",
      "\tาวที่เป็นผักเเล้วผมชอบผ<mask>กบ\n",
      "\tาวที่เป็นผักไปแล้วผมชอบผ<mask>กบ\n",
      "\n",
      "Masked Input: \n",
      "\tนผั<mask>้วผมชอบผ<mask>กบ<mask><mask>อดกรอบ\n",
      "Labeled Input: \n",
      "\tนผั<mask>้วผมชอบผักบ<mask><mask>อดกรอบ\n",
      "Predictions: \n",
      "\tนผั<mask>้วผมชอบผักบ<mask><mask>อดกรอบ\n",
      "\tนผั<mask>้วผมชอบผูกบ<mask><mask>อดกรอบ\n",
      "\tนผั<mask>้วผมชอบผู้กบ<mask><mask>อดกรอบ\n",
      "\tนผั<mask>้วผมชอบผุกบ<mask><mask>อดกรอบ\n",
      "\tนผั<mask>้วผมชอบผิกบ<mask><mask>อดกรอบ\n",
      "\n",
      "Masked Input: \n",
      "\t<mask>้วผมชอบผ<mask>กบ<mask><mask>อดกรอบ เห็\n",
      "Labeled Input: \n",
      "\t<mask>้วผมชอบผ<mask>กบุ้<mask>อดกรอบ เห็\n",
      "Predictions: \n",
      "\t<mask>้วผมชอบผ<mask>กบ้<mask>อดกรอบ เห็\n",
      "\t<mask>้วผมชอบผ<mask>กบั<mask>อดกรอบ เห็\n",
      "\t<mask>้วผมชอบผ<mask>กบ่<mask>อดกรอบ เห็\n",
      "\t<mask>้วผมชอบผ<mask>กบุ้<mask>อดกรอบ เห็\n",
      "\t<mask>้วผมชอบผ<mask>กบุ๋<mask>อดกรอบ เห็\n",
      "\n",
      "Masked Input: \n",
      "\t้วผมชอบผ<mask>กบ<mask><mask>อดกรอบ เห็ดห\n",
      "Labeled Input: \n",
      "\t้วผมชอบผ<mask>กบ<mask>งทอดกรอบ เห็ดห\n",
      "Predictions: \n",
      "\t้วผมชอบผ<mask>กบ<mask>งทอดกรอบ เห็ดห\n",
      "\t้วผมชอบผ<mask>กบ<mask>านทอดกรอบ เห็ดห\n",
      "\t้วผมชอบผ<mask>กบ<mask>กทอดกรอบ เห็ดห\n",
      "\t้วผมชอบผ<mask>กบ<mask>ดทอดกรอบ เห็ดห\n",
      "\t้วผมชอบผ<mask>กบ<mask>นทอดกรอบ เห็ดห\n",
      "\n",
      "Masked Input: \n",
      "\tอดกรอบ เห็ดหอม<mask>ทอดมาก แต่ก\n",
      "Labeled Input: \n",
      "\tอดกรอบ เห็ดหอมสดทอดมาก แต่ก\n",
      "Predictions: \n",
      "\tอดกรอบ เห็ดหอมกรอบทอดมาก แต่ก\n",
      "\tอดกรอบ เห็ดหอมปากทอดมาก แต่ก\n",
      "\tอดกรอบ เห็ดหอม ชอบทอดมาก แต่ก\n",
      "\tอดกรอบ เห็ดหอมสดทอดมาก แต่ก\n",
      "\tอดกรอบ เห็ดหอมหวานทอดมาก แต่ก\n",
      "\n",
      "Masked Input: \n",
      "\t<mask>ทอดมาก แต่ก<mask>ไม่ได้<mask>\n",
      "Labeled Input: \n",
      "\t<mask>ทอดมาก แต่ก็ไม่ได้<mask>\n",
      "Predictions: \n",
      "\t<mask>ทอดมาก แต่ก็ไม่ได้<mask>\n",
      "\t<mask>ทอดมาก แต่ก้ไม่ได้<mask>\n",
      "\t<mask>ทอดมาก แต่กูไม่ได้<mask>\n",
      "\t<mask>ทอดมาก แต่ก่ไม่ได้<mask>\n",
      "\t<mask>ทอดมาก แต่กัไม่ได้<mask>\n",
      "\n",
      "Masked Input: \n",
      "\tก<mask>ไม่ได้<mask>ั่งเพราะว่าเธ\n",
      "Labeled Input: \n",
      "\tก<mask>ไม่ได้สั่งเพราะว่าเธ\n",
      "Predictions: \n",
      "\tก<mask>ไม่ได้สั่งเพราะว่าเธ\n",
      "\tก<mask>ไม่ได้อยากสั่งเพราะว่าเธ\n",
      "\tก<mask>ไม่ได้ชอบสั่งเพราะว่าเธ\n",
      "\tก<mask>ไม่ได้เคยสั่งเพราะว่าเธ\n",
      "\tก<mask>ไม่ได้ไปสั่งเพราะว่าเธ\n",
      "\n",
      "Masked Input: \n",
      "\tงเพราะว่าเธอไม่<mask>ินถึงเค้\n",
      "Labeled Input: \n",
      "\tงเพราะว่าเธอไม่กินถึงเค้\n",
      "Predictions: \n",
      "\tงเพราะว่าเธอไม่ชอบกินถึงเค้\n",
      "\tงเพราะว่าเธอไม่กินถึงเค้\n",
      "\tงเพราะว่าเธอไม่อยากกินถึงเค้\n",
      "\tงเพราะว่าเธอไม่ยอมกินถึงเค้\n",
      "\tงเพราะว่าเธอไม่เคยกินถึงเค้\n",
      "\n",
      "Masked Input: \n",
      "\tยังเกรงใจเธออย<mask>ดี<mask>่ะคร\n",
      "Labeled Input: \n",
      "\tยังเกรงใจเธออยู่ดี<mask>่ะคร\n",
      "Predictions: \n",
      "\tยังเกรงใจเธออยู่ดี<mask>่ะคร\n",
      "\tยังเกรงใจเธออยุ่ดี<mask>่ะคร\n",
      "\tยังเกรงใจเธออยู๋ดี<mask>่ะคร\n",
      "\tยังเกรงใจเธออยูดี<mask>่ะคร\n",
      "\tยังเกรงใจเธออย่ดี<mask>่ะคร\n",
      "\n",
      "Masked Input: \n",
      "\tรงใจเธออย<mask>ดี<mask>่ะครั<mask> ผมร\n",
      "Labeled Input: \n",
      "\tรงใจเธออย<mask>ดีอ่ะครั<mask> ผมร\n",
      "Predictions: \n",
      "\tรงใจเธออย<mask>ดีอ่ะครั<mask> ผมร\n",
      "\tรงใจเธออย<mask>ดีน่ะครั<mask> ผมร\n",
      "\tรงใจเธออย<mask>ดีล่ะครั<mask> ผมร\n",
      "\tรงใจเธออย<mask>ดีหล่ะครั<mask> ผมร\n",
      "\tรงใจเธออย<mask>ดีๆน่ะครั<mask> ผมร\n",
      "\n",
      "Masked Input: \n",
      "\tดี<mask>่ะครั<mask> ผมรู้สึกก\n",
      "Labeled Input: \n",
      "\tดี<mask>่ะครับ ผมรู้สึกก\n",
      "Predictions: \n",
      "\tดี<mask>่ะครับ ผมรู้สึกก\n",
      "\tดี<mask>่ะครับบ ผมรู้สึกก\n",
      "\tดี<mask>่ะครับผม ผมรู้สึกก\n",
      "\tดี<mask>่ะครับๆ ผมรู้สึกก\n",
      "\tดี<mask>่ะครับเพราะ ผมรู้สึกก\n",
      "\n",
      "Masked Input: \n",
      "\tมีความสุขเลย<mask>ีว<mask>ตผมขาด\n",
      "Labeled Input: \n",
      "\tมีความสุขเลยชีว<mask>ตผมขาด\n",
      "Predictions: \n",
      "\tมีความสุขเลย ชีว<mask>ตผมขาด\n",
      "\tมีความสุขเลยในชีว<mask>ตผมขาด\n",
      "\tมีความสุขเลยชีว<mask>ตผมขาด\n",
      "\tมีความสุขเลย ในชีว<mask>ตผมขาด\n",
      "\tมีความสุขเลย เพราะชีว<mask>ตผมขาด\n",
      "\n",
      "Masked Input: \n",
      "\tุขเลย<mask>ีว<mask>ตผมขาดรสเผ็\n",
      "Labeled Input: \n",
      "\tุขเลย<mask>ีวิตผมขาดรสเผ็\n",
      "Predictions: \n",
      "\tุขเลย<mask>ีวิตผมขาดรสเผ็\n",
      "\tุขเลย<mask>ีวีตผมขาดรสเผ็\n",
      "\tุขเลย<mask>ีวัตผมขาดรสเผ็\n",
      "\tุขเลย<mask>ีวืตผมขาดรสเผ็\n",
      "\tุขเลย<mask>ีว่ตผมขาดรสเผ็\n",
      "\n",
      "Masked Input: \n",
      "\tตผมขาดรสเผ็ดไป<mask>ือนจะขาดใจ<mask>\n",
      "Labeled Input: \n",
      "\tตผมขาดรสเผ็ดไปเหมือนจะขาดใจ<mask>\n",
      "Predictions: \n",
      "\tตผมขาดรสเผ็ดไปเหมือนจะขาดใจ<mask>\n",
      "\tตผมขาดรสเผ็ดไป เหมือนจะขาดใจ<mask>\n",
      "\tตผมขาดรสเผ็ดไปเยอะเหมือนจะขาดใจ<mask>\n",
      "\tตผมขาดรสเผ็ดไปหลายเดือนจะขาดใจ<mask>\n",
      "\tตผมขาดรสเผ็ดไปเราเหมือนจะขาดใจ<mask>\n",
      "\n",
      "Masked Input: \n",
      "\tดไป<mask>ือนจะขาดใจ<mask><mask>อนมันท�\n",
      "Labeled Input: \n",
      "\tดไป<mask>ือนจะขาดใจเหม<mask>อนมันท�\n",
      "Predictions: \n",
      "\tดไป<mask>ือนจะขาดใจเหม<mask>อนมันท�\n",
      "\tดไป<mask>ือนจะขาดใจ เหม<mask>อนมันท�\n",
      "\tดไป<mask>ือนจะขาดใจเราเหม<mask>อนมันท�\n",
      "\tดไป<mask>ือนจะขาดใจ เพ<mask>อนมันท�\n",
      "\tดไป<mask>ือนจะขาดใจเพ<mask>อนมันท�\n",
      "\n",
      "Masked Input: \n",
      "\t<mask>ือนจะขาดใจ<mask><mask>อนมันทำ\n",
      "Labeled Input: \n",
      "\t<mask>ือนจะขาดใจ<mask>ือนมันทำ\n",
      "Predictions: \n",
      "\t<mask>ือนจะขาดใจ<mask>ือนมันทำ\n",
      "\t<mask>ือนจะขาดใจ<mask>่อนมันทำ\n",
      "\t<mask>ือนจะขาดใจ<mask>ื่อนมันทำ\n",
      "\t<mask>ือนจะขาดใจ<mask>้อนมันทำ\n",
      "\t<mask>ือนจะขาดใจ<mask>สอนมันทำ\n",
      "\n",
      "Masked Input: \n",
      "\tขาดความสุขไปอย่<mask>ึงเลยอ่ะคร\n",
      "Labeled Input: \n",
      "\tขาดความสุขไปอย่างนึงเลยอ่ะคร\n",
      "Predictions: \n",
      "\tขาดความสุขไปอย่างนึงเลยอ่ะคร\n",
      "\tขาดความสุขไปอย่างหนึงเลยอ่ะคร\n",
      "\tขาดความสุขไปอย่างงึงเลยอ่ะคร\n",
      "\tขาดความสุขไปอย่วนนึงเลยอ่ะคร\n",
      "\tขาดความสุขไปอย่างตึงเลยอ่ะคร\n",
      "\n",
      "Masked Input: \n",
      "\tงเลยอ่ะครับ<mask>ิ่<mask>้าเราแต\n",
      "Labeled Input: \n",
      "\tงเลยอ่ะครับ ยิ่<mask>้าเราแต\n",
      "Predictions: \n",
      "\tงเลยอ่ะครับ ยิ่<mask>้าเราแต\n",
      "\tงเลยอ่ะครับ เพราะยิ่<mask>้าเราแต\n",
      "\tงเลยอ่ะครับ ผมยิ่<mask>้าเราแต\n",
      "\tงเลยอ่ะครับ ผมเพิ่<mask>้าเราแต\n",
      "\tงเลยอ่ะครับ เริ่<mask>้าเราแต\n",
      "\n",
      "Masked Input: \n",
      "\t่ะครับ<mask>ิ่<mask>้าเราแต่งงานก\n",
      "Labeled Input: \n",
      "\t่ะครับ<mask>ิ่งถ้าเราแต่งงานก\n",
      "Predictions: \n",
      "\t่ะครับ<mask>ิ่งถ้าเราแต่งงานก\n",
      "\t่ะครับ<mask>ิ่มถ้าเราแต่งงานก\n",
      "\t่ะครับ<mask>ิ่ถ้าเราแต่งงานก\n",
      "\t่ะครับ<mask>ิ่มเข้าเราแต่งงานก\n",
      "\t่ะครับ<mask>ิ่งเค้าเราแต่งงานก\n",
      "\n",
      "Masked Input: \n",
      "\tงงานกันแล้วผมก็<mask>้องมีปั\n",
      "Labeled Input: \n",
      "\tงงานกันแล้วผมก็อาจจะต้องมีปั\n",
      "Predictions: \n",
      "\tงงานกันแล้วผมก็ต้องมีปั\n",
      "\tงงานกันแล้วผมก็จะต้องมีปั\n",
      "\tงงานกันแล้วผมก็คงต้องมีปั\n",
      "\tงงานกันแล้วผมก็เลยต้องมีปั\n",
      "\tงงานกันแล้วผมก็อาจจะต้องมีปั\n",
      "\n",
      "Masked Input: \n",
      "\tมากขึ้น พอผมเห็<mask>ู่ที่ชอบ<mask>\n",
      "Labeled Input: \n",
      "\tมากขึ้น พอผมเห็นคู่ที่ชอบ<mask>\n",
      "Predictions: \n",
      "\tมากขึ้น พอผมเห็นคู่ที่ชอบ<mask>\n",
      "\tมากขึ้น พอผมเห็นอยู่ที่ชอบ<mask>\n",
      "\tมากขึ้น พอผมเห็นหมู่ที่ชอบ<mask>\n",
      "\tมากขึ้น พอผมเห็นปู่ที่ชอบ<mask>\n",
      "\tมากขึ้น พอผมเห็นคนนู่ที่ชอบ<mask>\n",
      "\n",
      "Masked Input: \n",
      "\t็<mask>ู่ที่ชอบ<mask>เหมือนๆกั</s>\n",
      "Labeled Input: \n",
      "\t็<mask>ู่ที่ชอบทานอาหารเหมือนๆกั</s>\n",
      "Predictions: \n",
      "\t็<mask>ู่ที่ชอบเขาเหมือนๆกั</s>\n",
      "\t็<mask>ู่ที่ชอบของผมเหมือนๆกั</s>\n",
      "\t็<mask>ู่ที่ชอบๆเหมือนๆกั</s>\n",
      "\t็<mask>ู่ที่ชอบผมเหมือนๆกั</s>\n",
      "\t็<mask>ู่ที่ชอบของเขาเหมือนๆกั</s>\n",
      "\n",
      "Total Input Tokens: torch.Size([510])\n",
      "Total Correct for Top 5: 55\n",
      "Total Mask: 57\n",
      "Percent Correct: 96.49%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"ใครเคยมีแฟนที่กินอาหารไม่ถูกปากกันแล้วรู้สึกเสียความสุขไปอย่างนึงบ้างมั้ยครับ  ก่อนอื่นผมต้องบอกก่อนเลยว่าคนเราจะเลือกกินอาหารแบบไหนชอบแบบไหนเป็นเรื่องของความชอบส่วนตัวนะครับทุกคนมีสิทธิในการเลือกของที่ชอบและไม่ชอบอยู่แล้ว แต่ผมรู้สึกว่าตอนนี้ผมกำลังประสบปัญหาที่ดูเหมือนจะเล็กแต่กลายเป็นว่ามันค่อนข้างใหญ่ ผมคบกับแฟนมา6ปีแล้วครับ ผมเป็นคนชอบกินอาหารญี่ปุ่นและปลาดิบแต่แฟนผมไม่กินปลาดิบเลย ผมอยากกินบุฟเฟ่เนื้อแต่แฟนผมก็ไม่กินเนื้อ เราเลยไม่ได้เข้าทานร้านบุฟเฟ่เนื้อและบุฟเฟ่อาหารญี่ปุ่นกันเพราะรู้สึกลัวแฟนผมทานไม่คุ้ม และเรื่องใหญ่เลยคือผมเป็นคนชอบทานอาหารรสจัดและรสเผ็ดมาก แต่แฟนผมทานเผ็ดไม่ได้เลยเวลาเราไปกินส้มตำกันก็จะสั่ง ส้มตำไม่ใส่พริก ต้มแซ่บไม่ใส่พริก ลาบไม่ใส่พริก ร้านกับข้าวอื่นๆก็เช่นกันแฟนผมจะไม่ชอบกินผักไม่ค่อยสั่งกับข้าวที่เป็นผักแล้วผมชอบผักบุ้งทอดกรอบ เห็ดหอมสดทอดมาก แต่ก็ไม่ได้สั่งเพราะว่าเธอไม่กินถึงเค้าจะบอกให้สั่งเลยๆก็เถอะแต่ผมก็ยังเกรงใจเธออยู่ดีอ่ะครับ ผมรู้สึกกินอาหารไม่มีความสุขเลยชีวิตผมขาดรสเผ็ดไปเหมือนจะขาดใจเหมือนมันทำให้ขาดความสุขไปอย่างนึงเลยอ่ะครับ ยิ่งถ้าเราแต่งงานกันแล้วผมก็อาจจะต้องมีปัญหาเรื่องนี้มากขึ้น พอผมเห็นคู่ที่ชอบทานอาหารเหมือนๆกันเห็นเค้ากินอาหารกันอย่างมีความสุขแล้วผมรู้สึกอิจฉามากๆเลย มีใครเคยมีปัญหาแบบผมมั้ยครับแล้วจะแก้ปัญหานี้ยังไงดีครับ\"\n",
    "tokenized_input, labels = _mask_input(text, tokenizer, mlm_probability=0.1)\n",
    "_predict_masks(tokenized_input, labels, tokenizer , k=5, verbose=True, verbose_length=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Tokenize on Pantip Sample อาการแบบนี้คือไรกัน?\n",
    "https://pantip.com/topic/40009518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Input: \n",
      "\tี้คือไรกั<mask>?  เขาคุ<mask>\n",
      "Labeled Input: \n",
      "\tี้คือไรกัน?  เขาคุ<mask>\n",
      "Predictions: \n",
      "\tี้คือไรกัน?  เขาคุ<mask>\n",
      "\tี้คือไรกับเรา?  เขาคุ<mask>\n",
      "\tี้คือไรกันคะ?  เขาคุ<mask>\n",
      "\tี้คือไรกันหรอ?  เขาคุ<mask>\n",
      "\tี้คือไรกันไหม?  เขาคุ<mask>\n",
      "\n",
      "Masked Input: \n",
      "\tั<mask>?  เขาคุ<mask>ับเรามา<mask>-\n",
      "Labeled Input: \n",
      "\tั<mask>?  เขาคุยกับเรามา<mask>-\n",
      "Predictions: \n",
      "\tั<mask>?  เขาคุยกับเรามา<mask>-\n",
      "\tั<mask>?  เขาคุยอะไรกับเรามา<mask>-\n",
      "\tั<mask>?  เขาคุยกลับเรามา<mask>-\n",
      "\tั<mask>?  เขาคุบกับเรามา<mask>-\n",
      "\tั<mask>?  เขาคุยครับเรามา<mask>-\n",
      "\n",
      "Masked Input: \n",
      "\t เขาคุ<mask>ับเรามา<mask>-6 เดื<mask>\n",
      "Labeled Input: \n",
      "\t เขาคุ<mask>ับเรามา 5-6 เดื<mask>\n",
      "Predictions: \n",
      "\t เขาคุ<mask>ับเรามา 5-6 เดื<mask>\n",
      "\t เขาคุ<mask>ับเรามา 3-6 เดื<mask>\n",
      "\t เขาคุ<mask>ับเรามา 4-6 เดื<mask>\n",
      "\t เขาคุ<mask>ับเรามา 2-6 เดื<mask>\n",
      "\t เขาคุ<mask>ับเรามา5-6 เดื<mask>\n",
      "\n",
      "Masked Input: \n",
      "\tามา<mask>-6 เดื<mask><mask>าตามจีบเข\n",
      "Labeled Input: \n",
      "\tามา<mask>-6 เดือน<mask>าตามจีบเข\n",
      "Predictions: \n",
      "\tามา<mask>-6 เดือน<mask>าตามจีบเข\n",
      "\tามา<mask>-6 เดือนเรา<mask>าตามจีบเข\n",
      "\tามา<mask>-6 เดือนเข<mask>าตามจีบเข\n",
      "\tามา<mask>-6 เดือนเร<mask>าตามจีบเข\n",
      "\tามา<mask>-6 เดือนกว<mask>าตามจีบเข\n",
      "\n",
      "Masked Input: \n",
      "\t<mask>-6 เดื<mask><mask>าตามจีบเขานะคะ\n",
      "Labeled Input: \n",
      "\t<mask>-6 เดื<mask> เราตามจีบเขานะคะ\n",
      "Predictions: \n",
      "\t<mask>-6 เดื<mask> เราตามจีบเขานะคะ\n",
      "\t<mask>-6 เดื<mask> เขาตามจีบเขานะคะ\n",
      "\t<mask>-6 เดื<mask>เราตามจีบเขานะคะ\n",
      "\t<mask>-6 เดื<mask> เขามาตามจีบเขานะคะ\n",
      "\t<mask>-6 เดื<mask> เพราะเราตามจีบเขานะคะ\n",
      "\n",
      "Masked Input: \n",
      "\t ก็คุยกั<mask><mask>ระยะเวลาเขาบอกว่\n",
      "Labeled Input: \n",
      "\t ก็คุยกันมา<mask>ระยะเวลาเขาบอกว่\n",
      "Predictions: \n",
      "\t ก็คุยกัน<mask>ระยะเวลาเขาบอกว่\n",
      "\t ก็คุยกันไป<mask>ระยะเวลาเขาบอกว่\n",
      "\t ก็คุยกันตลอด<mask>ระยะเวลาเขาบอกว่\n",
      "\t ก็คุยกันมาตลอด<mask>ระยะเวลาเขาบอกว่\n",
      "\t ก็คุยกันปกต<mask>ระยะเวลาเขาบอกว่\n",
      "\n",
      "Masked Input: \n",
      "\t็คุยกั<mask><mask>ระยะเวลาเขาบอกว่า\n",
      "Labeled Input: \n",
      "\t็คุยกั<mask> ในระยะเวลาเขาบอกว่า\n",
      "Predictions: \n",
      "\t็คุยกั<mask>าตลอดระยะเวลาเขาบอกว่า\n",
      "\t็คุยกั<mask> ตลอดระยะเวลาเขาบอกว่า\n",
      "\t็คุยกั<mask> ในระยะเวลาเขาบอกว่า\n",
      "\t็คุยกั<mask>ตลอดระยะเวลาเขาบอกว่า\n",
      "\t็คุยกั<mask>ในระยะเวลาเขาบอกว่า\n",
      "\n",
      "Masked Input: \n",
      "\t้าเราลด นน เพื่<mask>าได้<mask>ยอมเป\n",
      "Labeled Input: \n",
      "\t้าเราลด นน เพื่อเขาได้<mask>ยอมเป\n",
      "Predictions: \n",
      "\t้าเราลด นน เพื่อนเขาได้<mask>ยอมเป\n",
      "\t้าเราลด นน เพื่อเขาได้<mask>ยอมเป\n",
      "\t้าเราลด นน เพื่อนเราได้<mask>ยอมเป\n",
      "\t้าเราลด นน เพื่อนหาได้<mask>ยอมเป\n",
      "\t้าเราลด นน เพื่อนเรามาได้<mask>ยอมเป\n",
      "\n",
      "Masked Input: \n",
      "\t นน เพื่<mask>าได้<mask>ยอมเป็นแฟนเรา\n",
      "Labeled Input: \n",
      "\t นน เพื่<mask>าได้ เขาจะยอมเป็นแฟนเรา\n",
      "Predictions: \n",
      "\t นน เพื่<mask>าได้ เขาจะยอมเป็นแฟนเรา\n",
      "\t นน เพื่<mask>าได้เขาจะยอมเป็นแฟนเรา\n",
      "\t นน เพื่<mask>าได้ จะยอมเป็นแฟนเรา\n",
      "\t นน เพื่<mask>าได้จะยอมเป็นแฟนเรา\n",
      "\t นน เพื่<mask>าได้ เราจะยอมเป็นแฟนเรา\n",
      "\n",
      "Masked Input: \n",
      "\tเรา ตรรกะโง่<mask>นะคะ แต่ถามว่\n",
      "Labeled Input: \n",
      "\tเรา ตรรกะโง่มากนะคะ แต่ถามว่\n",
      "Predictions: \n",
      "\tเรา ตรรกะโง่ๆนะคะ แต่ถามว่\n",
      "\tเรา ตรรกะโง่ไปนะคะ แต่ถามว่\n",
      "\tเรา ตรรกะโง่มากๆนะคะ แต่ถามว่\n",
      "\tเรา ตรรกะโง่มากนะคะ แต่ถามว่\n",
      "\tเรา ตรรกะโง่เองนะคะ แต่ถามว่\n",
      "\n",
      "Masked Input: \n",
      "\t่ถามว่าทำ<mask>ั้ย ทำ\n",
      "Labeled Input: \n",
      "\t่ถามว่าทำมั้ย ทำ\n",
      "Predictions: \n",
      "\t่ถามว่าทำมั้ย ทำ\n",
      "\t่ถามว่าทำชอบมั้ย ทำ\n",
      "\t่ถามว่าทำเคยมั้ย ทำ\n",
      "\t่ถามว่าทำเรามั้ย ทำ\n",
      "\t่ถามว่าทำบอกมั้ย ทำ\n",
      "\n",
      "Masked Input: \n",
      "\t พอไปรู้ว่าเขาค<mask><mask>ับเพื่อน\n",
      "Labeled Input: \n",
      "\t พอไปรู้ว่าเขาคุ<mask>ับเพื่อน\n",
      "Predictions: \n",
      "\t พอไปรู้ว่าเขาคุ<mask>ับเพื่อน\n",
      "\t พอไปรู้ว่าเขาคิ<mask>ับเพื่อน\n",
      "\t พอไปรู้ว่าเขาคู่<mask>ับเพื่อน\n",
      "\t พอไปรู้ว่าเขาคื<mask>ับเพื่อน\n",
      "\t พอไปรู้ว่าเขาค่<mask>ับเพื่อน\n",
      "\n",
      "Masked Input: \n",
      "\tรู้ว่าเขาค<mask><mask>ับเพื่อน เพ\n",
      "Labeled Input: \n",
      "\tรู้ว่าเขาค<mask>ยกับเพื่อน เพ\n",
      "Predictions: \n",
      "\tรู้ว่าเขาค<mask>ยกับเพื่อน เพ\n",
      "\tรู้ว่าเขาค<mask>ยอะไรกับเพื่อน เพ\n",
      "\tรู้ว่าเขาค<mask>ดอะไรกับเพื่อน เพ\n",
      "\tรู้ว่าเขาค<mask>ดกับเพื่อน เพ\n",
      "\tรู้ว่าเขาค<mask>กับเพื่อน เพ\n",
      "\n",
      "Masked Input: \n",
      "\tา รู้สึกย<mask>งไงกับเรา เขาตอบ\n",
      "Labeled Input: \n",
      "\tา รู้สึกยังไงกับเรา เขาตอบ\n",
      "Predictions: \n",
      "\tา รู้สึกยังไงกับเรา เขาตอบ\n",
      "\tา รู้สึกยุ่งไงกับเรา เขาตอบ\n",
      "\tา รู้สึกยํงไงกับเรา เขาตอบ\n",
      "\tา รู้สึกยิงไงกับเรา เขาตอบ\n",
      "\tา รู้สึกยั่งไงกับเรา เขาตอบ\n",
      "\n",
      "Masked Input: \n",
      "\t่า เขาว่าเขาควร<mask>ู่<mask>ี<mask><mask>\n",
      "Labeled Input: \n",
      "\t่า เขาว่าเขาควรอยู่<mask>ี<mask><mask>\n",
      "Predictions: \n",
      "\t่า เขาว่าเขาควรอยู่<mask>ี<mask><mask>\n",
      "\t่า เขาว่าเขาควรจะอยู่<mask>ี<mask><mask>\n",
      "\t่า เขาว่าเขาควรไปอยู่<mask>ี<mask><mask>\n",
      "\t่า เขาว่าเขาควรมาอยู่<mask>ี<mask><mask>\n",
      "\t่า เขาว่าเขาควร อยู่<mask>ี<mask><mask>\n",
      "\n",
      "Masked Input: \n",
      "\t เขาว่าเขาควร<mask>ู่<mask>ี<mask><mask>ังไม\n",
      "Labeled Input: \n",
      "\t เขาว่าเขาควร<mask>ู่คนเดี<mask><mask>ังไม\n",
      "Predictions: \n",
      "\t เขาว่าเขาควร<mask>ู่คนเดี<mask><mask>ังไม\n",
      "\t เขาว่าเขาควร<mask>ู่ดี<mask><mask>ังไม\n",
      "\t เขาว่าเขาควร<mask>ู่อี<mask><mask>ังไม\n",
      "\t เขาว่าเขาควร<mask>ู่ปี<mask><mask>ังไม\n",
      "\t เขาว่าเขาควร<mask>ู่จี<mask><mask>ังไม\n",
      "\n",
      "Masked Input: \n",
      "\tาเขาควร<mask>ู่<mask>ี<mask><mask>ังไม่พร\n",
      "Labeled Input: \n",
      "\tาเขาควร<mask>ู่<mask>ียว<mask>ังไม่พร\n",
      "Predictions: \n",
      "\tาเขาควร<mask>ู่<mask>ียว<mask>ังไม่พร\n",
      "\tาเขาควร<mask>ู่<mask>ีบเรา<mask>ังไม่พร\n",
      "\tาเขาควร<mask>ู่<mask>ีไหม<mask>ังไม่พร\n",
      "\tาเขาควร<mask>ู่<mask>ีบเขา<mask>ังไม่พร\n",
      "\tาเขาควร<mask>ู่<mask>ีๆ<mask>ังไม่พร\n",
      "\n",
      "Masked Input: \n",
      "\tาควร<mask>ู่<mask>ี<mask><mask>ังไม่พร้\n",
      "Labeled Input: \n",
      "\tาควร<mask>ู่<mask>ี<mask> ยังไม่พร้\n",
      "Predictions: \n",
      "\tาควร<mask>ู่<mask>ี<mask> เรายังไม่พร้\n",
      "\tาควร<mask>ู่<mask>ี<mask> ยังไม่พร้\n",
      "\tาควร<mask>ู่<mask>ี<mask> เพราะยังไม่พร้\n",
      "\tาควร<mask>ู่<mask>ี<mask> เขายังไม่พร้\n",
      "\tาควร<mask>ู่<mask>ี<mask>เรายังไม่พร้\n",
      "\n",
      "Masked Input: \n",
      "\tักใคร จนตอนนี้เราเริ่<mask>ู้<mask>ึกว่\n",
      "Labeled Input: \n",
      "\tักใคร จนตอนนี้เราเริ่มรู้<mask>ึกว่\n",
      "Predictions: \n",
      "\tักใคร จนตอนนี้เราเริ่มรู้<mask>ึกว่\n",
      "\tักใคร จนตอนนี้เราเริ่รู้<mask>ึกว่\n",
      "\tักใคร จนตอนนี้เราเริ่มความรู้<mask>ึกว่\n",
      "\tักใคร จนตอนนี้เราเริ่มสู้<mask>ึกว่\n",
      "\tักใคร จนตอนนี้เราเริ่มหู้<mask>ึกว่\n",
      "\n",
      "Masked Input: \n",
      "\t จนตอนนี้เราเริ่<mask>ู้<mask>ึกว่า ท\n",
      "Labeled Input: \n",
      "\t จนตอนนี้เราเริ่<mask>ู้สึกว่า ท\n",
      "Predictions: \n",
      "\t จนตอนนี้เราเริ่<mask>ู้สึกว่า ท\n",
      "\t จนตอนนี้เราเริ่<mask>ู้ลึกว่า ท\n",
      "\t จนตอนนี้เราเริ่<mask>ู้ สึกว่า ท\n",
      "\t จนตอนนี้เราเริ่<mask>ู้นึกว่า ท\n",
      "\t จนตอนนี้เราเริ่<mask>ู้ตึกว่า ท\n",
      "\n",
      "Masked Input: \n",
      "\tำไมเราต้องท<mask>�ขนาดนั้น ถ\n",
      "Labeled Input: \n",
      "\tำไมเราต้องทำขนาดนั้น ถ\n",
      "Predictions: \n",
      "\tำไมเราต้องทำขนาดนั้น ถ\n",
      "\tำไมเราต้องทราำขนาดนั้น ถ\n",
      "\tำไมเราต้องทเำขนาดนั้น ถ\n",
      "\tำไมเราต้องทาำขนาดนั้น ถ\n",
      "\tำไมเราต้องท 😳ขนาดนั้น ถ\n",
      "\n",
      "Masked Input: \n",
      "\tขนาดนั้น ถ้าเข<mask>ัก รักท\n",
      "Labeled Input: \n",
      "\tขนาดนั้น ถ้าเขาจะรัก รักท\n",
      "Predictions: \n",
      "\tขนาดนั้น ถ้าเขารัก รักท\n",
      "\tขนาดนั้น ถ้าเขาจะรัก รักท\n",
      "\tขนาดนั้น ถ้าเขาอยากรัก รักท\n",
      "\tขนาดนั้น ถ้าเขาเรารัก รักท\n",
      "\tขนาดนั้น ถ้าเขาเขารัก รักท\n",
      "\n",
      "Masked Input: \n",
      "\t่ได้หรอ หลั<mask>เลยเริ่<mask>สนใจเขาน\n",
      "Labeled Input: \n",
      "\t่ได้หรอ หลังๆเลยเริ่<mask>สนใจเขาน\n",
      "Predictions: \n",
      "\t่ได้หรอ หลังๆเลยเริ่<mask>สนใจเขาน\n",
      "\t่ได้หรอ หลังมาเลยเริ่<mask>สนใจเขาน\n",
      "\t่ได้หรอ หลักๆเลยเริ่<mask>สนใจเขาน\n",
      "\t่ได้หรอ หลังเราเลยเริ่<mask>สนใจเขาน\n",
      "\t่ได้หรอ หลับไปเลยเริ่<mask>สนใจเขาน\n",
      "\n",
      "Masked Input: \n",
      "\tหรอ หลั<mask>เลยเริ่<mask>สนใจเขาน้อยลง แต\n",
      "Labeled Input: \n",
      "\tหรอ หลั<mask>เลยเริ่มสนใจเขาน้อยลง แต\n",
      "Predictions: \n",
      "\tหรอ หลั<mask>เลยเริ่มสนใจเขาน้อยลง แต\n",
      "\tหรอ หลั<mask>เลยเริ่มไปสนใจเขาน้อยลง แต\n",
      "\tหรอ หลั<mask>เลยเริ่มจะสนใจเขาน้อยลง แต\n",
      "\tหรอ หลั<mask>เลยเริ่มความสนใจเขาน้อยลง แต\n",
      "\tหรอ หลั<mask>เลยเริ่มหายสนใจเขาน้อยลง แต\n",
      "\n",
      "Masked Input: \n",
      "\tแกล้งเงียบไป ไม<mask>ทักไปครึ่\n",
      "Labeled Input: \n",
      "\tแกล้งเงียบไป ไม่ทักไปครึ่\n",
      "Predictions: \n",
      "\tแกล้งเงียบไป ไม่ทักไปครึ่\n",
      "\tแกล้งเงียบไป ไม้ทักไปครึ่\n",
      "\tแกล้งเงียบไป ไม่...ทักไปครึ่\n",
      "\tแกล้งเงียบไป ไม็ทักไปครึ่\n",
      "\tแกล้งเงียบไป ไม่)ทักไปครึ่\n",
      "\n",
      "Masked Input: \n",
      "\tกไปครึ่งวัน<mask>ิเราจะมีการมอน\n",
      "Labeled Input: \n",
      "\tกไปครึ่งวัน ปกติเราจะมีการมอน\n",
      "Predictions: \n",
      "\tกไปครึ่งวัน ปกติเราจะมีการมอน\n",
      "\tกไปครึ่งวัน เพราะปกติเราจะมีการมอน\n",
      "\tกไปครึ่งวัน โดยปกติเราจะมีการมอน\n",
      "\tกไปครึ่งวันปกติเราจะมีการมอน\n",
      "\tกไปครึ่งวัน สมมติเราจะมีการมอน\n",
      "\n",
      "Masked Input: \n",
      "\tเราจะมีการมอนิ่งก<mask>นตอนเช้าค่\n",
      "Labeled Input: \n",
      "\tเราจะมีการมอนิ่งกันตอนเช้าค่\n",
      "Predictions: \n",
      "\tเราจะมีการมอนิ่งกันตอนเช้าค่\n",
      "\tเราจะมีการมอนิ่งกินตอนเช้าค่\n",
      "\tเราจะมีการมอนิ่งกั้นตอนเช้าค่\n",
      "\tเราจะมีการมอนิ่งก้นตอนเช้าค่\n",
      "\tเราจะมีการมอนิ่งก่นตอนเช้าค่\n",
      "\n",
      "Masked Input: \n",
      "\tักไป เขาทำงาน<mask>็จ ถึงเวล\n",
      "Labeled Input: \n",
      "\tักไป เขาทำงานเสร็จ ถึงเวล\n",
      "Predictions: \n",
      "\tักไป เขาทำงานเสร็จ ถึงเวล\n",
      "\tักไป เขาทำงานเสด็จ ถึงเวล\n",
      "\tักไป เขาทำงาน เสร็จ ถึงเวล\n",
      "\tักไป เขาทำงานเท็จ ถึงเวล\n",
      "\tักไป เขาทำงานเร็จ ถึงเวล\n",
      "\n",
      "Masked Input: \n",
      "\tกมาว่า กิ<mask>้าวกัน เราก\n",
      "Labeled Input: \n",
      "\tกมาว่า กินข้าวกัน เราก\n",
      "Predictions: \n",
      "\tกมาว่า กินข้าวกัน เราก\n",
      "\tกมาว่า กิบข้าวกัน เราก\n",
      "\tกมาว่า กินมะพร้าวกัน เราก\n",
      "\tกมาว่า กิงข้าวกัน เราก\n",
      "\tกมาว่า กิานข้าวกัน เราก\n",
      "\n",
      "Masked Input: \n",
      "\tาวกัน เราก็ย<mask><mask> งง ก็ค\n",
      "Labeled Input: \n",
      "\tาวกัน เราก็ยิ่<mask> งง ก็ค\n",
      "Predictions: \n",
      "\tาวกัน เราก็ยั<mask> งง ก็ค\n",
      "\tาวกัน เราก็ยิ้<mask> งง ก็ค\n",
      "\tาวกัน เราก็ยิ่<mask> งง ก็ค\n",
      "\tาวกัน เราก็ยื<mask> งง ก็ค\n",
      "\tาวกัน เราก็ย้ํ<mask> งง ก็ค\n",
      "\n",
      "Masked Input: \n",
      "\tัน เราก็ย<mask><mask> งง ก็คิ\n",
      "Labeled Input: \n",
      "\tัน เราก็ย<mask>ง งง ก็คิ\n",
      "Predictions: \n",
      "\tัน เราก็ย<mask>ง งง ก็คิ\n",
      "\tัน เราก็ย<mask>ม งง ก็คิ\n",
      "\tัน เราก็ย<mask>น งง ก็คิ\n",
      "\tัน เราก็ย<mask>มแบบ งง ก็คิ\n",
      "\tัน เราก็ย<mask>มๆ งง ก็คิ\n",
      "\n",
      "Masked Input: \n",
      "\tินหับการคุยก<mask><mask>ุกว<mask>น\n",
      "Labeled Input: \n",
      "\tินหับการคุยกั<mask>ุกว<mask>น\n",
      "Predictions: \n",
      "\tินหับการคุยกั<mask>ุกว<mask>น\n",
      "\tินหับการคุยก่<mask>ุกว<mask>น\n",
      "\tินหับการคุยก็<mask>ุกว<mask>น\n",
      "\tินหับการคุยกะเข<mask>ุกว<mask>น\n",
      "\tินหับการคุยกิ<mask>ุกว<mask>น\n",
      "\n",
      "Masked Input: \n",
      "\tนหับการคุยก<mask><mask>ุกว<mask>นเฉยๆ\n",
      "Labeled Input: \n",
      "\tนหับการคุยก<mask>บเราทุกว<mask>นเฉยๆ\n",
      "Predictions: \n",
      "\tนหับการคุยก<mask>นทุกว<mask>นเฉยๆ\n",
      "\tนหับการคุยก<mask>บเราทุกว<mask>นเฉยๆ\n",
      "\tนหับการคุยก<mask>นเราทุกว<mask>นเฉยๆ\n",
      "\tนหับการคุยก<mask>นแทบทุกว<mask>นเฉยๆ\n",
      "\tนหับการคุยก<mask>บแฟนทุกว<mask>นเฉยๆ\n",
      "\n",
      "Masked Input: \n",
      "\tุยก<mask><mask>ุกว<mask>นเฉยๆ นี่เลยไม\n",
      "Labeled Input: \n",
      "\tุยก<mask><mask>ุกวันเฉยๆ นี่เลยไม\n",
      "Predictions: \n",
      "\tุยก<mask><mask>ุกวันเฉยๆ นี่เลยไม\n",
      "\tุยก<mask><mask>ุกวืนเฉยๆ นี่เลยไม\n",
      "\tุยก<mask><mask>ุกวั้นเฉยๆ นี่เลยไม\n",
      "\tุยก<mask><mask>ุกวินเฉยๆ นี่เลยไม\n",
      "\tุยก<mask><mask>ุกว่นเฉยๆ นี่เลยไม\n",
      "\n",
      "Masked Input: \n",
      "\t<mask>นเฉยๆ นี่เลยไม<mask>ได้สนใจในส่\n",
      "Labeled Input: \n",
      "\t<mask>นเฉยๆ นี่เลยไม่ได้สนใจในส่\n",
      "Predictions: \n",
      "\t<mask>นเฉยๆ นี่เลยไม่ได้สนใจในส่\n",
      "\t<mask>นเฉยๆ นี่เลยไม้ได้สนใจในส่\n",
      "\t<mask>นเฉยๆ นี่เลยไมืได้สนใจในส่\n",
      "\t<mask>นเฉยๆ นี่เลยไม็ได้สนใจในส่\n",
      "\t<mask>นเฉยๆ นี่เลยไมี่ได้สนใจในส่\n",
      "\n",
      "Masked Input: \n",
      "\tน เราก็ตอบตามปกติ<mask>ื่อคืนมี\n",
      "Labeled Input: \n",
      "\tน เราก็ตอบตามปกติ จนเมื่อคืนมี\n",
      "Predictions: \n",
      "\tน เราก็ตอบตามปกติ เมื่อคืนมี\n",
      "\tน เราก็ตอบตามปกติ จนเมื่อคืนมี\n",
      "\tน เราก็ตอบตามปกติเมื่อคืนมี\n",
      "\tน เราก็ตอบตามปกติ และเมื่อคืนมี\n",
      "\tน เราก็ตอบตามปกติ เพราะเมื่อคืนมี\n",
      "\n",
      "Masked Input: \n",
      "\tไปส่งเราที่บ้<mask> เราก็เลยเล่าให\n",
      "Labeled Input: \n",
      "\tไปส่งเราที่บ้าน เราก็เลยเล่าให\n",
      "Predictions: \n",
      "\tไปส่งเราที่บ้าน เราก็เลยเล่าให\n",
      "\tไปส่งเราที่บ้านเขา เราก็เลยเล่าให\n",
      "\tไปส่งเราที่บ้านเรา เราก็เลยเล่าให\n",
      "\tไปส่งเราที่บ้านนะ เราก็เลยเล่าให\n",
      "\tไปส่งเราที่บ้านเลย เราก็เลยเล่าให\n",
      "\n",
      "Masked Input: \n",
      "\t<mask> เราก็เลยเล่าให<mask><mask>าฟ<mask>งว่\n",
      "Labeled Input: \n",
      "\t<mask> เราก็เลยเล่าให้<mask>าฟ<mask>งว่\n",
      "Predictions: \n",
      "\t<mask> เราก็เลยเล่าให้<mask>าฟ<mask>งว่\n",
      "\t<mask> เราก็เลยเล่าให่<mask>าฟ<mask>งว่\n",
      "\t<mask> เราก็เลยเล่าใหั<mask>าฟ<mask>งว่\n",
      "\t<mask> เราก็เลยเล่าใหร<mask>าฟ<mask>งว่\n",
      "\t<mask> เราก็เลยเล่าใหล<mask>าฟ<mask>งว่\n",
      "\n",
      "Masked Input: \n",
      "\t เราก็เลยเล่าให<mask><mask>าฟ<mask>งว่า\n",
      "Labeled Input: \n",
      "\t เราก็เลยเล่าให<mask>เขาฟ<mask>งว่า\n",
      "Predictions: \n",
      "\t เราก็เลยเล่าให<mask>เขาฟ<mask>งว่า\n",
      "\t เราก็เลยเล่าให<mask>เขาเขาฟ<mask>งว่า\n",
      "\t เราก็เลยเล่าให<mask> เขาฟ<mask>งว่า\n",
      "\t เราก็เลยเล่าให<mask>เราฟ<mask>งว่า\n",
      "\t เราก็เลยเล่าให<mask>เขามาฟ<mask>งว่า\n",
      "\n",
      "Masked Input: \n",
      "\tเลยเล่าให<mask><mask>าฟ<mask>งว่า ให้\n",
      "Labeled Input: \n",
      "\tเลยเล่าให<mask><mask>าฟังว่า ให้\n",
      "Predictions: \n",
      "\tเลยเล่าให<mask><mask>าฟังว่า ให้\n",
      "\tเลยเล่าให<mask><mask>าฟึ้งว่า ให้\n",
      "\tเลยเล่าให<mask><mask>าฟึ่งว่า ให้\n",
      "\tเลยเล่าให<mask><mask>าฟุ้งว่า ให้\n",
      "\tเลยเล่าให<mask><mask>าฟุงว่า ให้\n",
      "\n",
      "Masked Input: \n",
      "\t่า ให้ไลน์<mask> ให้<mask>าไปส่\n",
      "Labeled Input: \n",
      "\t่า ให้ไลน์ไป ให้<mask>าไปส่\n",
      "Predictions: \n",
      "\t่า ให้ไลน์ไป ให้<mask>าไปส่\n",
      "\t่า ให้ไลน์มา ให้<mask>าไปส่\n",
      "\t่า ให้ไลน์เรา ให้<mask>าไปส่\n",
      "\t่า ให้ไลน์ไปหา ให้<mask>าไปส่\n",
      "\t่า ให้ไลน์นะ ให้<mask>าไปส่\n",
      "\n",
      "Masked Input: \n",
      "\t้ไลน์<mask> ให้<mask>าไปส่งอยู่แต\n",
      "Labeled Input: \n",
      "\t้ไลน์<mask> ให้เขาไปส่งอยู่แต\n",
      "Predictions: \n",
      "\t้ไลน์<mask> ให้เขาไปส่งอยู่แต\n",
      "\t้ไลน์<mask> ให้เวลาไปส่งอยู่แต\n",
      "\t้ไลน์<mask> ให้เราเขาไปส่งอยู่แต\n",
      "\t้ไลน์<mask> ให้เวลาเขาไปส่งอยู่แต\n",
      "\t้ไลน์<mask> ให้พาไปส่งอยู่แต\n",
      "\n",
      "Masked Input: \n",
      "\t<mask>าไปส่งอยู่แต<mask>ไม<mask>่ด้\n",
      "Labeled Input: \n",
      "\t<mask>าไปส่งอยู่แต่ไม<mask>่ด้\n",
      "Predictions: \n",
      "\t<mask>าไปส่งอยู่แต่ไม<mask>่ด้\n",
      "\t<mask>าไปส่งอยู่แต่...ไม<mask>่ด้\n",
      "\t<mask>าไปส่งอยู่แต้ไม<mask>่ด้\n",
      "\t<mask>าไปส่งอยู่แต่..ไม<mask>่ด้\n",
      "\t<mask>าไปส่งอยู่แต่!ไม<mask>่ด้\n",
      "\n",
      "Masked Input: \n",
      "\t่งอยู่แต<mask>ไม<mask>่ด้นั่\n",
      "Labeled Input: \n",
      "\t่งอยู่แต<mask>ไมไ่ด้นั่\n",
      "Predictions: \n",
      "\t่งอยู่แต<mask>ไมไ่ด้นั่\n",
      "\t่งอยู่แต<mask>ไม่่ด้นั่\n",
      "\t่งอยู่แต<mask>ไม ไม่ด้นั่\n",
      "\t่งอยู่แต<mask>ไมไม่ด้นั่\n",
      "\t่งอยู่แต<mask>ไม เราไม่ด้นั่\n",
      "\n",
      "Masked Input: \n",
      "\t่ด้นั่งรถ<mask>ันเดียวกั\n",
      "Labeled Input: \n",
      "\t่ด้นั่งรถคันเดียวกั\n",
      "Predictions: \n",
      "\t่ด้นั่งรถคันเดียวกั\n",
      "\t่ด้นั่งรถมาคันเดียวกั\n",
      "\t่ด้นั่งรถเขาคันเดียวกั\n",
      "\t่ด้นั่งรถไปคันเดียวกั\n",
      "\t่ด้นั่งรถ คันเดียวกั\n",
      "\n",
      "Masked Input: \n",
      "\tบของเรา คนที่มาจี<mask>เขาก็ขับค\n",
      "Labeled Input: \n",
      "\tบของเรา คนที่มาจีบเราเขาก็ขับค\n",
      "Predictions: \n",
      "\tบของเรา คนที่มาจีบเราเขาก็ขับค\n",
      "\tบของเรา คนที่มาจีบเขาก็ขับค\n",
      "\tบของเรา คนที่มาจีบแรกเขาก็ขับค\n",
      "\tบของเรา คนที่มาจีบผมเขาก็ขับค\n",
      "\tบของเรา คนที่มาจีบของเขาก็ขับค\n",
      "\n",
      "Masked Input: \n",
      "\tอนิ่ง ก็ถาม<mask>ื่องเมื่อคื\n",
      "Labeled Input: \n",
      "\tอนิ่ง ก็ถามเราเรื่องเมื่อคื\n",
      "Predictions: \n",
      "\tอนิ่ง ก็ถามเรื่องเมื่อคื\n",
      "\tอนิ่ง ก็ถามเราเรื่องเมื่อคื\n",
      "\tอนิ่ง ก็ถาม เรื่องเมื่อคื\n",
      "\tอนิ่ง ก็ถามเขาเรื่องเมื่อคื\n",
      "\tอนิ่ง ก็ถามถามเรื่องเมื่อคื\n",
      "\n",
      "Masked Input: \n",
      "\tงานที่กลับดึ<mask>ไม่<mask><mask>ท\n",
      "Labeled Input: \n",
      "\tงานที่กลับดึกมากๆไม่<mask><mask>ท\n",
      "Predictions: \n",
      "\tงานที่กลับดึกๆไม่<mask><mask>ท\n",
      "\tงานที่กลับดึกมากไม่<mask><mask>ท\n",
      "\tงานที่กลับดึกมาไม่<mask><mask>ท\n",
      "\tงานที่กลับดึกไปไม่<mask><mask>ท\n",
      "\tงานที่กลับดึกเพราะไม่<mask><mask>ท\n",
      "\n",
      "Masked Input: \n",
      "\tับดึ<mask>ไม่<mask><mask>ทั<mask>บอก\n",
      "Labeled Input: \n",
      "\tับดึ<mask>ไม่ได<mask>ทั<mask>บอก\n",
      "Predictions: \n",
      "\tับดึ<mask>ไม่ได<mask>ทั<mask>บอก\n",
      "\tับดึ<mask>ไม่ร<mask>ทั<mask>บอก\n",
      "\tับดึ<mask>ไม่ม<mask>ทั<mask>บอก\n",
      "\tับดึ<mask>ไม่ให<mask>ทั<mask>บอก\n",
      "\tับดึ<mask>ไม่ด<mask>ทั<mask>บอก\n",
      "\n",
      "Masked Input: \n",
      "\tบดึ<mask>ไม่<mask><mask>ทั<mask>บอกเขา\n",
      "Labeled Input: \n",
      "\tบดึ<mask>ไม่<mask>้ทั<mask>บอกเขา\n",
      "Predictions: \n",
      "\tบดึ<mask>ไม่<mask>้ทั<mask>บอกเขา\n",
      "\tบดึ<mask>ไม่<mask>่ทั<mask>บอกเขา\n",
      "\tบดึ<mask>ไม่<mask>็ทั<mask>บอกเขา\n",
      "\tบดึ<mask>ไม่<mask>ีทั<mask>บอกเขา\n",
      "\tบดึ<mask>ไม่<mask>ู้ทั<mask>บอกเขา\n",
      "\n",
      "Masked Input: \n",
      "\tไม่<mask><mask>ทั<mask>บอกเขาไว<mask><mask>\n",
      "Labeled Input: \n",
      "\tไม่<mask><mask>ทักไปบอกเขาไว<mask><mask>\n",
      "Predictions: \n",
      "\tไม่<mask><mask>ทักไปบอกเขาไว<mask><mask>\n",
      "\tไม่<mask><mask>ทักมาบอกเขาไว<mask><mask>\n",
      "\tไม่<mask><mask>ทักบอกเขาไว<mask><mask>\n",
      "\tไม่<mask><mask>ทักเลยบอกเขาไว<mask><mask>\n",
      "\tไม่<mask><mask>ทักแชทบอกเขาไว<mask><mask>\n",
      "\n",
      "Masked Input: \n",
      "\tทั<mask>บอกเขาไว<mask><mask>่า ถึ\n",
      "Labeled Input: \n",
      "\tทั<mask>บอกเขาไว้<mask>่า ถึ\n",
      "Predictions: \n",
      "\tทั<mask>บอกเขาไว้<mask>่า ถึ\n",
      "\tทั<mask>บอกเขาไวๆ<mask>่า ถึ\n",
      "\tทั<mask>บอกเขาไว่<mask>่า ถึ\n",
      "\tทั<mask>บอกเขาไวมาก<mask>่า ถึ\n",
      "\tทั<mask>บอกเขาไวุ<mask>่า ถึ\n",
      "\n",
      "Masked Input: \n",
      "\tั<mask>บอกเขาไว<mask><mask>่า ถึงบ\n",
      "Labeled Input: \n",
      "\tั<mask>บอกเขาไว<mask>ว่า ถึงบ\n",
      "Predictions: \n",
      "\tั<mask>บอกเขาไว<mask>ว่า ถึงบ\n",
      "\tั<mask>บอกเขาไว<mask>เลยว่า ถึงบ\n",
      "\tั<mask>บอกเขาไว<mask> ว่า ถึงบ\n",
      "\tั<mask>บอกเขาไว<mask>ไหมว่า ถึงบ\n",
      "\tั<mask>บอกเขาไว<mask>เสมอว่า ถึงบ\n",
      "\n",
      "Masked Input: \n",
      "\tไปทั้งคืนเลย เขาก<mask>ถามเรื่องเมื่อค\n",
      "Labeled Input: \n",
      "\tไปทั้งคืนเลย เขาก็ถามเรื่องเมื่อค\n",
      "Predictions: \n",
      "\tไปทั้งคืนเลย เขาก็ถามเรื่องเมื่อค\n",
      "\tไปทั้งคืนเลย เขาก้ถามเรื่องเมื่อค\n",
      "\tไปทั้งคืนเลย เขากะถามเรื่องเมื่อค\n",
      "\tไปทั้งคืนเลย เขาก่ถามเรื่องเมื่อค\n",
      "\tไปทั้งคืนเลย เขากดถามเรื่องเมื่อค\n",
      "\n",
      "Masked Input: \n",
      "\tองเมื่อคืนว่<mask> หนุ่มไปส่\n",
      "Labeled Input: \n",
      "\tองเมื่อคืนว่า หนุ่มไปส่\n",
      "Predictions: \n",
      "\tองเมื่อคืนว่า หนุ่มไปส่\n",
      "\tองเมื่อคืนว่ะ หนุ่มไปส่\n",
      "\tองเมื่อคืนว่าอะไร หนุ่มไปส่\n",
      "\tองเมื่อคืนว่าเรา หนุ่มไปส่\n",
      "\tองเมื่อคืนว่าไหม หนุ่มไปส่\n",
      "\n",
      "Masked Input: \n",
      "\tนไงบ้าง ถามแต่<mask>ื่องของผู้ชายท\n",
      "Labeled Input: \n",
      "\tนไงบ้าง ถามแต่เรื่องของผู้ชายท\n",
      "Predictions: \n",
      "\tนไงบ้าง ถามแต่เรื่องของผู้ชายท\n",
      "\tนไงบ้าง ถามแต่ในเรื่องของผู้ชายท\n",
      "\tนไงบ้าง ถามแต่ถามเรื่องของผู้ชายท\n",
      "\tนไงบ้าง ถามแต่ เรื่องของผู้ชายท\n",
      "\tนไงบ้าง ถามแต่บางเรื่องของผู้ชายท\n",
      "\n",
      "Masked Input: \n",
      "\tงวัน จนเราเปลี่<mask>ื่องก็ย</s>\n",
      "Labeled Input: \n",
      "\tงวัน จนเราเปลี่ยนเรื่องก็ย</s>\n",
      "Predictions: \n",
      "\tงวัน จนเราเปลี่ยนเรื่องก็ย</s>\n",
      "\tงวัน จนเราเปลี่ยนเครื่องก็ย</s>\n",
      "\tงวัน จนเราเปลี่ยวเรื่องก็ย</s>\n",
      "\tงวัน จนเราเปลี่ยเรื่องก็ย</s>\n",
      "\tงวัน จนเราเปลี่ยนหื่องก็ย</s>\n",
      "\n",
      "Total Input Tokens: torch.Size([510])\n",
      "Total Correct for Top 5: 55\n",
      "Total Mask: 57\n",
      "Percent Correct: 96.49%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"อาการแบบนี้คือไรกัน?  เขาคุยกับเรามา 5-6 เดือน เราตามจีบเขานะคะ ก็คุยกันมา ในระยะเวลาเขาบอกว่า ถ้าเราลด นน เพื่อเขาได้ เขาจะยอมเป็นแฟนเรา ตรรกะโง่มากนะคะ แต่ถามว่าทำมั้ย ทำค่ะ พอไปรู้ว่าเขาคุยกับเพื่อน เพื่อนเขาถามว่า รู้สึกยังไงกับเรา เขาตอบเพื่อนว่า เขาว่าเขาควรอยู่คนเดียว ยังไม่พร้อมจะรักใคร จนตอนนี้เราเริ่มรู้สึกว่า ทำไมเราต้องทำขนาดนั้น ถ้าเขาจะรัก รักที่เป็นตัวเราไม่ได้หรอ หลังๆเลยเริ่มสนใจเขาน้อยลง แต่ยังคุยกันเหมือนเดิม เราลองแกล้งเงียบไป ไม่ทักไปครึ่งวัน ปกติเราจะมีการมอนิ่งกันตอนเช้าค่ะ พอเราไม่ทักไป เขาทำงานเสร็จ ถึงเวลาพักของเขา เขาก็ทักมาว่า กินข้าวกัน เราก็ยิ่ง งง ก็คิดว่า เขาอาจจะชินหับการคุยกับเราทุกวันเฉยๆ นี่เลยไม่ได้สนใจในส่วนนั้น เราก็ตอบตามปกติ จนเมื่อคืนมีคนมาทักเราจีบเรา จะไปส่งเราที่บ้าน เราก็เลยเล่าให้เขาฟังว่า ให้ไลน์ไป ให้เขาไปส่งอยู่แต่ไมไ่ด้นั่งรถคันเดียวกัน เราก็ขับของเรา คนที่มาจีบเราเขาก็ขับคันของเขาแค่มาส่งเฉยๆ พอเช้ามาเขาทักมามอนิ่ง ก็ถามเราเรื่องเมื่อคืน เราทำงานที่กลับดึกมากๆไม่ได้ทักไปบอกเขาไว้ว่า ถึงบ้านแล้วนะ เงียบไปทั้งคืนเลย เขาก็ถามเรื่องเมื่อคืนว่า หนุ่มไปส่งที่บ้านเป็นไงบ้าง ถามแต่เรื่องของผู้ชายที่มาจีบเราทั้งวัน จนเราเปลี่ยนเรื่องก็ยังกลับมาถามอีกรอบ ไออาการแบบนี้คืออะไรคะ ? ไหนเขาบอกอยากอยู่คนเดียว แต่พอเรามีคนเข้ามา ทำไมเขาถึงมีอาการแบบนี้ มาถามแบบนี้ซ้ำๆ คืออะไรกัน เราไม่อยากคิดอะไรไปเอง ใครพอจะตอบได้บ้างคะ ว่า ไอแบบนี้มันคืออะไร รู้สึกอะไรอยู่\"\n",
    "tokenized_input, labels = _mask_input(text, tokenizer, mlm_probability=0.1)\n",
    "_predict_masks(tokenized_input, labels, tokenizer , k=5, verbose=True, verbose_length=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Tokenize on Pantip Sample ร่างจำแลง (Literature)\n",
    "https://pantip.com/topic/40039192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Input: \n",
      "\tรมย์แห่งนั้<mask> เสียงต่<mask>\n",
      "Labeled Input: \n",
      "\tรมย์แห่งนั้น เสียงต่<mask>\n",
      "Predictions: \n",
      "\tรมย์แห่งนั้น เสียงต่<mask>\n",
      "\tรมย์แห่งนั้นเอง เสียงต่<mask>\n",
      "\tรมย์แห่งนั้นเลย เสียงต่<mask>\n",
      "\tรมย์แห่งนั้นๆ เสียงต่<mask>\n",
      "\tรมย์แห่งนั้นมา เสียงต่<mask>\n",
      "\n",
      "Masked Input: \n",
      "\tั้<mask> เสียงต่<mask>รวมถึงภาพเคลื่\n",
      "Labeled Input: \n",
      "\tั้<mask> เสียงต่างๆรวมถึงภาพเคลื่\n",
      "Predictions: \n",
      "\tั้<mask> เสียงต่างรวมถึงภาพเคลื่\n",
      "\tั้<mask> เสียงต่างๆรวมถึงภาพเคลื่\n",
      "\tั้<mask> เสียงต่างออกไปรวมถึงภาพเคลื่\n",
      "\tั้<mask> เสียงต่างหากรวมถึงภาพเคลื่\n",
      "\tั้<mask> เสียงต่างประเทศรวมถึงภาพเคลื่\n",
      "\n",
      "Masked Input: \n",
      "\tื่อนไหวประดังประเดเข<mask>าในโสตอย่\n",
      "Labeled Input: \n",
      "\tื่อนไหวประดังประเดเข้าในโสตอย่\n",
      "Predictions: \n",
      "\tื่อนไหวประดังประเดเข้าในโสตอย่\n",
      "\tื่อนไหวประดังประเดเข่าในโสตอย่\n",
      "\tื่อนไหวประดังประเดเขลาในโสตอย่\n",
      "\tื่อนไหวประดังประเดเขมาในโสตอย่\n",
      "\tื่อนไหวประดังประเดเขตาในโสตอย่\n",
      "\n",
      "Masked Input: \n",
      "\tาในโสตอย่างพร<mask><mask>รียง สร\n",
      "Labeled Input: \n",
      "\tาในโสตอย่างพร้<mask>รียง สร\n",
      "Predictions: \n",
      "\tาในโสตอย่างพร้<mask>รียง สร\n",
      "\tาในโสตอย่างพรุ<mask>รียง สร\n",
      "\tาในโสตอย่างพร่ํ<mask>รียง สร\n",
      "\tาในโสตอย่างพรี<mask>รียง สร\n",
      "\tาในโสตอย่างพรั<mask>รียง สร\n",
      "\n",
      "Masked Input: \n",
      "\tโสตอย่างพร<mask><mask>รียง สร้\n",
      "Labeled Input: \n",
      "\tโสตอย่างพร<mask>อมเพรียง สร้\n",
      "Predictions: \n",
      "\tโสตอย่างพร<mask>อมเพรียง สร้\n",
      "\tโสตอย่างพร<mask>มเปรียง สร้\n",
      "\tโสตอย่างพร<mask>งเปรียง สร้\n",
      "\tโสตอย่างพร<mask>งเพรียง สร้\n",
      "\tโสตอย่างพร<mask>อมเสรียง สร้\n",
      "\n",
      "Masked Input: \n",
      "\tางความอึกทึกม<mask>นตึงไปหมด\n",
      "\n",
      "Labeled Input: \n",
      "\tางความอึกทึกมึนตึงไปหมด\n",
      "\n",
      "Predictions: \n",
      "\tางความอึกทึกมึนตึงไปหมด\n",
      "\n",
      "\tางความอึกทึกมันตึงไปหมด\n",
      "\n",
      "\tางความอึกทึกมั่นตึงไปหมด\n",
      "\n",
      "\tางความอึกทึกมาจนตึงไปหมด\n",
      "\n",
      "\tางความอึกทึกมื้นตึงไปหมด\n",
      "\n",
      "\n",
      "Masked Input: \n",
      "\tหมด\n",
      "แสงสีบนเพ<mask>านที่กระพริบกว\n",
      "Labeled Input: \n",
      "\tหมด\n",
      "แสงสีบนเพดานที่กระพริบกว\n",
      "Predictions: \n",
      "\tหมด\n",
      "แสงสีบนเพดานที่กระพริบกว\n",
      "\tหมด\n",
      "แสงสีบนเพทานที่กระพริบกว\n",
      "\tหมด\n",
      "แสงสีบนเพชานที่กระพริบกว\n",
      "\tหมด\n",
      "แสงสีบนเพมานที่กระพริบกว\n",
      "\tหมด\n",
      "แสงสีบนเพลงสานที่กระพริบกว\n",
      "\n",
      "Masked Input: \n",
      "\tัดแกว่งไปมาจาก<mask>ุมด้วยเทคโนโลย\n",
      "Labeled Input: \n",
      "\tัดแกว่งไปมาจากการควบคุมด้วยเทคโนโลย\n",
      "Predictions: \n",
      "\tัดแกว่งไปมาจากมุมด้วยเทคโนโลย\n",
      "\tัดแกว่งไปมาจากหลุมด้วยเทคโนโลย\n",
      "\tัดแกว่งไปมาจากในมุมด้วยเทคโนโลย\n",
      "\tัดแกว่งไปมาจาก มุมด้วยเทคโนโลย\n",
      "\tัดแกว่งไปมาจากการควบคุมด้วยเทคโนโลย\n",
      "\n",
      "Masked Input: \n",
      "\t<mask>ุมด้วยเทคโนโลย<mask><mask>ับลำ\n",
      "Labeled Input: \n",
      "\t<mask>ุมด้วยเทคโนโลยี<mask>ับลำ\n",
      "Predictions: \n",
      "\t<mask>ุมด้วยเทคโนโลยี<mask>ับลำ\n",
      "\t<mask>ุมด้วยเทคโนโลยี่<mask>ับลำ\n",
      "\t<mask>ุมด้วยเทคโนโลยี,<mask>ับลำ\n",
      "\t<mask>ุมด้วยเทคโนโลยั<mask>ับลำ\n",
      "\t<mask>ุมด้วยเทคโนโลยิ<mask>ับลำ\n",
      "\n",
      "Masked Input: \n",
      "\tุมด้วยเทคโนโลย<mask><mask>ับลำ<mask>\n",
      "Labeled Input: \n",
      "\tุมด้วยเทคโนโลย<mask> สลับลำ<mask>\n",
      "Predictions: \n",
      "\tุมด้วยเทคโนโลย<mask>ประดับลำ<mask>\n",
      "\tุมด้วยเทคโนโลย<mask>กับลำ<mask>\n",
      "\tุมด้วยเทคโนโลย<mask>ระดับลำ<mask>\n",
      "\tุมด้วยเทคโนโลย<mask>รับลำ<mask>\n",
      "\tุมด้วยเทคโนโลย<mask>อับลำ<mask>\n",
      "\n",
      "Masked Input: \n",
      "\t<mask><mask>ับลำ<mask>งท<mask>ามกลางความมื\n",
      "Labeled Input: \n",
      "\t<mask><mask>ับลำแสงท<mask>ามกลางความมื\n",
      "Predictions: \n",
      "\t<mask><mask>ับลำลงท<mask>ามกลางความมื\n",
      "\t<mask><mask>ับลำมาลงท<mask>ามกลางความมื\n",
      "\t<mask><mask>ับลำตกลงท<mask>ามกลางความมื\n",
      "\t<mask><mask>ับลำทรงท<mask>ามกลางความมื\n",
      "\t<mask><mask>ับลำแสงท<mask>ามกลางความมื\n",
      "\n",
      "Masked Input: \n",
      "\tับลำ<mask>งท<mask>ามกลางความมืดจนต\n",
      "Labeled Input: \n",
      "\tับลำ<mask>งท่ามกลางความมืดจนต\n",
      "Predictions: \n",
      "\tับลำ<mask>งท่ามกลางความมืดจนต\n",
      "\tับลำ<mask>งท้ามกลางความมืดจนต\n",
      "\tับลำ<mask>งทํามกลางความมืดจนต\n",
      "\tับลำ<mask>งทนทามกลางความมืดจนต\n",
      "\tับลำ<mask>งท่”ามกลางความมืดจนต\n",
      "\n",
      "Masked Input: \n",
      "\t<mask>ามกลางความมืดจนต<mask>จ<mask>�แน<mask>\n",
      "Labeled Input: \n",
      "\t<mask>ามกลางความมืดจนตาลายจ<mask>�แน<mask>\n",
      "Predictions: \n",
      "\t<mask>ามกลางความมืดจนตกกระจ<mask>�แน<mask>\n",
      "\t<mask>ามกลางความมืดจนตกใจจ<mask>�แน<mask>\n",
      "\t<mask>ามกลางความมืดจนตาของจ<mask>�แน<mask>\n",
      "\t<mask>ามกลางความมืดจนตาลายจ<mask>�แน<mask>\n",
      "\t<mask>ามกลางความมืดจนตกของจ<mask>�แน<mask>\n",
      "\n",
      "Masked Input: \n",
      "\tความมืดจนต<mask>จ<mask>�แน<mask>ั<mask>\n",
      "Labeled Input: \n",
      "\tความมืดจนต<mask>จำแน<mask>ั<mask>\n",
      "Predictions: \n",
      "\tความมืดจนต<mask>จำแน<mask>ั<mask>\n",
      "\tความมืดจนต<mask>จเำแน<mask>ั<mask>\n",
      "\tความมืดจนต<mask>จราำแน<mask>ั<mask>\n",
      "\tความมืดจนต<mask>จฤทธ�แน<mask>ั<mask>\n",
      "\tความมืดจนต<mask>จ��แน<mask>ั<mask>\n",
      "\n",
      "Masked Input: \n",
      "\tนต<mask>จ<mask>�แน<mask>ั<mask>ุไม่\n",
      "Labeled Input: \n",
      "\tนต<mask>จ<mask>�แนกวั<mask>ุไม่\n",
      "Predictions: \n",
      "\tนต<mask>จ<mask>�แนบยั<mask>ุไม่\n",
      "\tนต<mask>จ<mask>�แนวยั<mask>ุไม่\n",
      "\tนต<mask>จ<mask>�แนบกั<mask>ุไม่\n",
      "\tนต<mask>จ<mask>�แนบสั<mask>ุไม่\n",
      "\tนต<mask>จ<mask>�แนวกั<mask>ุไม่\n",
      "\n",
      "Masked Input: \n",
      "\tจ<mask>�แน<mask>ั<mask>ุไม่ออก ย\n",
      "Labeled Input: \n",
      "\tจ<mask>�แน<mask>ัตถุไม่ออก ย\n",
      "Predictions: \n",
      "\tจ<mask>�แน<mask>ังเกตุไม่ออก ย\n",
      "\tจ<mask>�แน<mask>ันดุไม่ออก ย\n",
      "\tจ<mask>�แน<mask>ัสดุไม่ออก ย\n",
      "\tจ<mask>�แน<mask>ังดุไม่ออก ย\n",
      "\tจ<mask>�แน<mask>ับดุไม่ออก ย\n",
      "\n",
      "Masked Input: \n",
      "\tเคยชินอย่างผมท<mask>เพิ่<mask>่าง\n",
      "Labeled Input: \n",
      "\tเคยชินอย่างผมที่เพิ่<mask>่าง\n",
      "Predictions: \n",
      "\tเคยชินอย่างผมที่เพิ่<mask>่าง\n",
      "\tเคยชินอย่างผมทีเพิ่<mask>่าง\n",
      "\tเคยชินอย่างผมทยอยเพิ่<mask>่าง\n",
      "\tเคยชินอย่างผมทะยานเพิ่<mask>่าง\n",
      "\tเคยชินอย่างผมทดลองเพิ่<mask>่าง\n",
      "\n",
      "Masked Input: \n",
      "\t่างผมท<mask>เพิ่<mask>่างกรายเข้\n",
      "Labeled Input: \n",
      "\t่างผมท<mask>เพิ่งย่างกรายเข้\n",
      "Predictions: \n",
      "\t่างผมท<mask>เพิ่งร่างกรายเข้\n",
      "\t่างผมท<mask>เพิ่งว่างกรายเข้\n",
      "\t่างผมท<mask>เพิ่งต่างกรายเข้\n",
      "\t่างผมท<mask>เพิ่มร่างกรายเข้\n",
      "\t่างผมท<mask>เพิ่งคว่างกรายเข้\n",
      "\n",
      "Masked Input: \n",
      "\t็กระหึ่มกระแท<mask>ั้นเร้าใจ กระต\n",
      "Labeled Input: \n",
      "\t็กระหึ่มกระแทกกระทั้นเร้าใจ กระต\n",
      "Predictions: \n",
      "\t็กระหึ่มกระแทกนั้นเร้าใจ กระต\n",
      "\t็กระหึ่มกระแทกกั้นเร้าใจ กระต\n",
      "\t็กระหึ่มกระแทกขั้นเร้าใจ กระต\n",
      "\t็กระหึ่มกระแทกกระทั้นเร้าใจ กระต\n",
      "\t็กระหึ่มกระแทกตอนนั้นเร้าใจ กระต\n",
      "\n",
      "Masked Input: \n",
      "\tาดิ้นวาดลวดลาย<mask>นทรุดกองฮว\n",
      "Labeled Input: \n",
      "\tาดิ้นวาดลวดลายจนทรุดกองฮว\n",
      "Predictions: \n",
      "\tาดิ้นวาดลวดลายจนทรุดกองฮว\n",
      "\tาดิ้นวาดลวดลาย จนทรุดกองฮว\n",
      "\tาดิ้นวาดลวดลายไปจนทรุดกองฮว\n",
      "\tาดิ้นวาดลวดลาย บนทรุดกองฮว\n",
      "\tาดิ้นวาดลวดลายฝนทรุดกองฮว\n",
      "\n",
      "Masked Input: \n",
      "\tวบกับพื้น<mask>ุจดั่<mask><mask>\n",
      "Labeled Input: \n",
      "\tวบกับพื้น ดุจดั่<mask><mask>\n",
      "Predictions: \n",
      "\tวบกับพื้นประดุจดั่<mask><mask>\n",
      "\tวบกับพื้น และดุจดั่<mask><mask>\n",
      "\tวบกับพื้น ดุจดั่<mask><mask>\n",
      "\tวบกับพื้น ทรุจดั่<mask><mask>\n",
      "\tวบกับพื้น ประดุจดั่<mask><mask>\n",
      "\n",
      "Masked Input: \n",
      "\tื้น<mask>ุจดั่<mask><mask>หลายคนบนพ<mask>นเต\n",
      "Labeled Input: \n",
      "\tื้น<mask>ุจดั่งท<mask>หลายคนบนพ<mask>นเต\n",
      "Predictions: \n",
      "\tื้น<mask>ุจดั่งให<mask>หลายคนบนพ<mask>นเต\n",
      "\tื้น<mask>ุจดั่งใจ<mask>หลายคนบนพ<mask>นเต\n",
      "\tื้น<mask>ุจดั่งไ<mask>หลายคนบนพ<mask>นเต\n",
      "\tื้น<mask>ุจดั่งท<mask>หลายคนบนพ<mask>นเต\n",
      "\tื้น<mask>ุจดั่งของ<mask>หลายคนบนพ<mask>นเต\n",
      "\n",
      "Masked Input: \n",
      "\tน<mask>ุจดั่<mask><mask>หลายคนบนพ<mask>นเต้\n",
      "Labeled Input: \n",
      "\tน<mask>ุจดั่<mask>ี่หลายคนบนพ<mask>นเต้\n",
      "Predictions: \n",
      "\tน<mask>ุจดั่<mask>ี่หลายคนบนพ<mask>นเต้\n",
      "\tน<mask>ุจดั่<mask>้หลายคนบนพ<mask>นเต้\n",
      "\tน<mask>ุจดั่<mask>\n",
      "หลายคนบนพ<mask>นเต้\n",
      "\tน<mask>ุจดั่<mask>ีหลายคนบนพ<mask>นเต้\n",
      "\tน<mask>ุจดั่<mask>ใครหลายคนบนพ<mask>นเต้\n",
      "\n",
      "Masked Input: \n",
      "\tจดั่<mask><mask>หลายคนบนพ<mask>นเต้นกำ\n",
      "Labeled Input: \n",
      "\tจดั่<mask><mask>หลายคนบนพื้นเต้นกำ\n",
      "Predictions: \n",
      "\tจดั่<mask><mask>หลายคนบนพื้นเต้นกำ\n",
      "\tจดั่<mask><mask>หลายคนบนพื่นเต้นกำ\n",
      "\tจดั่<mask><mask>หลายคนบนพันเต้นกำ\n",
      "\tจดั่<mask><mask>หลายคนบนพืนเต้นกำ\n",
      "\tจดั่<mask><mask>หลายคนบนพ้นเต้นกำ\n",
      "\n",
      "Masked Input: \n",
      "\tนเต้นกำล<mask>งท<mask>�อยู่\n",
      "Labeled Input: \n",
      "\tนเต้นกำลังท<mask>�อยู่\n",
      "Predictions: \n",
      "\tนเต้นกำลังท<mask>�อยู่\n",
      "\tนเต้นกำลุงท<mask>�อยู่\n",
      "\tนเต้นกำลิงท<mask>�อยู่\n",
      "\tนเต้นกำลิ่งท<mask>�อยู่\n",
      "\tนเต้นกำลั่งท<mask>�อยู่\n",
      "\n",
      "Masked Input: \n",
      "\tนกำล<mask>งท<mask>�อยู่ หรื\n",
      "Labeled Input: \n",
      "\tนกำล<mask>งทำอยู่ หรื\n",
      "Predictions: \n",
      "\tนกำล<mask>งทำอยู่ หรื\n",
      "\tนกำล<mask>งทราำอยู่ หรื\n",
      "\tนกำล<mask>งท��อยู่ หรื\n",
      "\tนกำล<mask>งทว�อยู่ หรื\n",
      "\tนกำล<mask>งทเำอยู่ หรื\n",
      "\n",
      "Masked Input: \n",
      "\t�อยู่ หรือม<mask>เช่นน<mask>นก\n",
      "Labeled Input: \n",
      "\t�อยู่ หรือมิเช่นน<mask>นก\n",
      "Predictions: \n",
      "\t�อยู่ หรือมิเช่นน<mask>นก\n",
      "\t�อยู่ หรือมีเช่นน<mask>นก\n",
      "\t�อยู่ หรือมองอะไรเช่นน<mask>นก\n",
      "\t�อยู่ หรือมาผมเช่นน<mask>นก\n",
      "\t�อยู่ หรือมองไปเช่นน<mask>นก\n",
      "\n",
      "Masked Input: \n",
      "\tือม<mask>เช่นน<mask>นก็หนวกห\n",
      "Labeled Input: \n",
      "\tือม<mask>เช่นนั้นก็หนวกห\n",
      "Predictions: \n",
      "\tือม<mask>เช่นนั้นก็หนวกห\n",
      "\tือม<mask>เช่นนั่นก็หนวกห\n",
      "\tือม<mask>เช่นนันก็หนวกห\n",
      "\tือม<mask>เช่นนี้นก็หนวกห\n",
      "\tือม<mask>เช่นนู้นก็หนวกห\n",
      "\n",
      "Masked Input: \n",
      "\t่างที่ผมกำ<mask>ังรู้สึ\n",
      "Labeled Input: \n",
      "\t่างที่ผมกำลังรู้สึ\n",
      "Predictions: \n",
      "\t่างที่ผมกำยังรู้สึ\n",
      "\t่างที่ผมกำลังรู้สึ\n",
      "\t่างที่ผมกำดังรู้สึ\n",
      "\t่างที่ผมกำตรังรู้สึ\n",
      "\t่างที่ผมกำฟังรู้สึ\n",
      "\n",
      "Masked Input: \n",
      "\t้อย่างไรไม่<mask>ู้ เขาคงคุ้นเคยก\n",
      "Labeled Input: \n",
      "\t้อย่างไรไม่รู้ เขาคงคุ้นเคยก\n",
      "Predictions: \n",
      "\t้อย่างไรไม่รู้ เขาคงคุ้นเคยก\n",
      "\t้อย่างไรไม่เคยรู้ เขาคงคุ้นเคยก\n",
      "\t้อย่างไรไม่สู้ เขาคงคุ้นเคยก\n",
      "\t้อย่างไรไม่อยากรู้ เขาคงคุ้นเคยก\n",
      "\t้อย่างไรไม่ใครรู้ เขาคงคุ้นเคยก\n",
      "\n",
      "Masked Input: \n",
      "\tุ้นเคยกับห้องม<mask>ดสล<mask>วท<mask>\n",
      "Labeled Input: \n",
      "\tุ้นเคยกับห้องมืดสล<mask>วท<mask>\n",
      "Predictions: \n",
      "\tุ้นเคยกับห้องมืดสล<mask>วท<mask>\n",
      "\tุ้นเคยกับห้องมีดสล<mask>วท<mask>\n",
      "\tุ้นเคยกับห้องมัดสล<mask>วท<mask>\n",
      "\tุ้นเคยกับห้องมิดสล<mask>วท<mask>\n",
      "\tุ้นเคยกับห้องมุดสล<mask>วท<mask>\n",
      "\n",
      "Masked Input: \n",
      "\tบห้องม<mask>ดสล<mask>วท<mask>มีแสง\n",
      "Labeled Input: \n",
      "\tบห้องม<mask>ดสลัวท<mask>มีแสง\n",
      "Predictions: \n",
      "\tบห้องม<mask>ดสลัวท<mask>มีแสง\n",
      "\tบห้องม<mask>ดสลิวท<mask>มีแสง\n",
      "\tบห้องม<mask>ดสลิ่วท<mask>มีแสง\n",
      "\tบห้องม<mask>ดสลิ้วท<mask>มีแสง\n",
      "\tบห้องม<mask>ดสลุวท<mask>มีแสง\n",
      "\n",
      "Masked Input: \n",
      "\tองม<mask>ดสล<mask>วท<mask>มีแสงไฟเปล\n",
      "Labeled Input: \n",
      "\tองม<mask>ดสล<mask>วที่มีแสงไฟเปล\n",
      "Predictions: \n",
      "\tองม<mask>ดสล<mask>วที่มีแสงไฟเปล\n",
      "\tองม<mask>ดสล<mask>วทีมีแสงไฟเปล\n",
      "\tองม<mask>ดสล<mask>วท์มีแสงไฟเปล\n",
      "\tองม<mask>ดสล<mask>วท\n",
      "มีแสงไฟเปล\n",
      "\tองม<mask>ดสล<mask>วที้มีแสงไฟเปล\n",
      "\n",
      "Masked Input: \n",
      "\tมีแสงไฟเปลี่<mask>ี<mask>ัดกวั\n",
      "Labeled Input: \n",
      "\tมีแสงไฟเปลี่ยนสี<mask>ัดกวั\n",
      "Predictions: \n",
      "\tมีแสงไฟเปลี่ยนสี<mask>ัดกวั\n",
      "\tมีแสงไฟเปลี่ยนที<mask>ัดกวั\n",
      "\tมีแสงไฟเปลี่ยนมี<mask>ัดกวั\n",
      "\tมีแสงไฟเปลี่ยวที<mask>ัดกวั\n",
      "\tมีแสงไฟเปลี่ยวเดี<mask>ัดกวั\n",
      "\n",
      "Masked Input: \n",
      "\tแสงไฟเปลี่<mask>ี<mask>ัดกวัดไกว\n",
      "Labeled Input: \n",
      "\tแสงไฟเปลี่<mask>ีตวัดกวัดไกว\n",
      "Predictions: \n",
      "\tแสงไฟเปลี่<mask>ีปัดกวัดไกว\n",
      "\tแสงไฟเปลี่<mask>ีวัดกวัดไกว\n",
      "\tแสงไฟเปลี่<mask>ีชัดกวัดไกว\n",
      "\tแสงไฟเปลี่<mask>ีดปัดกวัดไกว\n",
      "\tแสงไฟเปลี่<mask>ีกมัดกวัดไกว\n",
      "\n",
      "Total Input Tokens: torch.Size([323])\n",
      "Total Correct for Top 5: 30\n",
      "Total Mask: 35\n",
      "Percent Correct: 85.71%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"ก้าวแรกของผมที่สัมผัสฝ่าเท้าลงภายในสถานเริงรมย์แห่งนั้น เสียงต่างๆรวมถึงภาพเคลื่อนไหวประดังประเดเข้าในโสตอย่างพร้อมเพรียง สร้างความอึกทึกมึนตึงไปหมด\n",
    "แสงสีบนเพดานที่กระพริบกวัดแกว่งไปมาจากการควบคุมด้วยเทคโนโลยี สลับลำแสงท่ามกลางความมืดจนตาลายจำแนกวัตถุไม่ออก ยิ่งสำหรับคนที่ไม่เคยชินอย่างผมที่เพิ่งย่างกรายเข้ามาเป็นหนแรก\n",
    "เสียงเพลงก็กระหึ่มกระแทกกระทั้นเร้าใจ กระตุ้นให้ทุกอณูส่วนของร่างกายอยากขยับเด้าดิ้นวาดลวดลายจนทรุดกองฮวบกับพื้น ดุจดั่งที่หลายคนบนพื้นเต้นกำลังทำอยู่ หรือมิเช่นนั้นก็หนวกหูรำคาญไปเลยอย่างที่ผมกำลังรู้สึก\n",
    "ชัยนาทเห็นผมแต่ไกลได้อย่างไรไม่รู้ เขาคงคุ้นเคยกับห้องมืดสลัวที่มีแสงไฟเปลี่ยนสีตวัดกวัดไกวไปมาจนปวดตา จึงเห็นผมได้ไม่ยากเย็น\"\"\"\n",
    "tokenized_input, labels = _mask_input(text, tokenizer, mlm_probability=0.1)\n",
    "_predict_masks(tokenized_input, labels, tokenizer , k=5, verbose=True, verbose_length=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Tokenize on Own Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Input: \n",
      "\tัสดีครับ<mask>ื่อไนท์ ตอนน\n",
      "Labeled Input: \n",
      "\tัสดีครับ ผมชื่อไนท์ ตอนน\n",
      "Predictions: \n",
      "\tัสดีครับ ผมชื่อไนท์ ตอนน\n",
      "\tัสดีครับ เราชื่อไนท์ ตอนน\n",
      "\tัสดีครับ เพื่อไนท์ ตอนน\n",
      "\tัสดีครับ ชื่อไนท์ ตอนน\n",
      "\tัสดีครับ เมื่อไนท์ ตอนน\n",
      "\n",
      "Masked Input: \n",
      "\t้องไปโรงเรียนแล้<mask> น<mask>คือการ\n",
      "Labeled Input: \n",
      "\t้องไปโรงเรียนแล้ว น<mask>คือการ\n",
      "Predictions: \n",
      "\t้องไปโรงเรียนแล้ว น<mask>คือการ\n",
      "\t้องไปโรงเรียนแล้วนะ น<mask>คือการ\n",
      "\t้องไปโรงเรียนแล้วผม น<mask>คือการ\n",
      "\t้องไปโรงเรียนแล้วว น<mask>คือการ\n",
      "\t้องไปโรงเรียนแล้ววว น<mask>คือการ\n",
      "\n",
      "Masked Input: \n",
      "\tโรงเรียนแล้<mask> น<mask>คือการ<mask>้\n",
      "Labeled Input: \n",
      "\tโรงเรียนแล้<mask> นี่คือการ<mask>้\n",
      "Predictions: \n",
      "\tโรงเรียนแล้<mask> นี่คือการ<mask>้\n",
      "\tโรงเรียนแล้<mask> นี้คือการ<mask>้\n",
      "\tโรงเรียนแล้<mask> นีคือการ<mask>้\n",
      "\tโรงเรียนแล้<mask> นิคือการ<mask>้\n",
      "\tโรงเรียนแล้<mask> น็คือการ<mask>้\n",
      "\n",
      "Masked Input: \n",
      "\t<mask> น<mask>คือการ<mask>้นวรรคสองที\n",
      "Labeled Input: \n",
      "\t<mask> น<mask>คือการเว้นวรรคสองที\n",
      "Predictions: \n",
      "\t<mask> น<mask>คือการเว้นวรรคสองที\n",
      "\t<mask> น<mask>คือการลดต้นวรรคสองที\n",
      "\t<mask> น<mask>คือการ เว้นวรรคสองที\n",
      "\t<mask> น<mask>คือการได้นวรรคสองที\n",
      "\t<mask> น<mask>คือการเข้นวรรคสองที\n",
      "\n",
      "Masked Input: \n",
      "\t้นวรรคสองทีคร<mask>บ จะได้<mask><mask>\n",
      "Labeled Input: \n",
      "\t้นวรรคสองทีครับ จะได้<mask><mask>\n",
      "Predictions: \n",
      "\t้นวรรคสองทีครับ จะได้<mask><mask>\n",
      "\t้นวรรคสองทีครีบ จะได้<mask><mask>\n",
      "\t้นวรรคสองทีคร้บ จะได้<mask><mask>\n",
      "\t้นวรรคสองทีครึบ จะได้<mask><mask>\n",
      "\t้นวรรคสองทีคริบ จะได้<mask><mask>\n",
      "\n",
      "Masked Input: \n",
      "\tีคร<mask>บ จะได้<mask><mask>นสอง</s>\n",
      "Labeled Input: \n",
      "\tีคร<mask>บ จะได้ออกเป<mask>นสอง</s>\n",
      "Predictions: \n",
      "\tีคร<mask>บ จะได้เป<mask>นสอง</s>\n",
      "\tีคร<mask>บ จะได้ร<mask>นสอง</s>\n",
      "\tีคร<mask>บ จะได้มาเป<mask>นสอง</s>\n",
      "\tีคร<mask>บ จะได้ข<mask>นสอง</s>\n",
      "\tีคร<mask>บ จะได้ย<mask>นสอง</s>\n",
      "\n",
      "Masked Input: \n",
      "\tคร<mask>บ จะได้<mask><mask>นสอง</s>\n",
      "Labeled Input: \n",
      "\tคร<mask>บ จะได้<mask>็นสอง</s>\n",
      "Predictions: \n",
      "\tคร<mask>บ จะได้<mask>็นสอง</s>\n",
      "\tคร<mask>บ จะได้<mask>ันสอง</s>\n",
      "\tคร<mask>บ จะได้<mask>ึ้นสอง</s>\n",
      "\tคร<mask>บ จะได้<mask>้นสอง</s>\n",
      "\tคร<mask>บ จะได้<mask>่นสอง</s>\n",
      "\n",
      "Total Input Tokens: torch.Size([49])\n",
      "Total Correct for Top 5: 6\n",
      "Total Mask: 7\n",
      "Percent Correct: 85.71%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"สวัสดีครับ ผมชื่อไนท์ ตอนนี้ก็เป็นเวลาที่ผมต้องไปโรงเรียนแล้ว นี่คือการเว้นวรรคสองทีครับ จะได้ออกเป็นสอง\"\n",
    "tokenized_input, labels = _mask_input(text, tokenizer, mlm_probability=0.15)\n",
    "_predict_masks(tokenized_input, labels, tokenizer , k=5, verbose=True, verbose_length=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or trying the Vanilla way to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = f\"Distilled models are smaller than the models they mimic. Using them instead of the large versions would help {tokenizer.mask_token} our carbon footprint.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,    40,  2744,   789,  9774, 17624,    87,  6344,  2352,  1848,\n",
       "           522, 13701,  1207, 17624,    87, 19898,   584,  1164,   721,    18,\n",
       "           225,    57, 19100,  1207,    81, 12140,    73,   977,  1572,  1207,\n",
       "           676,   633,  3789, 12847, 10865,   731, 11955, 15051,    84,     4,\n",
       "         14855,  5963,    70,   524,   655,  8489,  3220,  3449,    18,     2]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 40, 2744, 789, 9774, 17624, 87, 6344, 2352, 1848, 522, 13701, 1207, 17624, 87, 19898, 584, 1164, 721, 18, 225, 57, 19100, 1207, 81, 12140, 73, 977, 1572, 1207, 676, 633, 3789, 12847, 10865, 731, 11955, 15051, 84, 4, 14855, 5963, 70, 524, 655, 8489, 3220, 3449, 18, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([39])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_index = torch.where(_input == tokenizer.mask_token_id)[1]\n",
    "mask_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -6.8569, -11.4544,  -6.2892,  ...,  -3.3654,  -1.7394,  -3.8599],\n",
       "         [ -6.7165,  -7.8614, -10.1110,  ...,  -0.2116,  -1.2954,  -8.0255],\n",
       "         [ -6.4925,  -9.5634,  -9.8982,  ...,  -3.4279,  -1.0313,  -6.8084],\n",
       "         ...,\n",
       "         [ -6.2978,  -6.5940,  -9.4618,  ...,   0.5986,  -2.2195,  -8.1321],\n",
       "         [ -6.3295,  -9.3629,  -9.6262,  ...,   0.0172,  -8.5017,  -5.1815],\n",
       "         [ -6.8569, -11.4543,  -6.2891,  ...,  -3.3655,  -1.7393,  -3.8597]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits = model(_input)[0]\n",
    "token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.0691,  -7.5146, -11.4188,  ...,   3.1234,  -1.2106,  -6.2130]],\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "mask_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1228, 1187, 1796, 18, 12549]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "top_5_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help ed our carbon footprint.\n",
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help  in our carbon footprint.\n",
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help  to our carbon footprint.\n",
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help . our carbon footprint.\n",
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help  her our carbon footprint.\n"
     ]
    }
   ],
   "source": [
    "for token in top_5_tokens:\n",
    "     print(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Text-Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Generation is currently not supported for RobertaForMaskedLM. Please select a model from ['XLNetLMHeadModel', 'TransfoXLLMHeadModel', 'ReformerModelWithLMHead', 'GPT2LMHeadModel', 'OpenAIGPTLMHeadModel', 'CTRLLMHeadModel', 'TFXLNetLMHeadModel', 'TFTransfoXLLMHeadModel', 'TFGPT2LMHeadModel', 'TFOpenAIGPTLMHeadModel', 'TFCTRLLMHeadModel'] for generation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-cb55d1878408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"As far as I am concerned, I will\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/pipelines.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, return_tensors, return_text, clean_up_tokenization_spaces, *args, **generate_kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m             raise NotImplementedError(\n\u001b[1;32m    645\u001b[0m                 \"Generation is currently not supported for {}. Please select a model from {} for generation.\".format(\n\u001b[0;32m--> 646\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALLOWED_MODELS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m                 )\n\u001b[1;32m    648\u001b[0m             )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Generation is currently not supported for RobertaForMaskedLM. Please select a model from ['XLNetLMHeadModel', 'TransfoXLLMHeadModel', 'ReformerModelWithLMHead', 'GPT2LMHeadModel', 'OpenAIGPTLMHeadModel', 'CTRLLMHeadModel', 'TFXLNetLMHeadModel', 'TFTransfoXLLMHeadModel', 'TFGPT2LMHeadModel', 'TFOpenAIGPTLMHeadModel', 'TFCTRLLMHeadModel'] for generation."
     ]
    }
   ],
   "source": [
    "text_gen(\"As far as I am concerned, I will\", max_length=50, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1783,  275,  566,  278,  333,  275,  282]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['สว', 'ั', 'สด', 'ี', 'คร', 'ั', 'บ']"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"สวัสดีครับ\"\n",
    "_inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "print(_inputs)\n",
    "[tokenizer.decode([tok]) for tok in _inputs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1783,  275,  566,  278,  333,  275,  282,    4,    2]])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def _text_generation(prompt, max_length=250)\n",
    "prompt = \"สวัสดีครับ\"\n",
    "\n",
    "def _add_mask_to_last(prompt, tokenizer, device=None):\n",
    "    # Tokenize the sequence with special tokens inserted, remove last token and replace with mask\n",
    "    if type(prompt) is str:\n",
    "        _input = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "        _input[0, -1] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "        _temp_tensor = torch.zeros((_input.shape[0], 1), dtype=torch.int64)\n",
    "        _temp_tensor[0][0] = tokenizer.sep_token_id\n",
    "        return torch.cat((_input, _temp_tensor), dim=1)\n",
    "    else: # if it is tensor\n",
    "        _input = prompt.clone()\n",
    "        _temp_tensor = torch.zeros((_input.shape[0], 2), dtype=torch.int64)\n",
    "        _temp_tensor[0][0] = tokenizer.mask_token_id\n",
    "        _temp_tensor[0][1] = tokenizer.sep_token_id\n",
    "        _temp_tensor = _temp_tensor.to(device)\n",
    "        return torch.cat((prompt, _temp_tensor), dim=1)\n",
    "_add_mask_to_last(prompt, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(20000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=20000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_device = torch.device(\"cpu\")\n",
    "model.to(cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_last_token(_input, tokenizer, k, top_p):\n",
    "    \"\"\"top_k – (optional) int The number of highest probability vocabulary tokens to keep for top-k-filtering. Between 1 and infinity. Default to 50.\n",
    "\n",
    "    top_p – (optional) float The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be between 0 and 1. Default to 1.\"\"\"\n",
    "    mask_token_index = torch.where(_input == tokenizer.mask_token_id)[1]\n",
    "    _input.to(device)\n",
    "    token_logits = model(_input)[0]\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "    _mask_token_logits_cpu = mask_token_logits.clone().cpu()\n",
    "    top_k_tokens = torch.topk(_mask_token_logits_cpu, k, dim=1).indices[0].numpy()\n",
    "    if np.random.random() < top_p:\n",
    "        return top_k_tokens[0]\n",
    "    else:\n",
    "        return top_k_tokens[1:][np.random.randint(low=0, high=top_k_tokens.size-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _text_generate(prompt, tokenizer, length = 250, top_k=10, top_p=0.95, device=None):\n",
    "#     _input = _add_mask_to_last(prompt, tokenizer)\n",
    "    _input = prompt\n",
    "    for i in range(length):\n",
    "        _input = _add_mask_to_last(_input, tokenizer, device=device)\n",
    "        _input = _input.to(device)\n",
    "        _input[0, -2] = _predict_last_token(_input, tokenizer, k=top_k, top_p = top_p)\n",
    "        _input = _input[:, :-1].clone()\n",
    "    print(tokenizer.decode(_input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1783,  275,  566,  278,  333,  275,  282,    4]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>การตั้งกระทู้และการเชียร์บอล รวมถึงกิจกรรมทั้งหมดของชมรม ฯ เป็นไปเพื่อความบันเทิงของสมาชิกทุกๆท่าน\n",
      "และการตั้งกระทู้และการให้ความเห็น\n",
      "โดยการตั้งกระทู้และอิสรภาพ\n",
      "โดยทั่วไปของชมรม ฯ เป็นการเพื่อความสะดวกบํารุงรักษาบรรยากาศ\n",
      "โดยการตั้งกระทู้และการที่มีกระทันหัน\n",
      "โดยการตั้งกระทืและการให้ความเห็น\n",
      "โดยการตั้งกระทู้และการให้ความเห็น\n",
      "โดยการตั้งกระทู่และการให้เป็นกระทู้และการให้ความเห\n",
      "น\n",
      "โดยการขอให้มีสาระ\n",
      "หรือ ดูถึงความคิดเห็น\n",
      "โดยการตั้งกระทู้และการตั้งกระทุ้\n",
      "โดยการตั้งกระทู้และการให้ความเห็น\n",
      "โดยการตั้งกระทู้ และการตั้งกระทู้\n",
      "โดยการตั้งกระทู้และการให้เป็นกระทู้โดยการตั้งกระทู้และการที่มีกระทู้และการให้ความเห็น\n",
      "โดยการตั้งกระทู้และการตั้งกระทู้และเพื่\n"
     ]
    }
   ],
   "source": [
    "_text_generate(\"\"\"การตั้งกระทู้และการเชียร์บอล รวมถึงกิจกรรมทั้งหมดของชมรม ฯ เป็นไปเพื่อความบันเทิงของสมาชิกทุกๆท่าน\"\"\", tokenizer, device=device,length = 200,top_k=8, top_p=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>ตอนนี้เป็นเวลา 2 ปีแลด้วย และได้รับ sms ขยะที่มีข่าวออกมาว่าน่าจะมาด้วย และได้รับ dtac ขยะที่มีกระแสข่าวออกมาว่าน่าจะมาด้วย และไดเรรีย์ค่าย ais ขยะที่มั่นคงด้วย และกลายเป็น dtac ขยะที่มั่นคงไปด้วย และแพ็ก ais ขยะที่มั่นใจคงไปด้วย และยังมีข่าวออกมาวันนี้ท่ามกลางกระแสวิตกังวลอย่างมาก และกลายเป็น dtac ไดเรรีย์ค้าย ais ขยะ\n",
      "ส่วนตัว เป็น dtac ขยะที่ต้องการขายออนไลน์ และกลายเป็น dtac ขยะที่มั่นคงไปด้วย และเป้าหมายของ dtac ขยะทุกคน เป็น dtac ขยะ โดยที่มี dtac ขยะทุกคนมี dtac ขยะทุกคน เป\n"
     ]
    }
   ],
   "source": [
    "_text_generate(\"\"\"ตอนนี้เป็นเวลา\"\"\", tokenizer, device=device,length = 200,top_k=8, top_p=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_tokens.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48881225040001264"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_length = len(tokenizer.decode(_inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "prompt_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1783,  275,  566,  278,  333,  275,  282,  282,  282,  282,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,  404,\n",
       "          404,  404,  404,  404,  404,  404,  404,  404,  404,  404]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(_inputs, max_length=250, do_sample=True, top_p=0.95, top_k=5)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'สวัสดีครับ                                                                                                                                                                                                                                                   '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated = prompt + tokenizer.decode(outputs[0])[prompt_length:]\n",
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'สวัสดีครับบบบบบbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
