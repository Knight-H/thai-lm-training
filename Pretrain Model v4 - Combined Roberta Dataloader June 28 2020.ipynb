{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__How to train a language model__\tNotebook to Highlight all the steps to effectively train Transformer model on custom data\n",
    "https://github.com/huggingface/transformers/tree/master/notebooks\n",
    "\n",
    "https://github.com/huggingface/blog/blob/master/notebooks/01_how_to_train.ipynb\n",
    "\n",
    "__Language Modeling__\n",
    "https://github.com/huggingface/transformers/tree/master/examples/language-modeling\n",
    "https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tokenizers import CharBPETokenizer, Tokenizer, ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "from tokenizers.normalizers import BertNormalizer\n",
    "# from tokenizers import SentencePieceBPETokenizer\n",
    "\n",
    "import random\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast , AutoTokenizer,RobertaTokenizerFast, RobertaTokenizer\n",
    "from filelock import FileLock\n",
    "import logging\n",
    "import time\n",
    "import tqdm\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat123', 'dog123', 'mat123', 'pat123', 'rat123', 'bat123', 'bolo123']\n"
     ]
    }
   ],
   "source": [
    "array = [\"cat\", \"dog\", \"mat\", \"pat\", \"rat\", \"bat\" , \"bolo\"]\n",
    "def testadder(arrItem):\n",
    "    return arrItem+\"123\"\n",
    "\n",
    "with Pool(processes=3) as p:\n",
    "    examples = p.map(testadder, array)\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:1\")\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 28 20:09:00 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:21:01.0 Off |                    0 |\n",
      "| N/A   28C    P0    54W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:21:02.0 Off |                    0 |\n",
      "| N/A   32C    P0    56W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:21:03.0 Off |                    0 |\n",
      "| N/A   32C    P0    56W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:21:04.0 Off |                    0 |\n",
      "| N/A   28C    P0    56W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  Off  | 00000000:41:01.0 Off |                    0 |\n",
      "| N/A   33C    P0    56W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  Off  | 00000000:41:02.0 Off |                    0 |\n",
      "| N/A   33C    P0    55W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  Off  | 00000000:41:03.0 Off |                    0 |\n",
      "| N/A   37C    P0    58W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  Off  | 00000000:41:04.0 Off |                    0 |\n",
      "| N/A   36C    P0    53W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Check that PyTorch sees it\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../raw_data_extraction/thwiki-20200601-extracted/WikiAD_3.txt\n",
      "../raw_data_extraction/thwiki-20200601-extracted/WikiAE_3.txt\n",
      "../raw_data_extraction/thwiki-20200601-extracted/WikiAF_0.txt\n",
      "../raw_data_extraction/thwiki-20200601-extracted/WikiAF_2.txt\n",
      "../raw_data_extraction/thwiki-20200601-extracted/WikiAD_1.txt\n",
      "thwiki-20200601-extracted Amounts to a total of 566.79 MB\n",
      "../raw_data_extraction/classification_dataset/dailynews_0.txt\n",
      "../raw_data_extraction/classification_dataset/pptv36_0.txt\n",
      "../raw_data_extraction/classification_dataset/prbangkok_0.txt\n",
      "../raw_data_extraction/classification_dataset/siamrath_0.txt\n",
      "../raw_data_extraction/classification_dataset/springnews_0.txt\n",
      "classification_dataset Amounts to a total of 50.79 MB\n",
      "../raw_data_extraction/another_website/khaosod_16.txt\n",
      "../raw_data_extraction/another_website/pantip_470.txt\n",
      "../raw_data_extraction/another_website/pantip_415.txt\n",
      "../raw_data_extraction/another_website/naewna_2.txt\n",
      "../raw_data_extraction/another_website/brighttv_5.txt\n",
      "another_website Amounts to a total of 29552.82 MB\n",
      "../raw_data_extraction/data_lm/Pantipdata_train.csv_351.txt\n",
      "../raw_data_extraction/data_lm/Pantipdata_train.csv_81.txt\n",
      "../raw_data_extraction/data_lm/Pantipdata_train.csv_64.txt\n",
      "../raw_data_extraction/data_lm/Pantipdata_train.csv_118.txt\n",
      "../raw_data_extraction/data_lm/Pantipdata_train.csv_176.txt\n",
      "Senior Project Amounts to a total of 10942.78 MB\n",
      "../raw_data_extraction/social_listening/SocialListeningpantip_post_data.csv_5.txt\n",
      "../raw_data_extraction/social_listening/SocialListeningpantip_post_data.csv_1.txt\n",
      "../raw_data_extraction/social_listening/SocialListeningpantip_post_data.csv_3.txt\n",
      "../raw_data_extraction/social_listening/SocialListeningpantip_post_data.csv_2.txt\n",
      "../raw_data_extraction/social_listening/SocialListeningpantip_post_data.csv_0.txt\n",
      "GuruCrawler Amounts to a total of 171.21 MB\n",
      "\n",
      "I have a total of 1409 files!\n",
      "Amounts to a total of 41284.40 MB\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"..\")\n",
    "\n",
    "# DATA_RAW_PATH = DATA_PATH/\"raw\"\n",
    "DATA_RAW_EXTRACTED_PATH = DATA_PATH/\"raw_data_extraction\"\n",
    "\n",
    "# Output is in bytes - helper from Pathlib Path https://stackoverflow.com/questions/2104080/how-can-i-check-file-size-in-python\n",
    "def getStat(prev_value, cur_value):\n",
    "    if isinstance(prev_value, int):\n",
    "        return prev_value + cur_value.stat().st_size\n",
    "    return prev_value.stat().st_size + cur_value.stat().st_size\n",
    "\n",
    "# 1. The data from thwiki\n",
    "THWIKI_FOLDER = Path(\"thwiki-20200601-extracted\")\n",
    "WIKI_FILES = list((DATA_RAW_EXTRACTED_PATH/THWIKI_FOLDER).glob(\"*.txt\"))\n",
    "list(map(print , WIKI_FILES[:5]))\n",
    "print(f\"thwiki-20200601-extracted Amounts to a total of {reduce(getStat, WIKI_FILES)/1e6:.2f} MB\")\n",
    "\n",
    "# 2. The classification data from jung and ninja\n",
    "CLASSIFICATION_JUNG_NINJA_FOLDER = Path(\"classification_dataset\")\n",
    "CLASSIFICATION_FILES = list((DATA_RAW_EXTRACTED_PATH/CLASSIFICATION_JUNG_NINJA_FOLDER).glob(\"*.txt\"))\n",
    "list(map(print , CLASSIFICATION_FILES[:5]))\n",
    "print(f\"classification_dataset Amounts to a total of {reduce(getStat, CLASSIFICATION_FILES)/1e6:.2f} MB\")\n",
    "\n",
    "# 3. The Data from p'Moo Crawlers\n",
    "ANOTHER_WEBSITE_MOO_FOLDER = Path(\"another_website\")\n",
    "ANOTHER_WEBSITE_FILES = list((DATA_RAW_EXTRACTED_PATH/ANOTHER_WEBSITE_MOO_FOLDER).glob(\"*.txt\"))\n",
    "list(map(print , ANOTHER_WEBSITE_FILES[:5]))\n",
    "print(f\"another_website Amounts to a total of {reduce(getStat, ANOTHER_WEBSITE_FILES)/1e6:.2f} MB\")\n",
    "\n",
    "# 4. Senior Project Files\n",
    "SENIOR_PROJ_FOLDER = Path(\"data_lm\")\n",
    "SENIOR_PROJ_FILES = list((DATA_RAW_EXTRACTED_PATH/SENIOR_PROJ_FOLDER).glob(\"*.txt\"))\n",
    "list(map(print , SENIOR_PROJ_FILES[:5]))\n",
    "print(f\"Senior Project Amounts to a total of {reduce(getStat, SENIOR_PROJ_FILES)/1e6:.2f} MB\")\n",
    "\n",
    "# 5. Guru Crawler Files\n",
    "GURU_CRAWLER_FOLDER = Path(\"social_listening\")\n",
    "GURU_CRAWLER_FILES = list((DATA_RAW_EXTRACTED_PATH/GURU_CRAWLER_FOLDER).glob(\"*.txt\"))\n",
    "list(map(print , GURU_CRAWLER_FILES[:5]))\n",
    "print(f\"GuruCrawler Amounts to a total of {reduce(getStat, GURU_CRAWLER_FILES)/1e6:.2f} MB\")\n",
    "\n",
    "ALL_FILES = WIKI_FILES + CLASSIFICATION_FILES + ANOTHER_WEBSITE_FILES + SENIOR_PROJ_FILES + GURU_CRAWLER_FILES\n",
    "print(f\"\\nI have a total of {len(ALL_FILES)} files!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Amounts to a total of {reduce(getStat, ALL_FILES)/1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Electra Model\n",
    "\n",
    "However, currently pretraining Electra is still inside PR stage  \n",
    "- Issue : When will ELECTRA pretraining from scratch will be available? #3878 https://github.com/huggingface/transformers/issues/3878  \n",
    "- Issue : BERT and other models pretraining from scratch example #4425 https://github.com/huggingface/transformers/issues/4425\n",
    "- PR : Electra training from scratch #4656 https://github.com/huggingface/transformers/pull/4656\n",
    "\n",
    "Combined model\n",
    "- Combines ElectraForMaskedLM and ElectraForPreTraining with embedding sharing + custom masking/replaced token detection\n",
    "\n",
    "Commit before Merge: https://github.com/huggingface/transformers/pull/4656/commits/30b2dbbba6918ac6540b6a1758b7ee19f0ac969c#diff-8a95e2bfb7da25648b5d12ffa69fd7a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import ElectraModel, ElectraConfig\n",
    "\n",
    "# # Initializing a ELECTRA electra-base-uncased style configuration\n",
    "# configuration = ElectraConfig()\n",
    "# configuration.vocab_size = 20000\n",
    "\n",
    "# # Initializing a model from the electra-base-uncased style configuration\n",
    "# model = ElectraModel(configuration)\n",
    "\n",
    "# # Accessing the model configuration\n",
    "# configuration = model.config\n",
    "# configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.num_parameters()\n",
    "# # => 12 million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out Roberta per Notebook \n",
    "\n",
    "From __HuggingFace Notebooks__ https://huggingface.co/transformers/notebooks.html: \n",
    "\n",
    "How to train a language model\tHighlight all the steps to effectively train Transformer model on custom data\n",
    "- Colab (ipynb) version : https://github.com/huggingface/blog/blob/master/notebooks/01_how_to_train.ipynb\n",
    "- MD version: https://github.com/huggingface/blog/blob/master/how-to-train.md\n",
    "\n",
    "Pretrain Longformer\tHow to build a \"long\" version of existing pretrained models\tIz Beltagy  \n",
    "https://github.com/allenai/longformer/blob/master/scripts/convert_model_to_long.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "configuration = RobertaConfig(\n",
    "    vocab_size=30522,\n",
    "    max_position_embeddings=512, # 512 + 2 more special tokens\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=12,\n",
    "    type_vocab_size=1,\n",
    ")\n",
    "# configuration.vocab_size = 20000\n",
    "\n",
    "model = RobertaForMaskedLM(config=configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110104122"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()\n",
    "# => 102 million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tokenizers import Tokenizer\n",
    "# tokenizer = Tokenizer.from_file(\"./thwiki-sentencepiecebpe.tokenizer.json\")\n",
    "# encoded =  tokenizer.encode(u\"สวัสดีครับ ผมชื่อไนท์ ตอนนี้ก็เป็นเวลาที่ผมต้องไปโรงเรียนแล้ว  นี่คือการเว้นวรรคสองทีครับ  จะได้ออกเป็นสอง Spaces\")\n",
    "# print(encoded.ids)\n",
    "# print(encoded.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.enable_truncation(max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded =  tokenizer.encode(u\"สวัสดีครับ ผมชื่อไนท์ ตอนนี้ก็เป็นเวลาที่ผมต้องไปโรงเรียนแล้ว  นี่คือการเว้นวรรคสองทีครับ  จะได้ออกเป็นสอง SpacesWhat is great is that our tokenizer is optimized for Esperanto. Compared to a generic tokenizer trained for English, more native words are represented by a single, unsplit token. Diacritics, i.e. accented characters used in Esperanto – ĉ, ĝ, ĥ, ĵ, ŝ, and ŭ – are encoded natively. We also represent sequences in a more efficient manner. Here on this corpus, the average length of encoded sequences is ~30% smaller as when using the pretrained GPT-2 tokenizer.\")\n",
    "# print(\"This will not be over 128: \", len(encoded.ids), encoded.tokens)\n",
    "# print(encoded.overflowing[0].tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wrap tokenizers inside a PreTrainedTokenizerFast from transformers \n",
    "\n",
    "https://github.com/huggingface/tokenizers/issues/259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SentencePieceBPETokenizerFast(PreTrainedTokenizerFast):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         vocab_file,\n",
    "#         merges_file,\n",
    "#         bos_token=\"<s>\",\n",
    "#         eos_token=\"</s>\",\n",
    "#         sep_token=\"</s>\",\n",
    "#         cls_token=\"<s>\",\n",
    "#         unk_token=\"<unk>\",\n",
    "#         pad_token=\"<pad>\",\n",
    "#         mask_token=\"<mask>\",\n",
    "#         **kwargs\n",
    "#     ):\n",
    "#         super().__init__(\n",
    "#             SentencePieceBPETokenizer(\n",
    "#                 vocab_file=vocab_file,\n",
    "#                 merges_file=merges_file,\n",
    "#             ),\n",
    "#              bos_token=bos_token,\n",
    "#             eos_token=eos_token,\n",
    "#             unk_token=unk_token,\n",
    "#             sep_token=sep_token,\n",
    "#             cls_token=cls_token,\n",
    "#             pad_token=pad_token,\n",
    "#             mask_token=mask_token,\n",
    "#             **kwargs,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # with open(\"./thwiki-sentencepiecebpe.tokenizer.json\", 'r' ) as json_data:\n",
    "# with open(\"./thwiki-charbpe-30522.tokenizer.json\", 'r' ) as json_data:\n",
    "#      data = json.load(json_data)\n",
    "# vocab = data['model']['vocab']\n",
    "# merges = data['model']['merges']\n",
    "\n",
    "\n",
    "# with open('vocab.json', 'w', encoding='utf-8') as json_file:\n",
    "#     json.dump(vocab, json_file, ensure_ascii=False)\n",
    "# with open('merges.txt', 'w', encoding='utf-8') as f:\n",
    "#     for merge_string in merges:\n",
    "#         f.write(f'{merge_string}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain_tokenizer = SentencePieceBPETokenizerFast(vocab_file='vocab.json',merges_file ='merges.txt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "# from tokenizers import Tokenizer\n",
    "# from tokenizers.implementations import BaseTokenizer\n",
    "\n",
    "# tokenizer = Tokenizer.from_file(\"./thwiki-sentencepiecebpe.tokenizer.json\")\n",
    "# base_tokenizer = BaseTokenizer(tokenizer) # Wrapper!! to PretrainTokenizerFast Tokenizer should be an instance of a Tokenizer provided by HuggingFace tokenizers library.\n",
    "# base_tokenizer = SentencePieceBPETokenizer()\n",
    "# pretrain_tokenizer = PreTrainedTokenizerFast(tokenizer=base_tokenizer)\n",
    "# pretrain_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "# from tokenizers import Tokenizer, CharBPETokenizer\n",
    "# from tokenizers.implementations import BaseTokenizer\n",
    "\n",
    "# # tokenizer = Tokenizer.from_file(\"./thwiki-charbpe-30522.tokenizer.json\")\n",
    "# # base_tokenizer = BaseTokenizer(tokenizer) # Wrapper!! to PretrainTokenizerFast Tokenizer should be an instance of a Tokenizer provided by HuggingFace tokenizers library.\n",
    "# base_tokenizer = CharBPETokenizer(vocab_file='vocab.json',merges_file ='merges.txt')\n",
    "# pretrain_tokenizer = PreTrainedTokenizerFast(tokenizer=base_tokenizer)\n",
    "# pretrain_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CANNOT USE FAST BECAUSE multiprocessing Pool doesn't support Rust!!\n",
    "Using %%time, there is almost x7-x10 difference in tokenization but we cannot not allow multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import RobertaTokenizerFast\n",
    "\n",
    "# tokenizer = RobertaTokenizerFast.from_pretrained(\"./thwiki-seniorproj-bytebpe-30522\", max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RobertaTokenizer'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"./thwiki-seniorproj-bytebpe-30522\", max_len=512)\n",
    "tokenizer.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "['à¸ī', 'à¸±', 'à¸Ļà¹Ģà¸Ħà¸¢', 'à¹Ģà¸ģ', 'à¸·', 'à¸Ńà¸ļ', 'à¸ŀà¸¥à¸²à¸Ķ', 'à¸ª', 'à¸´à¹Ī', 'à¸ĩà¸Ĺ', 'à¸µà¹Ī', 'à¸Ķ', 'à¸µ', 'à¸Ĺ', 'à¸µà¹Ī', 'à¸ª', 'à¸¸', 'à¸Ķà¹ĥà¸Ļà¸Ĭ', 'à¸µ', 'à¸§', 'à¸´', 'à¸ķ', 'Ġà¸«à¸²à¸ģ', 'à¹ĥà¸Ļà¸§', 'à¸±', 'à¸Ļà¸Ĺ', 'à¸µà¹Ī', 'à¸ī', 'à¸±', 'à¸Ļà¸¥', 'à¹ī', 'à¸¡à¸Ńà¸¢', 'à¸¹à¹Ī', 'Ġà¹Ħà¸¡', 'à¹Ī', 'à¸¡', 'à¸µ', 'à¸«à¸Ļ', 'à¸¶à¹Ī', 'à¸ĩà¹ĥà¸Ī', 'à¸Ĥà¸Ńà¸ĩà¹Ģà¸ĺà¸Ń', 'Ġà¸Ŀ', 'à¸±', 'à¸Ļà¸Ħ', 'à¸ĩà¸Īà¸ļ', 'Ġà¸«à¸¥à¸²à¸¢', 'à¸ª', 'à¸´à¹Ī', 'à¸ĩà¸Ĺ', 'à¸µà¹Ī', 'à¸Ķ', 'à¸µ', 'à¸Ħ', 'à¸ĩà¸«à¸¡à¸Ķ', 'à¸Ĺà¸²à¸ĩ', 'à¹Ħà¸Ķ', 'à¹ī', 'à¹Ģà¸Īà¸Ń', 'Ġà¸«à¸Ļ', 'à¸¶à¹Ī', 'à¸ĩà¸ģ', 'à', '¸', '³', 'à¸¥', 'à¸±', 'à¸ĩà¹ĥà¸Īà¸Ĺ', 'à¸µà¹Ī', 'à¸¢', 'à¸´à¹Ī', 'à¸ĩà¹ĥà¸«à¸į', 'à¹Ī', 'Ġà¹Ħà¸¡', 'à¹Ī', 'à¸¥', 'à¸·', 'à¸¡à¹Ħà¸Ķ', 'à¹ī', 'à¹Ģà¸¥à¸¢', '...', 'Ġà¹ĥà¸Ħà¸£à¹Ģà¸Ħà¸¢à¸¡', 'à¸µ', 'à¹ģà¸Łà¸Ļà¸Ĺ', 'à¸µà¹Ī', 'à¸ģ', 'à¸´', 'à¸Ļà¸Ńà¸²à¸«à¸²à¸£', 'à¹Ħà¸¡', 'à¹Ī', 'à¸ĸ', 'à¸¹', 'à¸ģà¸Ľ', 'à¸²à¸ģà¸ģ', 'à¸±', 'à¸Ļà¹ģà¸¥', 'à¹ī', 'à¸§à¸£', 'à¸¹à¹ī', 'à¸ª', 'à¸¶', 'à¸ģà¹Ģà¸ª', 'à¸µ', 'à¸¢', 'à¸Ħà¸§à¸²à¸¡à¸ª', 'à¸¸', 'à¸Ĥ', 'à¹Ħà¸Ľà¸Ńà¸¢', 'à¹Ī', 'à¸²à¸ĩà¸Ļ', 'à¸¶', 'à¸ĩà¸ļ', 'à¹ī', 'à¸²à¸ĩà¸¡', 'à¸±à¹ī', 'à¸¢à¸Ħà¸£', 'à¸±', 'à¸ļ', 'Ġ', 'Ġà¸ģ', 'à¹Ī', 'à¸Ńà¸Ļà¸Ń', 'à¸·à¹Ī', 'à¸Ļà¸ľà¸¡à¸ķ', 'à¹ī', 'à¸Ńà¸ĩà¸ļà¸Ńà¸ģà¸ģ', 'à¹Ī', 'à¸Ńà¸Ļà¹Ģà¸¥à¸¢à¸§', 'à¹Ī', 'à¸²à¸Ħ', 'à¸Ļà¹Ģà¸£', 'à¸²à¸Īà¸°à¹Ģà¸¥', 'à¸·', 'à¸Ńà¸ģà¸ģ', 'à¸´', 'à¸Ļà¸Ńà¸²à¸«à¸²à¸£', 'à¹ģà¸ļà¸ļà¹Ħà¸«à¸Ļ', 'à¸Ĭà¸Ńà¸ļ', 'à¹ģà¸ļà¸ļà¹Ħà¸«à¸Ļ', 'à¹Ģà¸Ľ', 'à¹ĩ', 'à¸Ļà¹Ģà¸£', 'à¸·à¹Ī', 'à¸Ńà¸ĩà¸Ĥà¸Ńà¸ĩ', 'à¸Ħà¸§à¸²à¸¡', 'à¸Ĭà¸Ńà¸ļà¸ª', 'à¹Ī', 'à¸§à¸Ļà¸ķ', 'à¸±', 'à¸§à¸Ļà¸°à¸Ħà¸£', 'à¸±', 'à¸ļà¸Ĺ', 'à¸¸', 'à¸ģà¸Ħà¸Ļà¸¡', 'à¸µ', 'à¸ª', 'à¸´', 'à¸Ĺà¸ĺ', 'à¸´', 'à¹ĥà¸Ļà¸ģà¸²à¸£à¹Ģà¸¥', 'à¸·', 'à¸Ńà¸ģ', 'à¸Ĥà¸Ńà¸ĩà¸Ĺ', 'à¸µà¹Ī', 'à¸Ĭà¸Ńà¸ļ', 'à¹ģà¸¥à¸°à¹Ħà¸¡', 'à¹Ī', 'à¸Ĭà¸Ńà¸ļà¸Ńà¸¢', 'à¸¹à¹Ī', 'à¹ģà¸¥', 'à¹ī', 'à¸§', 'Ġà¹ģà¸ķ', 'à¹Ī', 'à¸ľà¸¡à¸£', 'à¸¹à¹ī', 'à¸ª', 'à¸¶', 'à¸ģà¸§', 'à¹Ī', 'à¸²à¸ķà¸Ńà¸Ļà¸Ļ', 'à¸µà¹ī', 'à¸ľà¸¡à¸ģ', 'à', '¸', '³', 'à¸¥', 'à¸±', 'à¸ĩ', 'à¸Ľà¸£à¸°à¸ªà¸ļà¸Ľ', 'à¸±', 'à¸įà¸«à¸²à¸Ĺ', 'à¸µà¹Ī', 'à¸Ķ', 'à¸¹', 'à¹Ģà¸«à¸¡', 'à¸·', 'à¸Ńà¸Ļà¸Īà¸°à¹Ģà¸¥', 'à¹ĩ', 'à¸ģà¹ģà¸ķ', 'à¹Ī', 'à¸ģà¸¥à¸²à¸¢à¹Ģà¸Ľ', 'à¹ĩ', 'à¸Ļà¸§', 'à¹Ī', 'à¸²à¸¡', 'à¸±', 'à¸Ļà¸Ħ', 'à¹Ī', 'à¸Ńà¸Ļà¸Ĥ', 'à¹ī', 'à¸²à¸ĩà¹ĥà¸«à¸į', 'à¹Ī', 'Ġà¸ľà¸¡', 'à¸Ħà¸ļà¸ģ', 'à¸±', 'à¸ļà¹ģà¸Łà¸Ļà¸¡à¸²', '6', 'à¸Ľ', 'à¸µ', 'à¹ģà¸¥', 'à¹ī', 'à¸§à¸Ħà¸£', 'à¸±', 'à¸ļ', 'Ġà¸ľà¸¡à¹Ģà¸Ľ', 'à¹ĩ', 'à¸Ļà¸Ħà¸Ļ', 'à¸Ĭà¸Ńà¸ļà¸ģ', 'à¸´', 'à¸Ļà¸Ńà¸²à¸«à¸²à¸£', 'à¸į', 'à¸µà¹Ī', 'à¸Ľ', 'à¸¸à¹Ī', 'à¸Ļà¹ģà¸¥à¸°', 'à¸Ľà¸¥à¸²à¸Ķ', 'à¸´', 'à¸ļà¹ģà¸ķ', 'à¹Ī', 'à¹ģà¸Łà¸Ļ', 'à¸ľà¸¡à¹Ħà¸¡', 'à¹Ī', 'à¸ģ', 'à¸´', 'à¸Ļà¸Ľà¸¥', 'à¸²à¸Ķ', 'à¸´', 'à¸ļà¹Ģà¸¥à¸¢', 'Ġà¸ľà¸¡', 'à¸Ńà¸¢à¸²à¸ģà¸ģ', 'à¸´', 'à¸Ļà¸ļ', 'à¸¸', 'à¸Łà¹Ģà¸Ł', 'à¹Ī', 'à¹Ģà¸Ļ', 'à¸·à¹ī', 'à¸Ńà¹ģà¸ķ', 'à¹Ī', 'à¹ģà¸Łà¸Ļà¸ľà¸¡à¸ģ', 'à¹ĩ', 'à¹Ħà¸¡', 'à¹Ī', 'à¸ģ', 'à¸´', 'à¸Ļà¹Ģà¸Ļ', 'à¸·à¹ī', 'à¸Ń', 'Ġà¹Ģà¸£à¸²à¹Ģà¸¥à¸¢à¹Ħà¸¡', 'à¹Ī', 'à¹Ħà¸Ķ', 'à¹ī', 'à¹Ģà¸Ĥ', 'à¹ī', 'à¸²à¸Ĺ', 'à¸²à¸Ļà¸£', 'à¹ī', 'à¸²à¸Ļà¸ļ', 'à¸¸', 'à¸Łà¹Ģà¸Ł', 'à¹Ī', 'à¹Ģà¸Ļ', 'à¸·à¹ī', 'à¸Ńà¹ģà¸¥à¸°', 'à¸ļ', 'à¸¸', 'à¸Łà¹Ģà¸Ł', 'à¹Ī', 'à¸Ńà¸²à¸«à¸²à¸£à¸į', 'à¸µà¹Ī', 'à¸Ľ', 'à¸¸à¹Ī', 'à¸Ļà¸ģ', 'à¸±', 'à¸Ļà¹Ģà¸ŀà¸£à¸²à¸°', 'à¸£', 'à¸¹à¹ī', 'à¸ª', 'à¸¶', 'à¸ģà¸¥', 'à¸±', 'à¸§', 'à¹ģà¸Łà¸Ļà¸ľà¸¡', 'à¸Ĺà¸²à¸Ļ', 'à¹Ħà¸¡', 'à¹Ī', 'à¸Ħ', 'à¸¸à¹ī', 'à¸¡', 'Ġà¹ģà¸¥à¸°à¹Ģà¸£', 'à¸·à¹Ī', 'à¸Ńà¸ĩà¹ĥà¸«à¸į', 'à¹Ī', 'à¹Ģà¸¥à¸¢à¸Ħ', 'à¸·', 'à¸Ńà¸ľà¸¡à¹Ģà¸Ľ', 'à¹ĩ', 'à¸Ļà¸Ħà¸Ļà¸Ĭà¸Ńà¸ļ', 'à¸Ĺà¸²à¸Ļà¸Ńà¸²à¸«à¸²à¸£', 'à¸£à¸ª', 'à¸Ī', 'à¸±', 'à¸Ķà¹ģà¸¥à¸°', 'à¸£à¸ª', 'à¹Ģà¸ľ', 'à¹ĩ', 'à¸Ķà¸¡à¸²à¸ģ', 'Ġà¹ģà¸ķ', 'à¹Ī', 'à¹ģà¸Łà¸Ļà¸ľà¸¡', 'à¸Ĺà¸²à¸Ļ', 'à¹Ģà¸ľ', 'à¹ĩ', 'à¸Ķà¹Ħà¸¡', 'à¹Ī', 'à¹Ħà¸Ķ', 'à¹ī', 'à¹Ģà¸¥à¸¢', 'à¹Ģà¸§à¸¥à¸²', 'à¹Ģà¸£à¸²à¹Ħà¸Ľà¸ģ', 'à¸´', 'à¸Ļà¸ª', 'à¹ī', 'à¸¡à¸ķ', 'à', '¸', '³', 'à¸ģ', 'à¸±', 'à¸Ļà¸ģ', 'à¹ĩ', 'à¸Īà¸°à¸ª', 'à¸±à¹Ī', 'à¸ĩ', 'Ġà¸ª', 'à¹ī', 'à¸¡à¸ķ', 'à', '¸', '³', 'à¹Ħà¸¡', 'à¹Ī', 'à¹ĥà¸ª', 'à¹Ī', 'à¸ŀà¸£', 'à¸´', 'à¸ģ', 'Ġà¸ķ', 'à¹ī', 'à¸¡', 'à¹ģà¸ĭ', 'à¹Ī', 'à¸ļà¹Ħà¸¡', 'à¹Ī', 'à¹ĥà¸ª', 'à¹Ī', 'à¸ŀà¸£', 'à¸´', 'à¸ģ', 'Ġà¸¥', 'à¸²à¸ļ', 'à¹Ħà¸¡', 'à¹Ī', 'à¹ĥà¸ª', 'à¹Ī', 'à¸ŀà¸£', 'à¸´', 'à¸ģ', 'Ġà¸£', 'à¹ī', 'à¸²à¸Ļà¸ģ', 'à¸±', 'à¸ļà¸Ĥ', 'à¹ī', 'à¸²à¸§à¸Ń', 'à¸·à¹Ī', 'à¸Ļà¹Ĩà¸ģ', 'à¹ĩ', 'à¹Ģà¸Ĭ', 'à¹Ī', 'à¸Ļà¸ģ', 'à¸±', 'à¸Ļà¹ģà¸Łà¸Ļ', 'à¸ľà¸¡à¸Īà¸°à¹Ħà¸¡', 'à¹Ī', 'à¸Ĭà¸Ńà¸ļà¸ģ', 'à¸´', 'à¸Ļà¸ľ', 'à¸±', 'à¸ģà¹Ħà¸¡', 'à¹Ī', 'à¸Ħ', 'à¹Ī', 'à¸Ńà¸¢à¸ª', 'à¸±à¹Ī', 'à¸ĩà¸ģ', 'à¸±', 'à¸ļà¸Ĥ', 'à¹ī', 'à¸²à¸§à¸Ĺ', 'à¸µà¹Ī', 'à¹Ģà¸Ľ', 'à¹ĩ', 'à¸Ļà¸ľ', 'à¸±', 'à¸ģà¹ģà¸¥', 'à¹ī', 'à¸§à¸ľà¸¡', 'à¸Ĭà¸Ńà¸ļà¸ľ', 'à¸±', 'à¸ģà¸ļ', 'à¸¸à¹ī', 'à¸ĩà¸Ĺà¸Ńà¸Ķ', 'à¸ģà¸£à¸Ńà¸ļ', 'Ġà¹Ģà¸«', 'à¹ĩ', 'à¸Ķà¸«', 'à¸Ńà¸¡', 'à¸ªà¸Ķ', 'à¸Ĺà¸Ńà¸Ķ', 'à¸¡à¸²à¸ģ', 'Ġà¹ģà¸ķ', 'à¹Ī', 'à¸ģ', 'à¹ĩ', 'à¹Ħà¸¡', 'à¹Ī', 'à¹Ħà¸Ķ', 'à¹ī', 'à¸ª', 'à¸±à¹Ī', 'à¸ĩ', 'à¹Ģà¸ŀà¸£à¸²à¸°à¸§', 'à¹Ī', 'à¸²à¹Ģà¸ĺà¸Ńà¹Ħà¸¡', 'à¹Ī', 'à¸ģ', 'à¸´', 'à¸Ļà¸ĸ', 'à¸¶', 'à¸ĩà¹Ģà¸Ħ', 'à¹ī', 'à¸²à¸Īà¸°', 'à¸ļà¸Ńà¸ģà¹ĥà¸«', 'à¹ī', 'à¸ª', 'à¸±à¹Ī', 'à¸ĩà¹Ģà¸¥à¸¢', 'à¹Ĩà¸ģ', 'à¹ĩ', 'à¹Ģà¸ĸà¸Ńà¸°', 'à¹ģà¸ķ', 'à¹Ī', 'à¸ľà¸¡à¸ģ', 'à¹ĩ', 'à¸¢', 'à¸±', 'à¸ĩà¹Ģà¸ģà¸£', 'à¸ĩà¹ĥà¸Ī', 'à¹Ģà¸ĺà¸Ńà¸Ńà¸¢', 'à¸¹à¹Ī', 'à¸Ķ', 'à¸µ', 'à¸Ń', 'à¹Ī', 'à¸°à¸Ħà¸£', 'à¸±', 'à¸ļ', 'Ġà¸ľà¸¡à¸£', 'à¸¹à¹ī', 'à¸ª', 'à¸¶', 'à¸ģà¸ģ', 'à¸´', 'à¸Ļà¸Ńà¸²à¸«à¸²à¸£', 'à¹Ħà¸¡', 'à¹Ī', 'à¸¡', 'à¸µ', 'à¸Ħà¸§à¸²à¸¡à¸ª', 'à¸¸', 'à¸Ĥ', 'à¹Ģà¸¥à¸¢à¸Ĭ', 'à¸µ', 'à¸§', 'à¸´', 'à¸ķà¸ľà¸¡', 'à¸Ĥà¸²à¸Ķ', 'à¸£à¸ª', 'à¹Ģà¸ľ', 'à¹ĩ', 'à¸Ķà¹Ħà¸Ľ', 'à¹Ģà¸«à¸¡', 'à¸·', 'à¸Ńà¸Ļà¸Īà¸°', 'à¸Ĥà¸²à¸Ķ', 'à¹ĥà¸Īà¹Ģà¸«à¸¡', 'à¸·', 'à¸Ńà¸Ļà¸¡', 'à¸±', 'à¸Ļà¸Ĺ', 'à', '¸', '³', 'à¹ĥà¸«', 'à¹ī', 'à¸Ĥà¸²à¸Ķ', 'à¸Ħà¸§à¸²à¸¡à¸ª', 'à¸¸', 'à¸Ĥ', 'à¹Ħà¸Ľà¸Ńà¸¢', 'à¹Ī', 'à¸²à¸ĩà¸Ļ', 'à¸¶', 'à¸ĩà¹Ģà¸¥à¸¢', 'à¸Ń', 'à¹Ī', 'à¸°à¸Ħà¸£', 'à¸±', 'à¸ļ', 'Ġà¸¢', 'à¸´à¹Ī', 'à¸ĩà¸ĸ', 'à¹ī', 'à¸²à¹Ģà¸£à¸²', 'à¹ģà¸ķ', 'à¹Ī', 'à¸ĩà¸ĩà¸²à¸Ļà¸ģ', 'à¸±', 'à¸Ļà¹ģà¸¥', 'à¹ī', 'à¸§à¸ľà¸¡à¸ģ', 'à¹ĩ', 'à¸Ńà¸²à¸Īà¸Īà¸°à¸ķ', 'à¹ī', 'à¸Ńà¸ĩà¸¡', 'à¸µ', 'à¸Ľ', 'à¸±', 'à¸įà¸«à¸²à¹Ģà¸£', 'à¸·à¹Ī', 'à¸Ńà¸ĩà¸Ļ', 'à¸µà¹ī', 'à¸¡à¸²à¸ģà¸Ĥ', 'à¸¶à¹ī', 'à¸Ļ', 'Ġà¸ŀà¸Ń', 'à¸ľà¸¡à¹Ģà¸«', 'à¹ĩ', 'à¸Ļà¸Ħ', 'à¸¹à¹Ī', 'à¸Ĺ', 'à¸µà¹Ī', 'à¸Ĭà¸Ńà¸ļ', 'à¸Ĺà¸²à¸Ļà¸Ńà¸²à¸«à¸²à¸£', 'à¹Ģà¸«à¸¡', 'à¸·', 'à¸Ńà¸Ļà¹Ĩà¸ģ', 'à¸±', 'à¸Ļà¹Ģà¸«', 'à¹ĩ', 'à¸Ļà¹Ģà¸Ħ', 'à¹ī', 'à¸²à¸ģ', 'à¸´', 'à¸Ļà¸Ńà¸²à¸«à¸²à¸£', 'à¸ģ', 'à¸±', 'à¸Ļà¸Ńà¸¢', 'à¹Ī', 'à¸²à¸ĩà¸¡', 'à¸µ', 'à¸Ħà¸§à¸²à¸¡à¸ª', 'à¸¸', 'à¸Ĥà¹ģà¸¥', 'à¹ī', 'à¸§à¸ľà¸¡', 'à¸£', 'à¸¹à¹ī', 'à¸ª', 'à¸¶', 'à¸ģà¸Ń', 'à¸´', 'à¸Īà¸ī', 'à¸²à¸¡à¸²à¸ģà¹Ĩ', 'à¹Ģà¸¥à¸¢', 'Ġà¸¡', 'à¸µ', 'à¹ĥà¸Ħà¸£à¹Ģà¸Ħà¸¢à¸¡', 'à¸µ', 'à¸Ľ', 'à¸±', 'à¸įà¸«à¸²', 'à¹ģà¸ļà¸ļ', 'à¸ľà¸¡à¸¡', 'à¸±à¹ī', 'à¸¢à¸Ħà¸£', 'à¸±', 'à¸ļà¹ģà¸¥', 'à¹ī', 'à¸§à¸Īà¸°', 'à¹ģà¸ģ', 'à¹ī', 'à¸Ľ', 'à¸±', 'à¸įà¸«à¸²à¸Ļ', 'à¸µà¹ī', 'à¸¢', 'à¸±', 'à¸ĩà¹Ħà¸ĩà¸Ķ', 'à¸µ', 'à¸Ħà¸£', 'à¸±', 'à¸ļ'] with length 634\n",
      "[603, 278, 5385, 397, 314, 374, 1835, 312, 443, 490, 322, 296, 286, 303, 322, 312, 326, 10540, 286, 288, 308, 306, 1479, 1985, 278, 405, 322, 603, 278, 946, 272, 3477, 403, 477, 268, 282, 286, 368, 489, 1104, 6914, 1912, 278, 535, 13790, 2928, 312, 443, 490, 322, 296, 286, 292, 1290, 605, 354, 272, 902, 833, 489, 527, 161, 121, 116, 301, 278, 6438, 322, 290, 443, 3637, 268, 477, 268, 301, 314, 2071, 272, 402, 631, 18843, 286, 6011, 322, 280, 308, 3688, 339, 268, 348, 324, 1627, 9890, 278, 1047, 272, 712, 371, 312, 356, 2557, 286, 290, 995, 326, 328, 4066, 268, 964, 356, 935, 272, 1511, 363, 1355, 278, 294, 225, 395, 268, 2293, 351, 21531, 272, 8478, 268, 11239, 268, 377, 807, 4699, 314, 3267, 308, 3688, 4083, 641, 4083, 357, 320, 807, 351, 1548, 420, 10028, 268, 1135, 278, 5178, 278, 685, 326, 5069, 286, 312, 308, 758, 308, 7475, 314, 364, 1992, 322, 641, 3550, 268, 12850, 403, 346, 272, 288, 414, 268, 3035, 371, 312, 356, 468, 268, 2927, 365, 1059, 161, 121, 116, 301, 278, 284, 12093, 278, 3968, 322, 296, 324, 585, 314, 28114, 320, 3176, 268, 2204, 320, 574, 268, 342, 278, 535, 268, 1330, 272, 9493, 268, 534, 2286, 278, 13748, 26, 318, 286, 346, 272, 1294, 278, 294, 4195, 320, 810, 4697, 308, 3688, 383, 322, 318, 474, 1475, 20980, 308, 2686, 268, 728, 1687, 268, 280, 308, 4311, 456, 308, 4075, 534, 6894, 308, 771, 326, 4122, 268, 494, 464, 3345, 268, 24452, 320, 339, 268, 280, 308, 2000, 464, 270, 12811, 268, 354, 272, 393, 272, 384, 2828, 272, 3181, 326, 4122, 268, 494, 464, 3285, 294, 326, 4122, 268, 9971, 322, 318, 474, 492, 278, 1760, 276, 371, 312, 356, 421, 278, 288, 7050, 1666, 339, 268, 292, 639, 282, 5655, 351, 5656, 268, 868, 314, 10636, 320, 6743, 14456, 2080, 316, 278, 3959, 2080, 1180, 320, 1943, 414, 268, 7050, 1666, 1180, 320, 1798, 268, 354, 272, 402, 936, 17531, 308, 528, 272, 1027, 161, 121, 116, 280, 278, 492, 320, 2653, 454, 284, 412, 272, 1027, 161, 121, 116, 339, 268, 677, 268, 662, 308, 280, 429, 272, 282, 1979, 268, 1461, 268, 677, 268, 662, 308, 280, 622, 521, 339, 268, 677, 268, 662, 308, 280, 448, 272, 1333, 278, 1369, 272, 4798, 351, 5715, 320, 503, 268, 492, 278, 3720, 21612, 268, 4697, 308, 938, 278, 1588, 268, 292, 268, 2770, 454, 527, 278, 1369, 272, 2647, 322, 357, 320, 938, 278, 1586, 272, 2123, 6247, 278, 1700, 639, 21067, 2209, 694, 320, 2030, 419, 620, 7745, 425, 414, 268, 280, 320, 339, 268, 354, 272, 312, 454, 284, 3800, 268, 18992, 268, 280, 308, 1037, 356, 3080, 272, 491, 2992, 272, 312, 454, 2234, 1416, 320, 2393, 369, 268, 1059, 320, 290, 278, 20143, 1104, 13811, 403, 296, 286, 270, 268, 1040, 278, 294, 3844, 371, 312, 356, 566, 308, 3688, 339, 268, 282, 286, 995, 326, 328, 19345, 286, 288, 308, 16391, 1999, 2080, 1180, 320, 1606, 585, 314, 2150, 1999, 23052, 314, 1669, 278, 405, 161, 121, 116, 362, 272, 1999, 995, 326, 328, 4066, 268, 964, 356, 2234, 270, 268, 1040, 278, 294, 604, 443, 1515, 272, 1363, 369, 268, 4721, 278, 1047, 272, 4792, 320, 10796, 272, 842, 286, 318, 278, 4356, 351, 724, 365, 2297, 498, 267, 1031, 6183, 320, 535, 403, 303, 322, 641, 14456, 585, 314, 7872, 278, 4234, 320, 2254, 272, 329, 308, 3688, 280, 278, 785, 268, 1511, 286, 995, 326, 27626, 272, 2123, 276, 371, 312, 356, 1553, 308, 3105, 4090, 402, 409, 286, 15756, 286, 318, 278, 1701, 475, 2287, 363, 1355, 278, 2559, 272, 2010, 652, 272, 318, 278, 4854, 365, 290, 278, 1718, 286, 349, 278, 294] with length 634\n",
      "[0, 603, 278, 5385, 397, 314, 374, 1835, 312, 443, 490, 322, 296, 286, 303, 322, 312, 326, 10540, 286, 288, 308, 306, 1479, 1985, 278, 405, 322, 603, 278, 946, 272, 3477, 403, 477, 268, 282, 286, 368, 489, 1104, 6914, 1912, 278, 535, 13790, 2928, 312, 443, 490, 322, 296, 286, 292, 1290, 605, 354, 272, 902, 833, 489, 527, 161, 121, 116, 301, 278, 6438, 322, 290, 443, 3637, 268, 477, 268, 301, 314, 2071, 272, 402, 631, 18843, 286, 6011, 322, 280, 308, 3688, 339, 268, 348, 324, 1627, 9890, 278, 1047, 272, 712, 371, 312, 356, 2557, 286, 290, 995, 326, 328, 4066, 268, 964, 356, 935, 272, 1511, 363, 1355, 278, 294, 225, 395, 268, 2293, 351, 21531, 272, 8478, 268, 11239, 268, 377, 807, 4699, 314, 3267, 308, 3688, 4083, 641, 4083, 357, 320, 807, 351, 1548, 420, 10028, 268, 1135, 278, 5178, 278, 685, 326, 5069, 286, 312, 308, 758, 308, 7475, 314, 364, 1992, 322, 641, 3550, 268, 12850, 403, 346, 272, 288, 414, 268, 3035, 371, 312, 356, 468, 268, 2927, 365, 1059, 161, 121, 116, 301, 278, 284, 12093, 278, 3968, 322, 296, 324, 585, 314, 28114, 320, 3176, 268, 2204, 320, 574, 268, 342, 278, 535, 268, 1330, 272, 9493, 268, 534, 2286, 278, 13748, 26, 318, 286, 346, 272, 1294, 278, 294, 4195, 320, 810, 4697, 308, 3688, 383, 322, 318, 474, 1475, 20980, 308, 2686, 268, 728, 1687, 268, 280, 308, 4311, 456, 308, 4075, 534, 6894, 308, 771, 326, 4122, 268, 494, 464, 3345, 268, 24452, 320, 339, 268, 280, 308, 2000, 464, 270, 12811, 268, 354, 272, 393, 272, 384, 2828, 272, 3181, 326, 4122, 268, 494, 464, 3285, 294, 326, 4122, 268, 9971, 322, 318, 474, 492, 278, 1760, 276, 371, 312, 356, 421, 278, 288, 7050, 1666, 339, 268, 292, 639, 282, 5655, 351, 5656, 268, 868, 314, 10636, 320, 6743, 14456, 2080, 316, 278, 3959, 2080, 1180, 320, 1943, 414, 268, 7050, 1666, 1180, 320, 1798, 268, 354, 272, 402, 936, 17531, 308, 528, 272, 1027, 161, 121, 116, 280, 278, 492, 320, 2653, 454, 284, 412, 272, 1027, 161, 121, 116, 339, 268, 677, 268, 662, 308, 280, 429, 272, 282, 1979, 268, 1461, 268, 677, 268, 662, 308, 280, 622, 521, 339, 268, 677, 268, 662, 308, 280, 448, 272, 1333, 278, 1369, 272, 4798, 351, 5715, 320, 503, 268, 492, 278, 3720, 21612, 268, 4697, 308, 938, 278, 1588, 268, 292, 268, 2770, 454, 527, 278, 1369, 272, 2647, 322, 357, 320, 938, 278, 1586, 272, 2123, 6247, 278, 1700, 639, 21067, 2209, 694, 320, 2030, 419, 620, 7745, 425, 414, 268, 280, 320, 339, 268, 354, 272, 312, 454, 284, 3800, 268, 18992, 268, 280, 308, 1037, 356, 3080, 272, 491, 2992, 272, 312, 454, 2234, 1416, 320, 2393, 369, 268, 1059, 320, 290, 278, 20143, 1104, 13811, 403, 296, 286, 270, 268, 1040, 278, 294, 3844, 371, 312, 356, 566, 308, 3688, 339, 268, 282, 286, 995, 326, 328, 19345, 286, 288, 308, 16391, 1999, 2080, 1180, 320, 1606, 585, 314, 2150, 1999, 23052, 314, 1669, 278, 405, 161, 121, 116, 362, 272, 1999, 995, 326, 328, 4066, 268, 964, 356, 2234, 270, 268, 1040, 278, 294, 604, 443, 1515, 272, 1363, 369, 268, 4721, 278, 1047, 272, 4792, 320, 10796, 272, 842, 286, 318, 278, 4356, 351, 724, 365, 2297, 498, 267, 1031, 6183, 320, 535, 403, 303, 322, 641, 14456, 585, 314, 7872, 278, 4234, 320, 2254, 272, 329, 308, 3688, 280, 278, 785, 268, 1511, 286, 995, 326, 27626, 272, 2123, 276, 371, 312, 356, 1553, 308, 3105, 4090, 402, 409, 286, 15756, 286, 318, 278, 1701, 475, 2287, 363, 1355, 278, 2559, 272, 2010, 652, 272, 318, 278, 4854, 365, 290, 278, 1718, 286, 349, 278, 294, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.cls_token_id)\n",
    "print(tokenizer.num_special_tokens_to_add())\n",
    "tokenized_text = tokenizer.tokenize(\"ฉันเคยเกือบพลาดสิ่งที่ดีที่สุดในชีวิต หากในวันที่ฉันล้มอยู่ ไม่มีหนึ่งใจของเธอ ฝันคงจบ หลายสิ่งที่ดีคงหมดทางได้เจอ หนึ่งกำลังใจที่ยิ่งใหญ่ ไม่ลืมได้เลย... ใครเคยมีแฟนที่กินอาหารไม่ถูกปากกันแล้วรู้สึกเสียความสุขไปอย่างนึงบ้างมั้ยครับ  ก่อนอื่นผมต้องบอกก่อนเลยว่าคนเราจะเลือกกินอาหารแบบไหนชอบแบบไหนเป็นเรื่องของความชอบส่วนตัวนะครับทุกคนมีสิทธิในการเลือกของที่ชอบและไม่ชอบอยู่แล้ว แต่ผมรู้สึกว่าตอนนี้ผมกำลังประสบปัญหาที่ดูเหมือนจะเล็กแต่กลายเป็นว่ามันค่อนข้างใหญ่ ผมคบกับแฟนมา6ปีแล้วครับ ผมเป็นคนชอบกินอาหารญี่ปุ่นและปลาดิบแต่แฟนผมไม่กินปลาดิบเลย ผมอยากกินบุฟเฟ่เนื้อแต่แฟนผมก็ไม่กินเนื้อ เราเลยไม่ได้เข้าทานร้านบุฟเฟ่เนื้อและบุฟเฟ่อาหารญี่ปุ่นกันเพราะรู้สึกลัวแฟนผมทานไม่คุ้ม และเรื่องใหญ่เลยคือผมเป็นคนชอบทานอาหารรสจัดและรสเผ็ดมาก แต่แฟนผมทานเผ็ดไม่ได้เลยเวลาเราไปกินส้มตำกันก็จะสั่ง ส้มตำไม่ใส่พริก ต้มแซ่บไม่ใส่พริก ลาบไม่ใส่พริก ร้านกับข้าวอื่นๆก็เช่นกันแฟนผมจะไม่ชอบกินผักไม่ค่อยสั่งกับข้าวที่เป็นผักแล้วผมชอบผักบุ้งทอดกรอบ เห็ดหอมสดทอดมาก แต่ก็ไม่ได้สั่งเพราะว่าเธอไม่กินถึงเค้าจะบอกให้สั่งเลยๆก็เถอะแต่ผมก็ยังเกรงใจเธออยู่ดีอ่ะครับ ผมรู้สึกกินอาหารไม่มีความสุขเลยชีวิตผมขาดรสเผ็ดไปเหมือนจะขาดใจเหมือนมันทำให้ขาดความสุขไปอย่างนึงเลยอ่ะครับ ยิ่งถ้าเราแต่งงานกันแล้วผมก็อาจจะต้องมีปัญหาเรื่องนี้มากขึ้น พอผมเห็นคู่ที่ชอบทานอาหารเหมือนๆกันเห็นเค้ากินอาหารกันอย่างมีความสุขแล้วผมรู้สึกอิจฉามากๆเลย มีใครเคยมีปัญหาแบบผมมั้ยครับแล้วจะแก้ปัญหานี้ยังไงดีครับ\")\n",
    "print(f\"{tokenized_text} with length {len(tokenized_text)}\")\n",
    "tokenized_text = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "print(f\"{tokenized_text} with length {len(tokenized_text)}\")\n",
    "print(tokenizer.build_inputs_with_special_tokens(tokenized_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing tokenizer wrapper based on [@theblackcat102 #259](https://github.com/huggingface/tokenizers/issues/259#issuecomment-625905930)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RobertaTokenizerFast(PreTrainedTokenizerFast):\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         vocab_file,\n",
    "#         merges_file,\n",
    "#         bos_token=\"<s>\",\n",
    "#         eos_token=\"</s>\",\n",
    "#         sep_token=\"</s>\",\n",
    "#         cls_token=\"<s>\",\n",
    "#         unk_token=\"<unk>\",\n",
    "#         pad_token=\"<pad>\",\n",
    "#         mask_token=\"<mask>\",\n",
    "#         **kwargs\n",
    "#     ):\n",
    "#         super().__init__(\n",
    "#             ByteLevelBPETokenizer(vocab_file=vocab_file,\n",
    "#                                     merges_file=merges_file,\n",
    "#                                   lowercase=True,                 # adds lowercase to normalizer\n",
    "#                                   unicode_normalizer=\"nfkc\",      # adds unicode normalizer nfkc to normalizer\n",
    "#                                   add_prefix_space=True,          # add space to the first word\n",
    "#                                  ),\n",
    "#              bos_token=bos_token,\n",
    "#             eos_token=eos_token,\n",
    "#             unk_token=unk_token,\n",
    "#             sep_token=sep_token,\n",
    "#             cls_token=cls_token,\n",
    "#             pad_token=pad_token,\n",
    "#             mask_token=mask_token,\n",
    "#             **kwargs,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer3 = RobertaTokenizerFast(vocab_file= \"./thwiki-seniorproj-bytebpe-30522/vocab.json\",\n",
    "#                                  merges_file=\"./thwiki-seniorproj-bytebpe-30522/merges.txt\")\n",
    "# print(tokenizer3.num_special_tokens_to_add())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer2 = Tokenizer.from_file(\"./thwiki-seniorproj-bytebpe-30522.tokenizer.json\")\n",
    "# tokenizer2.num_special_tokens_to_add(is_pair=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer2.normalize(\"asdpo qweasd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our dataset\n",
    "\n",
    "Build it with `from torch.utils.data.dataset import Dataset` just like [TextDataset](https://github.com/huggingface/transformers/blob/448c467256332e4be8c122a159b482c1ef039b98/src/transformers/data/datasets/language_modeling.py) and [LineByLineTextDataset](https://github.com/huggingface/transformers/blob/448c467256332e4be8c122a159b482c1ef039b98/src/transformers/data/datasets/language_modeling.py#L78)\n",
    "\n",
    "Note: Training with multiple files is currently not supported [issue/3445](https://github.com/huggingface/transformers/issues/3445)\n",
    "\n",
    "padding documentation [link](https://github.com/huggingface/tokenizers/blob/master/bindings/python/tokenizers/implementations/base_tokenizer.py#L52)\n",
    "\n",
    "Potential Improvements\n",
    "- การทำให้ Dataset นั้น dynamically tokenize + dynamically open file : ตอนนี้เวลาทำ Dataset จาก torch.utils.data.dataset จะทำการ tokenize เลยตอนอยู่ใน constructor  , กำลังคิดว่าถ้าเกิดว่า Data ใหญ่มากๆ อาจจะไม่เหมาะสมกับการทำแบบนี้  เพราะว่า Ram จะต้องมีขนาดเท่าๆกับ data ที่เราใส่เข้าไป  ซึ่งเป็นไปได้ยากหาก Data มีขนาดใหญ่มากๆ   ผมได้ทำการ Search ดูแล้วก็พบว่าจาก Discussion Forum ของ Pytorch: https://discuss.pytorch.org/t/how-to-use-a-huge-line-corpus-text-with-dataset-dataloader/30872 \n",
    "Option1: ใช้ pd.Dataframe ในการเปิด File แบบ small chunks of data https://discuss.pytorch.org/t/data-processing-as-a-batch-way/14154/4?u=ptrblck\n",
    "Option2: ใช้ byte Offsets จากไฟล์ใหญ่ๆเพื่อที่จะ lookup .seek(): https://github.com/pytorch/text/issues/130#issuecomment-510412877\n",
    "More Examples: https://github.com/pytorch/text/blob/master/torchtext/datasets/unsupervised_learning.py , https://github.com/pytorch/text/blob/a5880a3da7928dd7dd529507eec943a307204de7/examples/text_classification/iterable_train.py#L169-L214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TextDatasetParallel(Dataset):\n",
    "    \"\"\"\n",
    "    This will be superseded by a framework-agnostic approach\n",
    "    soon.\n",
    "    \"\"\"         \n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer, sample_path: [], block_size: int, overwrite_cache=False,\n",
    "                num_processes=8, cached_directory = \"/workdir/Code/bma_transformer_model/data/cached_data\"):\n",
    "        # assert os.path.isfile(file_path)\n",
    "        # For Loop MultiFile\n",
    "        self.examples = []\n",
    "        self.sample_path = sample_path\n",
    "#         print(f\"THIS IS SAMPLE PATH {sample_path}\")\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        # Set block size to be the blocksize-special tokens\n",
    "        self.block_size = block_size - tokenizer.num_special_tokens_to_add(pair=False)\n",
    "        \n",
    "        self.overwrite_cache = overwrite_cache\n",
    "        self.cached_directory = cached_directory\n",
    "        if not os.path.exists(cached_directory):\n",
    "            os.makedirs(cached_directory)\n",
    "        \n",
    "        # Multiprocess for getting examples\n",
    "        with Pool(processes=num_processes) as p:\n",
    "            self.examples = list(tqdm.tqdm(p.imap(self.load_data_tokenized, self.sample_path), total=len(self.sample_path)))\n",
    "        \n",
    "        \n",
    "\n",
    "    def load_data_tokenized(self, file_path):\n",
    "#         print(f\"I AM DOING {file_path}\")\n",
    "        directory, filename = os.path.split(file_path)\n",
    "        cached_features_file = os.path.join(\n",
    "            self.cached_directory, f\"cached_lm_{tokenizer.__class__.__name__}_{str(self.block_size)}_{filename}\",\n",
    "        )\n",
    "\n",
    "        # Make sure only the first process in distributed training processes the dataset,\n",
    "        # and the others will use the cache.\n",
    "        lock_path = cached_features_file + \".lock\"\n",
    "        with FileLock(lock_path):\n",
    "            if os.path.exists(cached_features_file) and not self.overwrite_cache:\n",
    "                start = time.time()\n",
    "                with open(cached_features_file, \"rb\") as handle:\n",
    "                    temp_examples = pickle.load(handle)\n",
    "                logger.info(\n",
    "                    f\"Loading features from cached file {cached_features_file} [took %.3f s]\", time.time() - start\n",
    "                )\n",
    "            else:\n",
    "                temp_examples = []\n",
    "                with open(file_path, encoding=\"utf-8\") as f:\n",
    "                    text = f.read()\n",
    "                print(\"I finished reading \", file_path)\n",
    "                tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[:10]))\n",
    "                print(\"I finished tokenizing \", file_path)\n",
    "                for i in range(0, len(tokenized_text) - self.block_size + 1, self.block_size):  # Truncate in block of block_size\n",
    "                    temp_examples.append(\n",
    "                        tokenizer.build_inputs_with_special_tokens(tokenized_text[i : i + self.block_size])\n",
    "                    )\n",
    "                    if i%20 == 0:\n",
    "                        print(\"I finished special tok \", file_path)\n",
    "                print(\"I finished every tokenizing \", file_path)\n",
    "                # Note that we are losing the last truncated example here for the sake of simplicity (no padding)\n",
    "                # If your dataset is small, first you should loook for a bigger one :-) and second you\n",
    "                # can change this behavior by adding (model specific) padding.\n",
    "\n",
    "                start = time.time()\n",
    "                with open(cached_features_file, \"wb\") as handle:\n",
    "                    pickle.dump(temp_examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                logger.info(\n",
    "                    \"Saving features into cached file %s [took %.3f s]\", cached_features_file, time.time() - start\n",
    "                )\n",
    "        return temp_examples\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i) -> torch.Tensor:\n",
    "        return torch.tensor(self.examples[i], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer from Pretrained copied from SimpleTransformers [link](https://github.com/ThilinaRajapakse/simpletransformers/blob/master/simpletransformers/language_modeling/language_modeling_model.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 1/6 [00:00<00:01,  2.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 2/6 [00:00<00:01,  2.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 3/6 [00:00<00:00,  3.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:00<00:00,  3.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "dataset = TextDatasetParallel(tokenizer, \n",
    "                              sample_path=list(map(str, GURU_CRAWLER_FILES)), \n",
    "                              block_size=512, \n",
    "                              cached_directory= \"/workdir/cached_data\",\n",
    "                              overwrite_cache=False, # make sure this is false when you have cache!!\n",
    "                              num_processes=3,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached_directory= \"/workdir/cached_data\"\n",
    "# def load_data_tokenized(file_path):\n",
    "#     directory, filename = os.path.split(file_path)\n",
    "#     cached_features_file = os.path.join(\n",
    "#         cached_directory, f\"cached_lm_something_{str(123)}_{filename}\",\n",
    "#     )\n",
    "#     temp_examples = []\n",
    "#     with open(file_path, encoding=\"utf-8\") as f:\n",
    "#         text = f.read()\n",
    "#     print(\"I finished reading \", file_path)\n",
    "#     tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[:10]))\n",
    "#     print(\"I finished tokenizing \", file_path)\n",
    "#     return f\"{file_path}+123\"\n",
    "# # Multiprocess for getting examples\n",
    "# with Pool(processes=2) as p:\n",
    "#     examples = list(tqdm.tqdm(p.imap(load_data_tokenized, list(map(str, GURU_CRAWLER_FILES))), total=len(list(map(str, GURU_CRAWLER_FILES)))))\n",
    "# print(examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# print(text[:1000])\n",
    "# print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[:1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 900 ms, sys: 4 ms, total: 904 ms\n",
      "Wall time: 903 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[:100000]))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.27 s, sys: 40 ms, total: 7.31 s\n",
      "Wall time: 7.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[:1000000]))\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For text[:3000000]__  \n",
    "\n",
    "Rust implementation\n",
    ">CPU times: user 6.38 s, sys: 328 ms, total: 6.7 s  \n",
    "Wall time: 5.18 s\n",
    "\n",
    "Python\n",
    ">CPU times: user 15.5 s, sys: 72 ms, total: 15.6 s  \n",
    "Wall time: 15.6 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 s, sys: 72 ms, total: 15.6 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[:3000000]))\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For text[:8000000]__  \n",
    "\n",
    "Rust implementation\n",
    ">\n",
    "\n",
    "Python\n",
    ">CPU times: user 36.1 s, sys: 340 ms, total: 36.4 s  \n",
    "Wall time: 36.4 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.1 s, sys: 340 ms, total: 36.4 s\n",
      "Wall time: 36.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[:8000000]))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8055389"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i_batch, sample_batched in enumerate(dataloader):\n",
    "#     print(i_batch, sample_batched)\n",
    "#     oumodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = CharBPETokenizer(vocab_file='vocab.json',merges_file ='merges.txt' )\n",
    "# no_accent_strip = BertNormalizer(strip_accents=False)\n",
    "# tokenizer._tokenizer.normalizer = no_accent_strip\n",
    "# tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "#     (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "#     (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "# )\n",
    "\n",
    "# input_ids = torch.tensor(tokenizer.encode(u\"สวัสดีครับ ผมชื่อไนท์ ตอนนี้ก็เป็นเวลาที่ผมต้องไปโรงเรียนแล้ว  นี่คือการเว้นวรรคสองทีครับ  จะได้ออกเป็นสอง Spaces\").ids).unsqueeze(0)\n",
    "# print(input_ids)\n",
    "# outputs = model(input_ids, labels=input_ids)\n",
    "# print(outputs)\n",
    "# loss, prediction_scores = outputs[:2]\n",
    "# print(loss, prediction_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.__getitem__(1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from transformers import TextDataset, LineByLineTextDataset\n",
    "\n",
    "# # dataset = LineByLineTextDataset(\n",
    "# #     tokenizer=pretrain_tokenizer,\n",
    "# #     file_path=\"../data/text/AA/wiki_01\",\n",
    "# #     block_size=128,\n",
    "# # )\n",
    "\n",
    "# dataset = TextDataset(\n",
    "#     tokenizer=pretrain_tokenizer,\n",
    "#     file_path=\"../data/text/AA/wiki_01\",\n",
    "#     block_size=128,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_doc = list(Path(\"../data/text/AA/\").glob(\"wiki*\"))[0].read_text(encoding=\"utf-8\").splitlines()\n",
    "# tokenizer = Tokenizer.from_file(\"./thwiki-sentencepiecebpe.tokenizer.json\")\n",
    "# tokenizer.encode_batch(one_doc[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_doc = list(Path(\"../data/text/AA/\").glob(\"wiki*\"))[0].read_text(encoding=\"utf-8\").splitlines()\n",
    "# tokenizer = RobertaTokenizerFast(vocab_file='vocab.json',merges_file ='merges.txt', max_len=512)\n",
    "# tokenizer.batch_encode_plus(one_doc[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(tokenizer.encode_batch(one_doc[:8])[5].tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_doc[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "# tokenizer = RobertaTokenizer(vocab_file='vocab.json',merges_file ='merges.txt', max_len=512)\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfomers Trainer [link](https://github.com/huggingface/transformers/blob/master/src/transformers/trainer.py#L133)\n",
    "\n",
    "```python\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Trainer is a simple but feature-complete training and eval loop for PyTorch,\n",
    "    optimized for Transformers.\n",
    "    Args:\n",
    "        prediction_loss_only:\n",
    "            (Optional) in evaluation and prediction, only return the loss\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: PreTrainedModel,\n",
    "        args: TrainingArguments,\n",
    "        data_collator: Optional[DataCollator] = None,\n",
    "        train_dataset: Optional[Dataset] = None,\n",
    "        eval_dataset: Optional[Dataset] = None,\n",
    "        compute_metrics: Optional[Callable[[EvalPrediction], Dict]] = None,\n",
    "        prediction_loss_only=False,\n",
    "        tb_writer: Optional[\"SummaryWriter\"] = None,\n",
    "        optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR] = None,\n",
    "```\n",
    "\n",
    "[TrainingArguments](https://github.com/huggingface/transformers/blob/master/src/transformers/training_args.py#L33) is referenced here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./test_RoBERTa2\",\n",
    "    overwrite_output_dir=True,  #\"Use this to continue training if output_dir points to a checkpoint directory.\"\n",
    "    \n",
    "    \n",
    "    do_train=True, #Whether to run training.\n",
    "    do_eval=True, #Whether to run eval on the dev set.\n",
    "#     do_predict=True, # Whether to run predictions on the test set.\n",
    "    \n",
    "    num_train_epochs=20, # Total number of training epochs to perform.\n",
    "    \n",
    "    \n",
    "    per_device_train_batch_size=8, # Batch size per GPU/TPU core/CPU for training.\n",
    "    per_device_eval_batch_size=8, # Batch size per GPU/TPU core/CPU for evaluation.\n",
    "    \n",
    "    learning_rate=5e-5,  #The initial learning rate for Adam.\n",
    "    adam_epsilon=1e-8, #Epsilon for Adam optimizer.\n",
    "    \n",
    "    save_steps=10_000,  #Save checkpoint every X updates steps.\n",
    "    save_total_limit=2, #\"Limit the total amount of checkpoints. Deletes the older checkpoints in the output_dir. Default is unlimited checkpoints\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc031ac05f148bb8d835a8ad309fcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=20.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531c19f9c0a14cd9abdd0e9aa0a6db44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=323.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2097a573ae411cafe0432f2aa44365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=323.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./EsperBERTo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded = pretrain_tokenizer.encode(u\"สวัสดีครับ ผมชื่อไนท์ ตอนนี้ก็เป็นเวลาที่ผมต้องไปโรงเรียนแล้ว  นี่คือการเว้นวรรคสองทีครับ  จะได้ออกเป็นสอง Spaces\")\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
